{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:48.792834Z",
     "start_time": "2018-03-24T22:57:48.048559Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:49.258194Z",
     "start_time": "2018-03-24T22:57:49.242844Z"
    }
   },
   "outputs": [],
   "source": [
    "def mapper_check(mapper):\n",
    "    for feat_tup in mapper.features:\n",
    "        print('col: {0}, mean: {1}, std_dev: {2}'.format(feat_tup[0][0], feat_tup[1].mean_, feat_tup[1].var_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:50.128100Z",
     "start_time": "2018-03-24T22:57:49.654893Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# generic setup with actual data I encountered\n",
    "# Two 3 numerical columns are drawn from standard normal distribution.\n",
    "# num_0 and num_1 data has been collected since inception. num_2 has only \n",
    "# started being collected recently, so it is null for most entries.\n",
    "# categorical represents some new levels being added later, maybe as \n",
    "# a company expands into states/zip codes. Levels exist in the validation set\n",
    "# that are not in the training set.\n",
    "\n",
    "# num_0 and 1 have data since inception\n",
    "train = pd.DataFrame(np.zeros([1000000,2]))\n",
    "train[[0,1]] = np.random.normal(size=(1000000,2))\n",
    "# num_2 has only started being collected recently\n",
    "train[2] = np.nan\n",
    "train[2][-100000:] = np.random.normal(size=(100000))\n",
    "# categorical has only had 3 levels historically but valid has two more levels\n",
    "train[3] = np.nan\n",
    "train[3][:-50000] = np.random.choice([np.nan, 'a', 'b', 'c'], size=950000)\n",
    "train.columns = ['num_0','num_1','num_2','categorical']\n",
    "\n",
    "# taking the last 50000 records as valid, first 950000 as train\n",
    "valid = train[-50000:].copy()\n",
    "train = train[:-50000]\n",
    "valid['categorical'][-50000:] = np.random.choice([np.nan, 'a', 'b', 'c', 'd', 'e'], size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:50.678211Z",
     "start_time": "2018-03-24T22:57:50.478187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique vals in col \"categorical\": 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_0</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>950000.000000</td>\n",
       "      <td>950000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>-0.003441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999406</td>\n",
       "      <td>1.000015</td>\n",
       "      <td>0.999647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.551844</td>\n",
       "      <td>-4.858162</td>\n",
       "      <td>-3.879602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.672878</td>\n",
       "      <td>-0.674253</td>\n",
       "      <td>-0.678242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>-0.002547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.675054</td>\n",
       "      <td>0.675148</td>\n",
       "      <td>0.670807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.818942</td>\n",
       "      <td>5.112520</td>\n",
       "      <td>4.052374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               num_0          num_1         num_2\n",
       "count  950000.000000  950000.000000  50000.000000\n",
       "mean        0.000417       0.000682     -0.003441\n",
       "std         0.999406       1.000015      0.999647\n",
       "min        -4.551844      -4.858162     -3.879602\n",
       "25%        -0.672878      -0.674253     -0.678242\n",
       "50%         0.000720       0.000916     -0.002547\n",
       "75%         0.675054       0.675148      0.670807\n",
       "max         4.818942       5.112520      4.052374"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('unique vals in col \"categorical\": {0}'.format(len(train['categorical'].unique())))\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:51.061009Z",
     "start_time": "2018-03-24T22:57:51.015755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique vals in col \"categorical\": 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_0</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.001741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.998002</td>\n",
       "      <td>0.999020</td>\n",
       "      <td>1.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.391096</td>\n",
       "      <td>-4.378382</td>\n",
       "      <td>-4.792240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.671800</td>\n",
       "      <td>-0.671017</td>\n",
       "      <td>-0.676408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.005734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.679714</td>\n",
       "      <td>0.680993</td>\n",
       "      <td>0.673335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.222815</td>\n",
       "      <td>3.917901</td>\n",
       "      <td>4.210958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              num_0         num_1         num_2\n",
       "count  50000.000000  50000.000000  50000.000000\n",
       "mean       0.000764      0.005412      0.001741\n",
       "std        0.998002      0.999020      1.002388\n",
       "min       -4.391096     -4.378382     -4.792240\n",
       "25%       -0.671800     -0.671017     -0.676408\n",
       "50%        0.000033      0.004079      0.005734\n",
       "75%        0.679714      0.680993      0.673335\n",
       "max        4.222815      3.917901      4.210958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('unique vals in col \"categorical\": {0}'.format(len(valid['categorical'].unique())))\n",
    "valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:52.483250Z",
     "start_time": "2018-03-24T22:57:51.710585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: num_0, mean: [ 0.00042], std_dev: [ 0.99881]\n",
      "col: num_1, mean: [ 0.00068], std_dev: [ 1.00003]\n",
      "col: num_2, mean: [-0.00259], std_dev: [ 0.05259]\n",
      "col: num_2_na, mean: [ 0.94737], std_dev: [ 0.04986]\n"
     ]
    }
   ],
   "source": [
    "train_cats(train)\n",
    "X_train, y_train, nas_train, mapper_train = proc_df(train, do_scale=True)\n",
    "mapper_check(mapper_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard deviation for col num_2 has dropped a lot due to filling na values and running sklearn's StandardScaler. We know the real distribution is standard normal (std_dev should be 1)\n",
    "\n",
    "# I propose fitting a StandardScaler before filling nas so the distribution isn't changed.\n",
    "\n",
    "# Having proc_df spit out the expected number of levels for each categorical was helpful when troubleshooting index errors with embeddings on different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:52.869741Z",
     "start_time": "2018-03-24T22:57:52.801070Z"
    }
   },
   "outputs": [],
   "source": [
    "train_cats(valid)\n",
    "X_valid, y_valid, nas_valid, _ = proc_df(valid, do_scale=True, na_dict=nas_train)\n",
    "assert(nas_train == nas_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proposed changes proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:53.971513Z",
     "start_time": "2018-03-24T22:57:53.831606Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class StandardScalerPandas(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        self.with_mean = with_mean\n",
    "        self.with_std = with_std\n",
    "        self.copy = copy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # fits without nas via pandas library\n",
    "        if type(X) == np.ndarray:\n",
    "            X = pd.Series(X.reshape(-1))\n",
    "        self.mean_ = X.dropna().mean()\n",
    "        self.var_ = X.dropna().var()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mean = self.mean_\n",
    "        std_dev = np.sqrt(self.var_)\n",
    "        if std_dev == 0:\n",
    "            return X\n",
    "        return (X-mean)/std_dev\n",
    "    \n",
    "def fit_scalers(df, mapper):\n",
    "    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n],StandardScalerPandas()) for n in df.columns if is_numeric_dtype(df[n])]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    return mapper\n",
    "\n",
    "def count_emb_lvls(c, n):\n",
    "    return (n, len(c.cat.categories)+1)\n",
    "\n",
    "def proc_df_new(df, y_fld=None, skip_flds=None, do_scale=False, na_dict=None, preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    if y_fld is None: y = None\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n",
    "        y = df[y_fld].values\n",
    "        skip_flds += [y_fld]\n",
    "    df.drop(skip_flds, axis=1, inplace=True)\n",
    "\n",
    "    # fit the scalers\n",
    "    if do_scale: mapper = fit_scalers(df, mapper)    \n",
    "    if na_dict is None: na_dict = {}\n",
    "    # then fillna\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    # finally transform\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    # numericalize cats and count emb_lvls\n",
    "    emb_lvls=[]\n",
    "    for n,c in df.items():\n",
    "        numericalize(df, c, n, max_n_cat)\n",
    "        if not is_numeric_dtype(c):\n",
    "            emb_lvls.append(count_emb_lvls(c, n))\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "    # return the result\n",
    "    res = [pd.get_dummies(df, dummy_na=True), y, na_dict, emb_lvls]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:55.027271Z",
     "start_time": "2018-03-24T22:57:54.503521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('categorical', 5)]\n",
      "col: num_0, mean: 0.000417164075680511, std_dev: 0.9988131849472348\n",
      "col: num_1, mean: 0.0006815402437186164, std_dev: 1.0000304658662287\n",
      "col: num_2, mean: -0.0034411691905263434, std_dev: 0.999295076599445\n"
     ]
    }
   ],
   "source": [
    "X_train_n, y_train_n, nas_train_n, emb_lvls_train_n, mapper_train_n = proc_df_new(train, do_scale=True)\n",
    "print(emb_lvls_train_n)\n",
    "mapper_check(mapper_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:55.084222Z",
     "start_time": "2018-03-24T22:57:55.036113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('categorical', 7)]\n"
     ]
    }
   ],
   "source": [
    "X_valid_n, y_valid_n, nas_valid_n, emb_lvls_valid_n, mapper_valid_n = proc_df_new(valid, do_scale=True, na_dict=nas_train)\n",
    "print(emb_lvls_valid_n)\n",
    "assert(nas_train == nas_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T23:02:18.681034Z",
     "start_time": "2018-03-24T23:02:18.658616Z"
    }
   },
   "outputs": [],
   "source": [
    "# check numbers on train and valid sets, old proc_df on left, proc_df_new on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:56.018298Z",
     "start_time": "2018-03-24T22:57:55.864473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_0</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "      <th>categorical</th>\n",
       "      <th>num_2_na</th>\n",
       "      <th>num_0_n</th>\n",
       "      <th>num_1_n</th>\n",
       "      <th>num_2_n</th>\n",
       "      <th>categorical_n</th>\n",
       "      <th>num_2_na_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.160973</td>\n",
       "      <td>1.146524</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>-2.160972</td>\n",
       "      <td>1.146524</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.040743</td>\n",
       "      <td>0.110703</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>-1.040743</td>\n",
       "      <td>0.110703</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>-2.247012</td>\n",
       "      <td>-0.727538</td>\n",
       "      <td>-1.739665</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.242641</td>\n",
       "      <td>-2.247011</td>\n",
       "      <td>-0.727538</td>\n",
       "      <td>-0.398255</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0.825047</td>\n",
       "      <td>1.078543</td>\n",
       "      <td>2.989957</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.242641</td>\n",
       "      <td>0.825047</td>\n",
       "      <td>1.078543</td>\n",
       "      <td>0.686784</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num_0     num_1     num_2  categorical  num_2_na   num_0_n  \\\n",
       "0      -2.160973  1.146524  0.000205            4  0.235702 -2.160972   \n",
       "1      -1.040743  0.110703  0.000205            2  0.235702 -1.040743   \n",
       "949998 -2.247012 -0.727538 -1.739665            2 -4.242641 -2.247011   \n",
       "949999  0.825047  1.078543  2.989957            4 -4.242641  0.825047   \n",
       "\n",
       "         num_1_n   num_2_n  categorical_n  num_2_na_n  \n",
       "0       1.146524  0.000895              4        True  \n",
       "1       0.110703  0.000895              2        True  \n",
       "949998 -0.727538 -0.398255              2       False  \n",
       "949999  1.078543  0.686784              4       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_train.join(X_train_n, how='outer', rsuffix='_n').head(2),X_train.join(X_train_n, how='outer', rsuffix='_n').tail(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:57:57.244742Z",
     "start_time": "2018-03-24T22:57:57.200152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_0</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "      <th>categorical</th>\n",
       "      <th>num_2_na</th>\n",
       "      <th>num_0_n</th>\n",
       "      <th>num_1_n</th>\n",
       "      <th>num_2_n</th>\n",
       "      <th>categorical_n</th>\n",
       "      <th>num_2_na_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950000</th>\n",
       "      <td>0.339303</td>\n",
       "      <td>-1.855631</td>\n",
       "      <td>0.197993</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339300</td>\n",
       "      <td>-1.855612</td>\n",
       "      <td>0.197991</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950001</th>\n",
       "      <td>-0.056827</td>\n",
       "      <td>0.231256</td>\n",
       "      <td>1.283059</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.056826</td>\n",
       "      <td>0.231254</td>\n",
       "      <td>1.283046</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.220468</td>\n",
       "      <td>1.357868</td>\n",
       "      <td>-0.833487</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220466</td>\n",
       "      <td>1.357854</td>\n",
       "      <td>-0.833479</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.190175</td>\n",
       "      <td>-1.344253</td>\n",
       "      <td>-0.212788</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190173</td>\n",
       "      <td>-1.344239</td>\n",
       "      <td>-0.212785</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num_0     num_1     num_2  categorical  num_2_na   num_0_n  \\\n",
       "950000  0.339303 -1.855631  0.197993            6       0.0  0.339300   \n",
       "950001 -0.056827  0.231256  1.283059            5       0.0 -0.056826   \n",
       "999998 -0.220468  1.357868 -0.833487            2       0.0 -0.220466   \n",
       "999999  0.190175 -1.344253 -0.212788            3       0.0  0.190173   \n",
       "\n",
       "         num_1_n   num_2_n  categorical_n  num_2_na_n  \n",
       "950000 -1.855612  0.197991              6       False  \n",
       "950001  0.231254  1.283046              5       False  \n",
       "999998  1.357854 -0.833479              2       False  \n",
       "999999 -1.344239 -0.212785              3       False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_valid.join(X_valid_n, how='outer', rsuffix='_n').head(2),X_valid.join(X_valid_n, how='outer', rsuffix='_n').tail(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T22:58:11.711131Z",
     "start_time": "2018-03-24T22:58:11.686808Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastai.structured_new as s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T23:01:21.441009Z",
     "start_time": "2018-03-24T23:01:20.923052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('categorical', 5)]\n",
      "col: num_0, mean: 0.000417164075680511, std_dev: 0.9988131849472348\n",
      "col: num_1, mean: 0.0006815402437186164, std_dev: 1.0000304658662287\n",
      "col: num_2, mean: -0.0034411691905263434, std_dev: 0.999295076599445\n"
     ]
    }
   ],
   "source": [
    "X_train_n, y_train_n, nas_train_n, emb_lvls_train_n, mapper_train_n = s_new.proc_df(train, do_scale=True)\n",
    "print(emb_lvls_train_n)\n",
    "mapper_check(mapper_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T23:01:05.987939Z",
     "start_time": "2018-03-24T23:01:05.956611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting structured_new.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile structured_new.py\n",
    "from .imports import *\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from sklearn.ensemble import forest\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class StandardScalerPandas(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        self.with_mean = with_mean\n",
    "        self.with_std = with_std\n",
    "        self.copy = copy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # fits without nas via pandas library\n",
    "        if type(X) == np.ndarray:\n",
    "            X = pd.Series(X.reshape(-1))\n",
    "        self.mean_ = X.dropna().mean()\n",
    "        self.var_ = X.dropna().var()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mean = self.mean_\n",
    "        std_dev = np.sqrt(self.var_)\n",
    "        if std_dev == 0:\n",
    "            return X\n",
    "        return (X-mean)/std_dev\n",
    "\n",
    "\n",
    "def set_plot_sizes(sml, med, big):\n",
    "    plt.rc('font', size=sml)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=sml)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=med)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=sml)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=sml)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=sml)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=big)  # fontsize of the figure title\n",
    "\n",
    "def parallel_trees(m, fn, n_jobs=8):\n",
    "        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n",
    "\n",
    "def draw_tree(t, df, size=10, ratio=0.6, precision=0):\n",
    "    \"\"\" Draws a representation of a random forest in IPython.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    t: The tree you wish to draw\n",
    "    df: The data used to train the tree. This is used to get the names of the features.\n",
    "    \"\"\"\n",
    "    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n",
    "                      special_characters=True, rotate=True, precision=precision)\n",
    "    IPython.display.display(graphviz.Source(re.sub('Tree {',\n",
    "       f'Tree {{ size={size}; ratio={ratio}', s)))\n",
    "\n",
    "def combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n",
    "              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n",
    "    years = np.asarray(years) - 1970\n",
    "    months = np.asarray(months) - 1\n",
    "    days = np.asarray(days) - 1\n",
    "    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',\n",
    "             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')\n",
    "    vals = (years, months, days, weeks, hours, minutes, seconds,\n",
    "            milliseconds, microseconds, nanoseconds)\n",
    "    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n",
    "               if v is not None)\n",
    "\n",
    "def get_sample(df,n):\n",
    "    \"\"\" Gets a random sample of n rows from df, without replacement.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame, that you wish to sample from.\n",
    "    n: The number of rows you wish to sample.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    return value: A random sample of n rows of df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    >>> get_sample(df, 2)\n",
    "       col1 col2\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "    \"\"\"\n",
    "    idxs = sorted(np.random.permutation(len(df))[:n])\n",
    "    return df.iloc[idxs].copy()\n",
    "\n",
    "def add_datepart(df, fldname, drop=True):\n",
    "    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n",
    "    the information from the date. This applies changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame. df gain several new columns.\n",
    "    fldname: A string that is the name of the date column you wish to expand.\n",
    "        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n",
    "    drop: If true then the original date column will be removed.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n",
    "    >>> df\n",
    "\n",
    "        A\n",
    "    0   2000-03-11\n",
    "    1   2000-03-12\n",
    "    2   2000-03-13\n",
    "\n",
    "    >>> add_datepart(df, 'A')\n",
    "    >>> df\n",
    "\n",
    "        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n",
    "    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n",
    "    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n",
    "    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n",
    "    \"\"\"\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "\n",
    "def is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n",
    "\n",
    "def train_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    catagorical values. This applies the changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values. The category codes are determined by trn.\n",
    "\n",
    "    trn: A pandas dataframe. When creating a category for df, it looks up the\n",
    "        what the category's code were in trn and makes those the category codes\n",
    "        for df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category {a : 1, b : 2}\n",
    "\n",
    "    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n",
    "    >>> apply_cats(df2, df)\n",
    "\n",
    "           col1 col2\n",
    "        0     1    b\n",
    "        1     2    a\n",
    "        2     3    a\n",
    "\n",
    "    now the type of col is category {a : 1, b : 2}\n",
    "    \"\"\"\n",
    "    for n,c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n",
    "\n",
    "def fix_missing(df, col, name, na_dict):\n",
    "    \"\"\" Fill missing data in a column of df with the median, and add a {name}_na column\n",
    "    which specifies if the data was missing.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: The data frame that will be changed.\n",
    "\n",
    "    col: The column of data to fix by filling in missing data.\n",
    "\n",
    "    name: The name of the new filled column in df.\n",
    "\n",
    "    na_dict: A dictionary of values to create na's of and the value to insert. If\n",
    "        name is not a key of na_dict the median will fill any missing data. Also\n",
    "        if name is not a key of na_dict and there is no missing data in col, then\n",
    "        no {name}_na column is not created.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "    >>> fix_missing(df, df['col1'], 'col1', {})\n",
    "    >>> df\n",
    "       col1 col2 col1_na\n",
    "    0     1    5   False\n",
    "    1     2    2    True\n",
    "    2     3    2   False\n",
    "\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "    >>> fix_missing(df, df['col2'], 'col2', {})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "    >>> fix_missing(df, df['col1'], 'col1', {'col1' : 500})\n",
    "    >>> df\n",
    "       col1 col2 col1_na\n",
    "    0     1    5   False\n",
    "    1   500    2    True\n",
    "    2     3    2   False\n",
    "    \"\"\"\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum() or (name in na_dict):\n",
    "            df[name+'_na'] = pd.isnull(col)\n",
    "            filler = na_dict[name] if name in na_dict else col.median()\n",
    "            df[name] = col.fillna(filler)\n",
    "            na_dict[name] = filler\n",
    "    return na_dict\n",
    "\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    \"\"\" Changes the column col from a categorical type to it's integer codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. df[name] will be filled with the integer codes from\n",
    "        col.\n",
    "\n",
    "    col: The column you wish to change into the categories.\n",
    "    name: The column name you wish to insert into df. This column will hold the\n",
    "        integer codes.\n",
    "\n",
    "    max_n_cat: If col has more categories than max_n_cat it will not change the\n",
    "        it to its integer codes. If max_n_cat is None, then col will always be\n",
    "        converted.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category { a : 1, b : 2}\n",
    "\n",
    "    >>> numericalize(df, df['col2'], 'col3', None)\n",
    "\n",
    "       col1 col2 col3\n",
    "    0     1    a    1\n",
    "    1     2    b    2\n",
    "    2     3    a    1\n",
    "    \"\"\"\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n",
    "        df[name] = col.cat.codes+1\n",
    "\n",
    "def fit_scalers(df, mapper):\n",
    "    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n],StandardScalerPandas()) for n in df.columns if is_numeric_dtype(df[n])]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    return mapper\n",
    "\n",
    "def proc_df(df, y_fld=None, skip_flds=None, do_scale=False, na_dict=None,\n",
    "            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n",
    "\n",
    "    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n",
    "    changes the df into an entirely numeric dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: The data frame you wish to process.\n",
    "\n",
    "    y_fld: The name of the response variable\n",
    "\n",
    "    skip_flds: A list of fields that dropped from df.\n",
    "\n",
    "    do_scale: Standardizes each column in df,Takes Boolean Values(True,False)\n",
    "\n",
    "    na_dict: a dictionary of na columns to add. Na columns are also added if there\n",
    "        are any missing values.\n",
    "\n",
    "    preproc_fn: A function that gets applied to df.\n",
    "\n",
    "    max_n_cat: The maximum number of categories to break into dummy values, instead\n",
    "        of integer codes.\n",
    "\n",
    "    subset: Takes a random subset of size subset from df.\n",
    "\n",
    "    mapper: If do_scale is set as True, the mapper variable\n",
    "        calculates the values used for scaling of variables during training time(mean and standard deviation).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    [x, y, nas, mapper(optional)]:\n",
    "\n",
    "        x: x is the transformed version of df. x will not have the response variable\n",
    "            and is entirely numeric.\n",
    "\n",
    "        y: y is the response variable\n",
    "\n",
    "        nas: returns a dictionary of which nas it created, and the associated median.\n",
    "        \n",
    "        emb_lvls: returns list of tuples where each tuple is categorical name and number of levels+1\n",
    "\n",
    "        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continous\n",
    "        variables which is then used for scaling of during test-time.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category { a : 1, b : 2}\n",
    "\n",
    "    >>> x, y, nas = proc_df(df, 'col1')\n",
    "    >>> x\n",
    "\n",
    "       col2\n",
    "    0     1\n",
    "    1     2\n",
    "    2     1\n",
    "\n",
    "    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n",
    "                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n",
    "                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n",
    "\n",
    "    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n",
    "                          ([:children], StandardScaler())])\n",
    "\n",
    "    >>>round(fit_transform!(mapper, copy(data)), 2)\n",
    "\n",
    "    8x4 Array{Float64,2}:\n",
    "    1.0  0.0  0.0   0.21\n",
    "    0.0  1.0  0.0   1.88\n",
    "    0.0  1.0  0.0  -0.63\n",
    "    0.0  0.0  1.0  -0.63\n",
    "    1.0  0.0  0.0  -1.46\n",
    "    0.0  1.0  0.0  -0.63\n",
    "    1.0  0.0  0.0   1.04\n",
    "    0.0  0.0  1.0   0.21\n",
    "    \"\"\"\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    if y_fld is None: y = None\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n",
    "        y = df[y_fld].values\n",
    "        skip_flds += [y_fld]\n",
    "    df.drop(skip_flds, axis=1, inplace=True)\n",
    "\n",
    "    # fit the scalers\n",
    "    if do_scale: mapper = fit_scalers(df, mapper)    \n",
    "    if na_dict is None: na_dict = {}\n",
    "    # then fillna\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    # finally transform\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    # numericalize cats and count emb_lvls\n",
    "    emb_lvls=[]\n",
    "    for n,c in df.items():\n",
    "        numericalize(df, c, n, max_n_cat)\n",
    "        if not is_numeric_dtype(c):\n",
    "            emb_lvls.append(count_emb_lvls(c, n))\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "    # return the result\n",
    "    res = [pd.get_dummies(df, dummy_na=True), y, na_dict, emb_lvls]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res\n",
    "\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "def set_rf_samples(n):\n",
    "    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n",
    "    n random rows.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n))\n",
    "\n",
    "def reset_rf_samples():\n",
    "    \"\"\" Undoes the changes produced by set_rf_samples.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n",
    "\n",
    "def get_nn_mappers(df, cat_vars, contin_vars):\n",
    "    # Replace nulls with 0 for continuous, \"\" for categorical.\n",
    "    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n",
    "    for v in cat_vars: df[v].fillna('#NA#', inplace=True)\n",
    "\n",
    "    # list of tuples, containing variable and instance of a transformer for that variable\n",
    "    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n",
    "    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n",
    "    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n",
    "    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n",
    "\n",
    "def count_emb_lvls(c, n):\n",
    "    return (n, len(c.cat.categories)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
