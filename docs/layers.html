---

title: layers
keywords: fastai
sidebar: home_sidebar

summary: "Provides essential functions to building and modifying `Model` architectures."
---
<!--


#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: docs_src/layers.ipynb
# instructions: https://docs.fast.ai/gen_doc_main.html

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Layers">Model Layers<a class="anchor-link" href="#Model-Layers">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This module contains many layer classes that we might be interested in using in our models. These layers complement the default <a href="https://pytorch.org/docs/stable/nn.html">Pytorch layers</a> which we can also use as predefined layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Custom-fastai-modules">Custom fastai modules<a class="anchor-link" href="#Custom-fastai-modules">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="AdaptiveConcatPool2d" class="doc_header"><code>class</code> <code>AdaptiveConcatPool2d</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L176" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#AdaptiveConcatPool2d-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>AdaptiveConcatPool2d</code>(<strong><code>sz</code></strong>:<code>Optional</code>[<code>int</code>]=<strong><em><code>None</code></em></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="AdaptiveConcatPool2d-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#AdaptiveConcatPool2d-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>AdaptiveConcatPool2d</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Layer that concats <code>AdaptiveAvgPool2d</code> and <code>AdaptiveMaxPool2d</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The output will be <code>2*sz</code>, or just 2 if <code>sz</code> is None.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <a href="/layers.html#AdaptiveConcatPool2d"><code>AdaptiveConcatPool2d</code></a> object uses adaptive average pooling and adaptive max pooling and concatenates them both. We use this because it provides the model with the information of both methods and improves performance. This technique is called <code>adaptive</code> because it allows us to decide on what output dimensions we want, instead of choosing the input's dimensions to fit a desired output size.</p>
<p>Let's try training with Adaptive Average Pooling first, then with Adaptive Max Pooling and finally with the concatenation of them both to see how they fare in performance.</p>
<p>We will first define a <a href="/layers.html#simple_cnn"><code>simple_cnn</code></a> using <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveMaxPool2d">Adaptive Max Pooling</a> by changing the source code a bit.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">simple_cnn_max</span><span class="p">(</span><span class="n">actns</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">kernel_szs</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">strides</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="s2">&quot;CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`&quot;</span>
    <span class="n">nl</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actns</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
    <span class="n">kernel_szs</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">kernel_szs</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">*</span><span class="n">nl</span><span class="p">)</span>
    <span class="n">strides</span>    <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">strides</span>   <span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">nl</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">actns</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">actns</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">kernel_szs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">strides</span><span class="p">))]</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">Flatten</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">simple_cnn_max</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Total time: 00:02 <p><table style='width:300px; margin-bottom:10px'>
  <tr>
    <th>epoch</th>
    <th>train_loss</th>
    <th>valid_loss</th>
    <th>accuracy</th>
  </tr>
  <tr>
    <th>1</th>
    <th>0.102758</th>
    <th>0.064676</th>
    <th>0.984298</th>
  </tr>
</table>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's try with <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d">Adaptive Average Pooling</a> now.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">simple_cnn_avg</span><span class="p">(</span><span class="n">actns</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">kernel_szs</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">strides</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="s2">&quot;CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`&quot;</span>
    <span class="n">nl</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actns</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
    <span class="n">kernel_szs</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">kernel_szs</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">*</span><span class="n">nl</span><span class="p">)</span>
    <span class="n">strides</span>    <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">strides</span>   <span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">nl</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">actns</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">actns</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">kernel_szs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">strides</span><span class="p">))]</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">Flatten</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">simple_cnn_avg</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Total time: 00:02 <p><table style='width:300px; margin-bottom:10px'>
  <tr>
    <th>epoch</th>
    <th>train_loss</th>
    <th>valid_loss</th>
    <th>accuracy</th>
  </tr>
  <tr>
    <th>1</th>
    <th>0.241485</th>
    <th>0.201116</th>
    <th>0.973994</th>
  </tr>
</table>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we will try with the concatenation of them both <a href="/layers.html#AdaptiveConcatPool2d"><code>AdaptiveConcatPool2d</code></a>. We will see that, in fact, it increases our accuracy and decreases our loss considerably!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">simple_cnn</span><span class="p">(</span><span class="n">actns</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">kernel_szs</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">strides</span><span class="p">:</span><span class="n">Collection</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="s2">&quot;CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`&quot;</span>
    <span class="n">nl</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actns</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
    <span class="n">kernel_szs</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">kernel_szs</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">*</span><span class="n">nl</span><span class="p">)</span>
    <span class="n">strides</span>    <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">strides</span>   <span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">nl</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">actns</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">actns</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">kernel_szs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">strides</span><span class="p">))]</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">AdaptiveConcatPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">Flatten</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">simple_cnn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Total time: 00:02 <p><table style='width:300px; margin-bottom:10px'>
  <tr>
    <th>epoch</th>
    <th>train_loss</th>
    <th>valid_loss</th>
    <th>accuracy</th>
  </tr>
  <tr>
    <th>1</th>
    <th>0.203015</th>
    <th>0.122094</th>
    <th>0.988224</th>
  </tr>
</table>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="Lambda" class="doc_header"><code>class</code> <code>Lambda</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L10" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#Lambda-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>Lambda</code>(<strong><code>func</code></strong>:<code>LambdaFunc</code>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="Lambda-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#Lambda-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>Lambda</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Create a layer that simply calls <code>func</code> with <code>x</code></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is very useful to use functions as layers in our networks inside a <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential">Sequential</a> object. So, for example, say we want to apply a <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.log_softmax">log_softmax loss</a> and we need to change the shape of our output batches to be able to use this loss. We can add a layer that applies the necessary change in shape by calling:</p>
<p><code>Lambda(lambda x: x.view(x.size(0),-1))</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see an example of how the shape of our output can change when we add this layer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">train_dl</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">xb</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([64, 10, 1, 1])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">train_dl</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">xb</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([64, 10])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Flatten" class="doc_header"><code>class</code> <code>Flatten</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L25" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#Flatten-pytest" style="float:right; padding-right:10px">[test]</a></h2><blockquote><p><code>Flatten</code>(<strong><code>full</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="Flatten-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#Flatten-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>Flatten</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Flatten <code>x</code> to a single dimension, often used at the end of a model. <code>full</code> for rank-1 tensor</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The function we build above is actually implemented in our library as <a href="/layers.html#Flatten"><code>Flatten</code></a>. We can see that it returns the same size when we run it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">Flatten</span><span class="p">(),</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">train_dl</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">xb</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([64, 10])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="PoolFlatten" class="doc_header"><code>PoolFlatten</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L30" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#PoolFlatten-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>PoolFlatten</code>() â†’ <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential"><code>Sequential</code></a></p>
</blockquote>
<div class="collapse" id="PoolFlatten-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#PoolFlatten-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>PoolFlatten</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Apply <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d"><code>nn.AdaptiveAvgPool2d</code></a> to <code>x</code> and then flatten the result.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can combine these two final layers (<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d">AdaptiveAvgPool2d</a> and <a href="/layers.html#Flatten"><code>Flatten</code></a>) by using <a href="/layers.html#PoolFlatten"><code>PoolFlatten</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">PoolFlatten</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">train_dl</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">xb</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([64, 10])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another use we give to the Lambda function is to resize batches with <a href="/layers.html#ResizeBatch"><code>ResizeBatch</code></a> when we have a layer that expects a different input than what comes from the previous one.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResizeBatch" class="doc_header"><code>class</code> <code>ResizeBatch</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L20" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#ResizeBatch-pytest" style="float:right; padding-right:10px">[test]</a></h2><blockquote><p><code>ResizeBatch</code>(<strong>*<code>size</code></strong>:<code>int</code>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="ResizeBatch-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#ResizeBatch-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>ResizeBatch</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Reshape <code>x</code> to <code>size</code>, keeping batch dim the same size</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])[</span><span class="kc">None</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[[ 1., -1.],
         [ 1., -1.]]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">ResizeBatch</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[ 1., -1.,  1., -1.]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="Debugger" class="doc_header"><code>class</code> <code>Debugger</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L186" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#Debugger-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>Debugger</code>() :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="Debugger-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#Debugger-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>Debugger</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>A module to debug inside a model.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The debugger module allows us to peek inside a network while its training and see in detail what is going on. We can see inputs, outputs and sizes at any point in the network.</p>
<p>For instance, if you run the following:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">Debugger</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
<p>... you'll see something like this:</p>

<pre><code>/home/ubuntu/fastai/fastai/layers.py(74)forward()
     72     def forward(self,x:Tensor) -&gt; Tensor:
     73         set_trace()
---&gt; 74         return x
     75 
     76 class StdUpsample(nn.Module):

ipdb&gt;</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="PixelShuffle_ICNR" class="doc_header"><code>class</code> <code>PixelShuffle_ICNR</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L202" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#PixelShuffle_ICNR-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>PixelShuffle_ICNR</code>(<strong><code>ni</code></strong>:<code>int</code>, <strong><code>nf</code></strong>:<code>int</code>=<strong><em><code>None</code></em></strong>, <strong><code>scale</code></strong>:<code>int</code>=<strong><em><code>2</code></em></strong>, <strong><code>blur</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong><code>norm_type</code></strong>=<strong><em><code>&lt;NormType.Weight: 3&gt;</code></em></strong>, <strong><code>leaky</code></strong>:<code>float</code>=<strong><em><code>None</code></em></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="PixelShuffle_ICNR-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#PixelShuffle_ICNR-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>PixelShuffle_ICNR</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Upsample by <code>scale</code> from <code>ni</code> filters to <code>nf</code> (default <code>ni</code>), using <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.PixelShuffle"><code>nn.PixelShuffle</code></a>, <a href="/layers.html#icnr"><code>icnr</code></a> init, and <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.weight_norm"><code>weight_norm</code></a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="MergeLayer" class="doc_header"><code>class</code> <code>MergeLayer</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L147" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#MergeLayer-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>MergeLayer</code>(<strong><code>dense</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="MergeLayer-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#MergeLayer-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>MergeLayer</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Merge a shortcut with the result of the module by adding them or concatenating them if <code>dense=True</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="PartialLayer" class="doc_header"><code>class</code> <code>PartialLayer</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L170" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#PartialLayer-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>PartialLayer</code>(<strong><code>func</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="PartialLayer-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#PartialLayer-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>PartialLayer</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Layer that applies <code>partial(func, **kwargs)</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="SigmoidRange" class="doc_header"><code>class</code> <code>SigmoidRange</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L165" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#SigmoidRange-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>SigmoidRange</code>(<strong><code>low</code></strong>, <strong><code>high</code></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="SigmoidRange-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#SigmoidRange-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>SigmoidRange</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Sigmoid module with range <code>(low,x_max)</code></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="SequentialEx" class="doc_header"><code>class</code> <code>SequentialEx</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L128" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#SequentialEx-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>SequentialEx</code>(<strong>*<code>layers</code></strong>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="SequentialEx-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#SequentialEx-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>SequentialEx</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Like <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential"><code>nn.Sequential</code></a>, but with ModuleList semantics, and can access module input</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="SelfAttention" class="doc_header"><code>class</code> <code>SelfAttention</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L81" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#SelfAttention-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>SelfAttention</code>(<strong><code>n_channels</code></strong>:<code>int</code>) :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="SelfAttention-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#SelfAttention-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>SelfAttention</code>:</p><ul><li><code>pytest -sv tests/test_torch_core.py::test_keep_parameter</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_torch_core.py#L269" class="source_link" style="float:right">[source]</a></li></ul><p>To run tests please refer to this <a href="/dev/test.html#quick-guide">guide</a>.</p></div></div><p>Self attention layer for nd.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="BatchNorm1dFlat" class="doc_header"><code>class</code> <code>BatchNorm1dFlat</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L292" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#BatchNorm1dFlat-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>BatchNorm1dFlat</code>(<strong><code>num_features</code></strong>, <strong><code>eps</code></strong>=<strong><em><code>1e-05</code></em></strong>, <strong><code>momentum</code></strong>=<strong><em><code>0.1</code></em></strong>, <strong><code>affine</code></strong>=<strong><em><code>True</code></em></strong>, <strong><code>track_running_stats</code></strong>=<strong><em><code>True</code></em></strong>) :: <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d"><code>BatchNorm1d</code></a></p>
</blockquote>
<div class="collapse" id="BatchNorm1dFlat-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#BatchNorm1dFlat-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>BatchNorm1dFlat</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d"><code>nn.BatchNorm1d</code></a>, but first flattens leading dimensions</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-functions">Loss functions<a class="anchor-link" href="#Loss-functions">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="FlattenedLoss" class="doc_header"><code>class</code> <code>FlattenedLoss</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L221" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#FlattenedLoss-pytest" style="float:right; padding-right:10px">[test]</a></h3><blockquote><p><code>FlattenedLoss</code>(<strong><code>func</code></strong>, <strong>*<code>args</code></strong>, <strong><code>axis</code></strong>:<code>int</code>=<strong><em><code>-1</code></em></strong>, <strong><code>floatify</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong><code>is_2d</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="FlattenedLoss-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#FlattenedLoss-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>FlattenedLoss</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Same as <code>func</code>, but flattens input and target.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create an instance of <code>func</code> with <code>args</code> and <code>kwargs</code>. When passing an output and target, it</p>
<ul>
<li>puts <code>axis</code> first in output and target with a transpose</li>
<li>casts the target to <code>float</code> if <code>floatify=True</code></li>
<li>squeezes the <code>output</code> to two dimensions if <code>is_2d</code>, otherwise one dimension, squeezes the target to one dimension</li>
<li>applies the instance of <code>func</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="BCEFlat" class="doc_header"><code>BCEFlat</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L253" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#BCEFlat-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>BCEFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>:<code>int</code>=<strong><em><code>-1</code></em></strong>, <strong><code>floatify</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="BCEFlat-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#BCEFlat-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>BCEFlat</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Same as <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss"><code>nn.BCELoss</code></a>, but flattens input and target.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="BCEWithLogitsFlat" class="doc_header"><code>BCEWithLogitsFlat</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L249" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#BCEWithLogitsFlat-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>BCEWithLogitsFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>:<code>int</code>=<strong><em><code>-1</code></em></strong>, <strong><code>floatify</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="BCEWithLogitsFlat-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#BCEWithLogitsFlat-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>BCEWithLogitsFlat</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Same as <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.BCEWithLogitsLoss"><code>nn.BCEWithLogitsLoss</code></a>, but flattens input and target.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="CrossEntropyFlat" class="doc_header"><code>CrossEntropyFlat</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L245" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#CrossEntropyFlat-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>CrossEntropyFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>:<code>int</code>=<strong><em><code>-1</code></em></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="CrossEntropyFlat-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#CrossEntropyFlat-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>CrossEntropyFlat</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Same as <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss"><code>nn.CrossEntropyLoss</code></a>, but flattens input and target.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="MSELossFlat" class="doc_header"><code>MSELossFlat</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L257" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#MSELossFlat-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>MSELossFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>:<code>int</code>=<strong><em><code>-1</code></em></strong>, <strong><code>floatify</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="MSELossFlat-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#MSELossFlat-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>MSELossFlat</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Same as <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss"><code>nn.MSELoss</code></a>, but flattens input and target.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NoopLoss" class="doc_header"><code>class</code> <code>NoopLoss</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L261" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#NoopLoss-pytest" style="float:right; padding-right:10px">[test]</a></h2><blockquote><p><code>NoopLoss</code>() :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="NoopLoss-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#NoopLoss-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>NoopLoss</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Just returns the mean of the <code>output</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="WassersteinLoss" class="doc_header"><code>class</code> <code>WassersteinLoss</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L265" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#WassersteinLoss-pytest" style="float:right; padding-right:10px">[test]</a></h2><blockquote><p><code>WassersteinLoss</code>() :: <a href="/core.html#PrePostInitMeta"><code>PrePostInitMeta</code></a> :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="WassersteinLoss-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#WassersteinLoss-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>WassersteinLoss</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>For WGAN.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Helper-functions-to-create-modules">Helper functions to create modules<a class="anchor-link" href="#Helper-functions-to-create-modules">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bn_drop_lin" class="doc_header"><code>bn_drop_lin</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L44" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#bn_drop_lin-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>bn_drop_lin</code>(<strong><code>n_in</code></strong>:<code>int</code>, <strong><code>n_out</code></strong>:<code>int</code>, <strong><code>bn</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong><code>p</code></strong>:<code>float</code>=<strong><em><code>0.0</code></em></strong>, <strong><code>actn</code></strong>:<code>Optional</code>[<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>Module</code></a>]=<strong><em><code>None</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="bn_drop_lin-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#bn_drop_lin-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>bn_drop_lin</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <a href="/layers.html#bn_drop_lin"><code>bn_drop_lin</code></a> function returns a sequence of <a href="https://arxiv.org/abs/1502.03167">batch normalization</a>, <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf">dropout</a> and a linear layer. This custom layer is usually used at the end of a model.</p>
<p><code>n_in</code> represents the size of the input, <code>n_out</code> the size of the output, <code>bn</code> whether we want batch norm or not, <code>p</code> how much dropout, and <code>actn</code> (optional parameter) adds an activation function at the end.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv2d" class="doc_header"><code>conv2d</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L98" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#conv2d-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>conv2d</code>(<strong><code>ni</code></strong>:<code>int</code>, <strong><code>nf</code></strong>:<code>int</code>, <strong><code>ks</code></strong>:<code>int</code>=<strong><em><code>3</code></em></strong>, <strong><code>stride</code></strong>:<code>int</code>=<strong><em><code>1</code></em></strong>, <strong><code>padding</code></strong>:<code>int</code>=<strong><em><code>None</code></em></strong>, <strong><code>bias</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>init</code></strong>:<code>LayerFunc</code>=<strong><em><code>'kaiming_normal_'</code></em></strong>) â†’ <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d"><code>Conv2d</code></a></p>
</blockquote>
<div class="collapse" id="conv2d-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#conv2d-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>conv2d</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Create and initialize <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d"><code>nn.Conv2d</code></a> layer. <code>padding</code> defaults to <code>ks//2</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv2d_trans" class="doc_header"><code>conv2d_trans</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L103" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#conv2d_trans-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>conv2d_trans</code>(<strong><code>ni</code></strong>:<code>int</code>, <strong><code>nf</code></strong>:<code>int</code>, <strong><code>ks</code></strong>:<code>int</code>=<strong><em><code>2</code></em></strong>, <strong><code>stride</code></strong>:<code>int</code>=<strong><em><code>2</code></em></strong>, <strong><code>padding</code></strong>:<code>int</code>=<strong><em><code>0</code></em></strong>, <strong><code>bias</code></strong>=<strong><em><code>False</code></em></strong>) â†’ <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d"><code>ConvTranspose2d</code></a></p>
</blockquote>
<div class="collapse" id="conv2d_trans-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#conv2d_trans-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>conv2d_trans</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Create <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d"><code>nn.ConvTranspose2d</code></a> layer.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv_layer" class="doc_header"><code>conv_layer</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L111" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#conv_layer-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>conv_layer</code>(<strong><code>ni</code></strong>:<code>int</code>, <strong><code>nf</code></strong>:<code>int</code>, <strong><code>ks</code></strong>:<code>int</code>=<strong><em><code>3</code></em></strong>, <strong><code>stride</code></strong>:<code>int</code>=<strong><em><code>1</code></em></strong>, <strong><code>padding</code></strong>:<code>int</code>=<strong><em><code>None</code></em></strong>, <strong><code>bias</code></strong>:<code>bool</code>=<strong><em><code>None</code></em></strong>, <strong><code>is_1d</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong><code>norm_type</code></strong>:<code>Optional</code>[<a href="/layers.html#NormType"><code>NormType</code></a>]=<strong><em><code>&lt;NormType.Batch: 1&gt;</code></em></strong>, <strong><code>use_activ</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong><code>leaky</code></strong>:<code>float</code>=<strong><em><code>None</code></em></strong>, <strong><code>transpose</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong><code>init</code></strong>:<code>Callable</code>=<strong><em><code>'kaiming_normal_'</code></em></strong>, <strong><code>self_attention</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="conv_layer-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#conv_layer-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>conv_layer</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <a href="/layers.html#conv_layer"><code>conv_layer</code></a> function returns a sequence of <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d">nn.Conv2D</a>, <a href="https://arxiv.org/abs/1502.03167">BatchNorm</a> and a ReLU or <a href="https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf">leaky RELU</a> activation function.</p>
<p><code>n_in</code> represents the size of the input, <code>n_out</code> the size of the output, <code>ks</code> the kernel size, <code>stride</code> the stride with which we want to apply the convolutions. <code>bias</code> will decide if they have bias or not (if None, defaults to True unless using batchnorm). <code>norm_type</code> selects the type of normalization (or <code>None</code>). If <code>leaky</code> is None, the activation is a standard <code>ReLU</code>, otherwise it's a <code>LeakyReLU</code> of slope <code>leaky</code>. Finally if <code>transpose=True</code>, the convolution is replaced by a <code>ConvTranspose2D</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="embedding" class="doc_header"><code>embedding</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L285" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#embedding-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>embedding</code>(<strong><code>ni</code></strong>:<code>int</code>, <strong><code>nf</code></strong>:<code>int</code>) â†’ <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>Module</code></a></p>
</blockquote>
<div class="collapse" id="embedding-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#embedding-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>embedding</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create an <a href="https://arxiv.org/abs/1711.09160">embedding layer</a> with input size <code>ni</code> and output size <code>nf</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="relu" class="doc_header"><code>relu</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L107" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#relu-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>relu</code>(<strong><code>inplace</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong><code>leaky</code></strong>:<code>float</code>=<strong><em><code>None</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="relu-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#relu-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>relu</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Return a relu activation, maybe <code>leaky</code> and <code>inplace</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="res_block" class="doc_header"><code>res_block</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L152" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#res_block-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>res_block</code>(<strong><code>nf</code></strong>, <strong><code>dense</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong><code>norm_type</code></strong>:<code>Optional</code>[<a href="/layers.html#NormType"><code>NormType</code></a>]=<strong><em><code>&lt;NormType.Batch: 1&gt;</code></em></strong>, <strong><code>bottle</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>, <strong>**<code>conv_kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="res_block-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#res_block-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>res_block</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Resnet block of <code>nf</code> features. <code>conv_kwargs</code> are passed to <a href="/layers.html#conv_layer"><code>conv_layer</code></a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="sigmoid_range" class="doc_header"><code>sigmoid_range</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L161" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#sigmoid_range-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>sigmoid_range</code>(<strong><code>x</code></strong>, <strong><code>low</code></strong>, <strong><code>high</code></strong>)</p>
</blockquote>
<div class="collapse" id="sigmoid_range-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#sigmoid_range-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>sigmoid_range</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Sigmoid function with range <code>(low, high)</code></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="simple_cnn" class="doc_header"><code>simple_cnn</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L269" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#simple_cnn-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>simple_cnn</code>(<strong><code>actns</code></strong>:<code>Collection</code>[<code>int</code>], <strong><code>kernel_szs</code></strong>:<code>Collection</code>[<code>int</code>]=<strong><em><code>None</code></em></strong>, <strong><code>strides</code></strong>:<code>Collection</code>[<code>int</code>]=<strong><em><code>None</code></em></strong>, <strong><code>bn</code></strong>=<strong><em><code>False</code></em></strong>) â†’ <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential"><code>Sequential</code></a></p>
</blockquote>
<div class="collapse" id="simple_cnn-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#simple_cnn-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>simple_cnn</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>CNN with <a href="/layers.html#conv_layer"><code>conv_layer</code></a> defined by <code>actns</code>, <code>kernel_szs</code> and <code>strides</code>, plus batchnorm if <code>bn</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Initialization-of-modules">Initialization of modules<a class="anchor-link" href="#Initialization-of-modules">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="batchnorm_2d" class="doc_header"><code>batchnorm_2d</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L36" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#batchnorm_2d-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>batchnorm_2d</code>(<strong><code>nf</code></strong>:<code>int</code>, <strong><code>norm_type</code></strong>:<a href="/layers.html#NormType"><code>NormType</code></a>=<strong><em><code>&lt;NormType.Batch: 1&gt;</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="batchnorm_2d-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#batchnorm_2d-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>batchnorm_2d</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>A batchnorm2d layer with <code>nf</code> features initialized depending on <code>norm_type</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="icnr" class="doc_header"><code>icnr</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L192" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#icnr-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>icnr</code>(<strong><code>x</code></strong>, <strong><code>scale</code></strong>=<strong><em><code>2</code></em></strong>, <strong><code>init</code></strong>=<strong><em><code>'kaiming_normal_'</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="icnr-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#icnr-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>icnr</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>ICNR init of <code>x</code>, with <code>scale</code> and <code>init</code> function.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="trunc_normal_" class="doc_header"><code>trunc_normal_</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L280" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#trunc_normal_-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>trunc_normal_</code>(<strong><code>x</code></strong>:<code>Tensor</code>, <strong><code>mean</code></strong>:<code>float</code>=<strong><em><code>0.0</code></em></strong>, <strong><code>std</code></strong>:<code>float</code>=<strong><em><code>1.0</code></em></strong>) â†’ <code>Tensor</code></p>
</blockquote>
<div class="collapse" id="trunc_normal_-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#trunc_normal_-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>trunc_normal_</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Truncated normal initialization.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="icnr" class="doc_header"><code>icnr</code><a href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L192" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#icnr-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>icnr</code>(<strong><code>x</code></strong>, <strong><code>scale</code></strong>=<strong><em><code>2</code></em></strong>, <strong><code>init</code></strong>=<strong><em><code>'kaiming_normal_'</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="icnr-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#icnr-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>icnr</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>ICNR init of <code>x</code>, with <code>scale</code> and <code>init</code> function.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NormType" class="doc_header">`NormType`<a class="source_link" data-toggle="collapse" data-target="#NormType-pytest" style="float:right; padding-right:10px">[test]</a></h2><blockquote><p><code>Enum</code> = [Batch, BatchZero, Weight, Spectral]</p>
</blockquote>
<div class="collapse" id="NormType-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#NormType-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>NormType</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>An enumeration.</p>

</div>

</div>

</div>
</div>

</div>
</div>
 

