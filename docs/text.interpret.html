---

title: text.interpret
keywords: fastai
sidebar: home_sidebar

summary: "Easy access of language models and ULMFiT"
---
<!--


#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: docs_src/text.interpret.ipynb
# instructions: https://docs.fast.ai/gen_doc_main.html

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="NLP-Interpret">NLP Interpret<a class="anchor-link" href="#NLP-Interpret">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/text.interpret.html#text.interpret"><code>text.interpret</code></a> is the module that implements custom <a href="/train.html#Interpretation"><code>Interpretation</code></a> classes for different NLP tasks by inheriting from it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TextClassificationInterpretation" class="doc_header"><code>class</code> <code>TextClassificationInterpretation</code><a href="https://github.com/fastai/fastai/blob/master/fastai/text/interpret.py#L35" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#TextClassificationInterpretation-pytest" style="float:right; padding-right:10px">[test]</a></h2><blockquote><p><code>TextClassificationInterpretation</code>(<strong><code>learn</code></strong>:<a href="/basic_train.html#Learner"><code>Learner</code></a>, <strong><code>preds</code></strong>:<code>Tensor</code>, <strong><code>y_true</code></strong>:<code>Tensor</code>, <strong><code>losses</code></strong>:<code>Tensor</code>, <strong><code>ds_type</code></strong>:<a href="/basic_data.html#DatasetType"><code>DatasetType</code></a>=<strong><em><code>&lt;DatasetType.Valid: 2&gt;</code></em></strong>) :: <a href="/train.html#ClassificationInterpretation"><code>ClassificationInterpretation</code></a></p>
</blockquote>
<div class="collapse" id="TextClassificationInterpretation-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#TextClassificationInterpretation-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>TextClassificationInterpretation</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Provides an interpretation of classification based on input sensitivity. This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_doc</span><span class="p">(</span><span class="n">TextClassificationInterpretation</span><span class="o">.</span><span class="n">intrinsic_attention</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TextClassificationInterpretation.intrinsic_attention" class="doc_header"><code>intrinsic_attention</code><a href="https://github.com/fastai/fastai/blob/master/fastai/text/interpret.py#L49" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#TextClassificationInterpretation-intrinsic_attention-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>intrinsic_attention</code>(<strong><code>text</code></strong>:<code>str</code>, <strong><code>class_id</code></strong>:<code>int</code>=<strong><em><code>None</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="TextClassificationInterpretation-intrinsic_attention-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#TextClassificationInterpretation-intrinsic_attention-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>intrinsic_attention</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Calculate the intrinsic attention of the input w.r.t to an output <code>class_id</code>, or the classification given by the model if <code>None</code>. For reference, see the Sequential Jacobian session at <a href="https://www.cs.toronto.edu/~graves/preprint.pdf">https://www.cs.toronto.edu/~graves/preprint.pdf</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_doc</span><span class="p">(</span><span class="n">TextClassificationInterpretation</span><span class="o">.</span><span class="n">html_intrinsic_attention</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TextClassificationInterpretation.html_intrinsic_attention" class="doc_header"><code>html_intrinsic_attention</code><a href="https://github.com/fastai/fastai/blob/master/fastai/text/interpret.py#L69" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#TextClassificationInterpretation-html_intrinsic_attention-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>html_intrinsic_attention</code>(<strong><code>text</code></strong>:<code>str</code>, <strong><code>class_id</code></strong>:<code>int</code>=<strong><em><code>None</code></em></strong>, <strong>**<code>kwargs</code></strong>) â†’ <code>str</code></p>
</blockquote>
<div class="collapse" id="TextClassificationInterpretation-html_intrinsic_attention-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#TextClassificationInterpretation-html_intrinsic_attention-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>html_intrinsic_attention</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_doc</span><span class="p">(</span><span class="n">TextClassificationInterpretation</span><span class="o">.</span><span class="n">show_intrinsic_attention</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TextClassificationInterpretation.show_intrinsic_attention" class="doc_header"><code>show_intrinsic_attention</code><a href="https://github.com/fastai/fastai/blob/master/fastai/text/interpret.py#L73" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#TextClassificationInterpretation-show_intrinsic_attention-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>show_intrinsic_attention</code>(<strong><code>text</code></strong>:<code>str</code>, <strong><code>class_id</code></strong>:<code>int</code>=<strong><em><code>None</code></em></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<div class="collapse" id="TextClassificationInterpretation-show_intrinsic_attention-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#TextClassificationInterpretation-show_intrinsic_attention-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>show_intrinsic_attention</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_doc</span><span class="p">(</span><span class="n">TextClassificationInterpretation</span><span class="o">.</span><span class="n">show_top_losses</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="TextClassificationInterpretation.show_top_losses" class="doc_header"><code>show_top_losses</code><a href="https://github.com/fastai/fastai/blob/master/fastai/text/interpret.py#L77" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#TextClassificationInterpretation-show_top_losses-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>show_top_losses</code>(<strong><code>k</code></strong>:<code>int</code>, <strong><code>max_len</code></strong>:<code>int</code>=<strong><em><code>70</code></em></strong>)</p>
</blockquote>
<div class="collapse" id="TextClassificationInterpretation-show_top_losses-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#TextClassificationInterpretation-show_top_losses-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>show_top_losses</code>. To contribute a test please refer to <a href="/dev/test.html">this guide</a> and <a href="https://forums.fast.ai/t/improving-expanding-functional-tests/32929">this discussion</a>.</p></div></div><p>Create a tabulation showing the first <code>k</code> texts in top_losses along with their prediction, actual,loss, and probability of actual class. <code>max_len</code> is the maximum number of tokens displayed.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's show how <a href="/text.interpret.html#TextClassificationInterpretation"><code>TextClassificationInterpretation</code></a> can be used once we train a text classification model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="train">train<a class="anchor-link" href="#train">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imdb</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB_SAMPLE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_lm</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextList</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="n">imdb</span><span class="p">,</span> <span class="s1">&#39;texts.csv&#39;</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">split_by_rand_pct</span><span class="p">()</span>
                   <span class="o">.</span><span class="n">label_for_lm</span><span class="p">()</span>
                   <span class="o">.</span><span class="n">databunch</span><span class="p">())</span>
<span class="n">data_lm</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_lm</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>idx</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>! ! ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . xxmaj xxunk ! xxbos xxmaj this is a extremely well - made film . xxmaj the acting , script and camera - work are all first - rate . xxmaj the music is good , too , though it is</td>
    </tr>
    <tr>
      <td>1</td>
      <td>) . xxmaj all in all , we were very disappointed at this xxmaj spike xxmaj lee effort ! ! xxbos a really great movie and true story . xxmaj dan xxmaj jansen the xxmaj greatest xxunk ever . a touching and beautiful movie the whole family can enjoy . xxmaj the story of xxmaj jane xxmaj xxunk battle with cancer and xxmaj dan xxmaj jansen love for his sister</td>
    </tr>
    <tr>
      <td>2</td>
      <td>just typical folks ) in everyday settings in order to create xxunk involving and realistic films . \n \n  xxmaj in this case , the film is about xxmaj french and xxmaj german coal miners , so appropriately , the people in the roles seem like miners -- not actors . xxmaj the central conflict as the film begins is that there is a huge mine xxunk on the</td>
    </tr>
    <tr>
      <td>3</td>
      <td>here that xxunk banning ... which is a shame because i never would have sat through it where it not for the fact that it 's on ' the xxunk list ' . xxmaj the plot actually gives the film a decent base - or at least more of a decent base than most xxunk films - and it follows an actress who is kidnapped and dragged off into the</td>
    </tr>
    <tr>
      <td>4</td>
      <td>xxmaj at the same time , the xxmaj john xxmaj holmes character shows a very clever hustler who is able to pass through the xxunk and xxunk situations almost xxunk . xxmaj the movie deserves being watched more than once . xxmaj the seventies ambiance xxunk and full of drugs is amazing . xxbos xxmaj if you loved xxmaj long xxmaj way xxmaj round you will enjoy this nearly as</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">language_model_learner</span><span class="p">(</span><span class="n">data_lm</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;mini_train_lm&#39;</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">save_encoder</span><span class="p">(</span><span class="s1">&#39;mini_train_encoder&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.650112</td>
      <td>3.822781</td>
      <td>0.290729</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>1</td>
      <td>4.378561</td>
      <td>3.766616</td>
      <td>0.295357</td>
      <td>00:21</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_clas</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextList</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="n">imdb</span><span class="p">,</span> <span class="s1">&#39;texts.csv&#39;</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">data_lm</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">split_from_df</span><span class="p">(</span><span class="n">col</span><span class="o">=</span><span class="s1">&#39;is_valid&#39;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">label_from_df</span><span class="p">(</span><span class="n">cols</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">databunch</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">data_clas</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">load_encoder</span><span class="p">(</span><span class="s1">&#39;mini_train_encoder&#39;</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">,</span><span class="mf">1e-2</span><span class="p">))</span>
<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;mini_train_clas&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.666474</td>
      <td>0.666000</td>
      <td>0.605000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.666053</td>
      <td>0.646565</td>
      <td>0.615000</td>
      <td>00:18</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="interpret">interpret<a class="anchor-link" href="#interpret">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interp</span> <span class="o">=</span> <span class="n">TextClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interp</span><span class="o">.</span><span class="n">show_intrinsic_attention</span><span class="p">(</span><span class="s2">&quot;I really like this movie, it is amazing!&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<span style="font-family: monospace;"><span title="1.000" style="background-color: rgba(0, 104, 55, 0.5);">xxbos</span> <span title="0.335" style="background-color: rgba(253, 190, 110, 0.5);">i</span> <span title="0.599" style="background-color: rgba(217, 239, 139, 0.5);">really</span> <span title="0.258" style="background-color: rgba(248, 144, 83, 0.5);">like</span> <span title="0.130" style="background-color: rgba(223, 65, 47, 0.5);">this</span> <span title="0.100" style="background-color: rgba(214, 47, 38, 0.5);">movie</span> <span title="0.034" style="background-color: rgba(180, 15, 38, 0.5);">,</span> <span title="0.101" style="background-color: rgba(214, 47, 38, 0.5);">it</span> <span title="0.065" style="background-color: rgba(196, 30, 38, 0.5);">is</span> <span title="0.300" style="background-color: rgba(252, 172, 96, 0.5);">amazing</span> <span title="0.156" style="background-color: rgba(231, 82, 54, 0.5);">!</span></span>
</div>

</div>

</div>
</div>

</div>
</div>
 

