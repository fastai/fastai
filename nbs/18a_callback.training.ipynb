{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.fp16 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastai2.test_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking callbacks\n",
    "\n",
    "> Callbacks that make decisions depending how a monitored metric/loss behaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShortEpochCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@log_args\n",
    "class ShortEpochCallback(Callback):\n",
    "    \"Fit just `pct` of an epoch, then stop\"\n",
    "    def __init__(self,pct=0.01,short_valid=True): self.pct,self.short_valid = pct,short_valid\n",
    "    def after_batch(self):\n",
    "        if self.iter/self.n_iter < self.pct: return\n",
    "        if self.training:    raise CancelTrainException\n",
    "        if self.short_valid: raise CancelValidException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = synth_learner()\n",
    "learn.fit(1, cbs=ShortEpochCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = synth_learner()\n",
    "learn.fit(1, cbs=ShortEpochCallback(short_valid=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientAccumulation -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@log_args\n",
    "class GradientAccumulation(Callback):\n",
    "    \"Accumulate gradients before updating weights\"\n",
    "    toward_end,run_before=True,MixedPrecision\n",
    "\n",
    "    def __init__(self, n_acc=32): store_attr(self, 'n_acc')\n",
    "    def begin_fit(self): self.count=0\n",
    "\n",
    "    def after_backward(self):\n",
    "        self.count += find_bs(self.learn.yb)\n",
    "        if self.count < self.n_acc: raise CancelBatchException() #skip weight update\n",
    "        else: self.count=0\n",
    "\n",
    "    _docs = dict(begin_fit=\"Set counter to 0\",\n",
    "                 after_backward=\"Skip weight update if we have not seen enough items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = synth_learner()\n",
    "\n",
    "learn.fit(2, lr=0.01, cbs=GradientAccumulation(n_acc=2*learn.dls.bs))\n",
    "# ensure train_loss decreased\n",
    "assert learn.recorder.values[-1][0] < learn.recorder.values[0][0]\n",
    "\n",
    "learn.fit(2, lr=0.01, cbs=GradientAccumulation(n_acc=1e6))\n",
    "# ensure valid_loss didn't change (same weights)\n",
    "assert learn.recorder.values[-1][1] == learn.recorder.values[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BnFreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
    "\n",
    "def set_bn_eval(m:nn.Module)->None:\n",
    "    \"Set bn layers in eval mode for all recursive children of `m`.\"\n",
    "    for l in m.children():\n",
    "        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n",
    "            l.eval()\n",
    "        set_bn_eval(l)\n",
    "\n",
    "class BnFreeze(Callback):\n",
    "    \"Freeze moving average statistics in all non-trainable batchnorm layers.\"\n",
    "    def begin_epoch(self):\n",
    "        set_bn_eval(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BnFreeze` is useful when you'd like to train two separate models that have a common feature extractor / body. The only part of the model that's different is the head that you attach for transfer learning. <br>\n",
    "\n",
    "`Learner.freeze()` doesn't suffice here as the `BatchNorm` layers are trainable by default, and running mean and sdev of batches are tracked. For feature extractors to fully match, you need to set `train_bn=False` and these stats need to be frozen as well, which is precisely the function of `BnFreeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "dls  = ImageDataLoaders.from_folder(path, valid_pct=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first demonstrate the mismatch of the running stats when using only `train_bn=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "learn1 = cnn_learner(deepcopy(dls), resnet18, pretrained=True, train_bn=False)\n",
    "learn2 = cnn_learner(deepcopy(dls), resnet18, pretrained=True, train_bn=False)\n",
    "\n",
    "learn1.fit(1, lr=0.02)\n",
    "learn2.fit(1, lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "# SOURCE: https://discuss.pytorch.org/t/check-if-models-have-same-weights/4351/6\n",
    "def models_equal(model_1, model_2, verbose=False):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                if verbose: print(f'Mismtach found at {key_item_1[0]}')\n",
    "            else:\n",
    "                raise Exception\n",
    "                if verbose: print('Models being compared have different architectures')\n",
    "    if models_differ == 0:\n",
    "        if verbose: print('Models match perfectly')\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "models_equal(learn1.model, learn2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "learn1 = cnn_learner(deepcopy(dls), resnet18, pretrained=True, train_bn=False, cbs=BnFreeze)\n",
    "learn2 = cnn_learner(deepcopy(dls), resnet18, pretrained=True, train_bn=False, cbs=BnFreeze)\n",
    "\n",
    "learn1.fit(1, lr=0.02)\n",
    "learn2.fit(1, lr=0.02)\n",
    "\n",
    "assert models_equal(learn1.model[0], learn2.model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
