{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.data.all import *\n",
    "from fastai.optimizer import *\n",
    "from fastai.learner import *\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.test_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of Predictions\n",
    "\n",
    "> Classes to build objects to better interpret predictions of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock), \n",
    "                  get_items=get_image_files, \n",
    "                  splitter=RandomSubsetSplitter(.1,.1, seed=42),\n",
    "                  get_y=parent_label)\n",
    "test_dls = mnist.dataloaders(untar_data(URLs.MNIST_SAMPLE), bs=8)\n",
    "test_learner = cnn_learner(test_dls, resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def plot_top_losses(x, y, *args, **kwargs):\n",
    "    raise Exception(f\"plot_top_losses is not implemented for {type(x)},{type(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = [\"plot_top_losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Interpretation():\n",
    "    \"Interpretation base class, can be inherited for task specific Interpretation classes\"\n",
    "    def __init__(self, dl, inputs, preds, targs, decoded, losses):\n",
    "        store_attr(\"dl,inputs,preds,targs,decoded,losses\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_learner(cls, learn, ds_idx=1, dl=None, act=None):\n",
    "        \"Construct interpretation object from a learner\"\n",
    "        if dl is None: dl = learn.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "        return cls(dl, *learn.get_preds(dl=dl, with_input=True, with_loss=True, with_decoded=True, act=None))\n",
    "\n",
    "    def top_losses(self, k=None, largest=True):\n",
    "        \"`k` largest(/smallest) losses and indexes, defaulting to all losses (sorted by `largest`).\"\n",
    "        return self.losses.topk(ifnone(k, len(self.losses)), largest=largest)\n",
    "\n",
    "    def plot_top_losses(self, k, largest=True, **kwargs):\n",
    "        losses,idx = self.top_losses(k, largest)\n",
    "        if not isinstance(self.inputs, tuple): self.inputs = (self.inputs,)\n",
    "        if isinstance(self.inputs[0], Tensor): inps = tuple(o[idx] for o in self.inputs)\n",
    "        else: inps = self.dl.create_batch(self.dl.before_batch([tuple(o[i] for o in self.inputs) for i in idx]))\n",
    "        b = inps + tuple(o[idx] for o in (self.targs if is_listy(self.targs) else (self.targs,)))\n",
    "        x,y,its = self.dl._pre_show_batch(b, max_n=k)\n",
    "        b_out = inps + tuple(o[idx] for o in (self.decoded if is_listy(self.decoded) else (self.decoded,)))\n",
    "        x1,y1,outs = self.dl._pre_show_batch(b_out, max_n=k)\n",
    "        if its is not None:\n",
    "            plot_top_losses(x, y, its, outs.itemgot(slice(len(inps), None)), L(self.preds).itemgot(idx), losses,  **kwargs)\n",
    "        #TODO: figure out if this is needed\n",
    "        #its None means that a batch knows how to show itself as a whole, so we pass x, x1\n",
    "        #else: show_results(x, x1, its, ctxs=ctxs, max_n=max_n, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "interp = Interpretation.from_learner(test_learner)\n",
    "x, y, out = [], [], []\n",
    "for batch in test_learner.dls.valid:\n",
    "    x += batch[0]\n",
    "    y += batch[1]\n",
    "    out += test_learner.model(batch[0])\n",
    "x,y,out = torch.stack(x), torch.stack(y, dim=0), torch.stack(out, dim=0)\n",
    "test_eq(interp.inputs, to_cpu(x))\n",
    "test_eq(interp.targs, to_cpu(y))\n",
    "losses = torch.stack([test_learner.loss_func(p,t) for p,t in zip(out,y)], dim=0)\n",
    "test_close(interp.losses, to_cpu(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "#dummy test to ensure we can run on the training set\n",
    "interp = Interpretation.from_learner(test_learner, ds_idx=0)\n",
    "x, y, out = [], [], []\n",
    "for batch in test_learner.dls.train.new(drop_last=False, shuffle=False):\n",
    "    x += batch[0]\n",
    "    y += batch[1]\n",
    "    out += test_learner.model(batch[0])\n",
    "x,y,out = torch.stack(x), torch.stack(y, dim=0), torch.stack(out, dim=0)\n",
    "test_eq(interp.inputs, to_cpu(x))\n",
    "test_eq(interp.targs, to_cpu(y))\n",
    "losses = torch.stack([test_learner.loss_func(p,t) for p,t in zip(out,y)], dim=0)\n",
    "test_close(interp.losses, to_cpu(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClassificationInterpretation(Interpretation):\n",
    "    \"Interpretation methods for classification models.\"\n",
    "\n",
    "    def __init__(self, dl, inputs, preds, targs, decoded, losses):\n",
    "        super().__init__(dl, inputs, preds, targs, decoded, losses)\n",
    "        self.vocab = self.dl.vocab\n",
    "        if is_listy(self.vocab): self.vocab = self.vocab[-1]\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        \"Confusion matrix as an `np.ndarray`.\"\n",
    "        x = torch.arange(0, len(self.vocab))\n",
    "        d,t = flatten_check(self.decoded, self.targs)\n",
    "        cm = ((d==x[:,None]) & (t==x[:,None,None])).long().sum(2)\n",
    "        return to_np(cm)\n",
    "\n",
    "    def plot_confusion_matrix(self, normalize=False, title='Confusion matrix', cmap=\"Blues\", norm_dec=2,\n",
    "                              plot_txt=True, **kwargs):\n",
    "        \"Plot the confusion matrix, with `title` and using `cmap`.\"\n",
    "        # This function is mainly copied from the sklearn docs\n",
    "        cm = self.confusion_matrix()\n",
    "        if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig = plt.figure(**kwargs)\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        tick_marks = np.arange(len(self.vocab))\n",
    "        plt.xticks(tick_marks, self.vocab, rotation=90)\n",
    "        plt.yticks(tick_marks, self.vocab, rotation=0)\n",
    "\n",
    "        if plot_txt:\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                coeff = f'{cm[i, j]:.{norm_dec}f}' if normalize else f'{cm[i, j]}'\n",
    "                plt.text(j, i, coeff, horizontalalignment=\"center\", verticalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        ax = fig.gca()\n",
    "        ax.set_ylim(len(self.vocab)-.5,-.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.grid(False)\n",
    "\n",
    "    def most_confused(self, min_val=1):\n",
    "        \"Sorted descending list of largest non-diagonal entries of confusion matrix, presented as actual, predicted, number of occurrences.\"\n",
    "        cm = self.confusion_matrix()\n",
    "        np.fill_diagonal(cm, 0)\n",
    "        res = [(self.vocab[i],self.vocab[j],cm[i,j])\n",
    "                for i,j in zip(*np.where(cm>=min_val))]\n",
    "        return sorted(res, key=itemgetter(2), reverse=True)\n",
    "\n",
    "    def print_classification_report(self):\n",
    "        \"Print scikit-learn classification report\"\n",
    "        d,t = flatten_check(self.decoded, self.targs)\n",
    "        print(skm.classification_report(t, d, labels=list(self.vocab.o2i.values()), target_names=[str(v) for v in self.vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SegmentationInterpretation(Interpretation):\n",
    "    \"Interpretation methods for segmentation models.\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "#ensure Interpretation.plot_top_losses works on problems with multiple outputs\n",
    "\n",
    "mnist = DataBlock((ImageBlock, CategoryBlock, CategoryBlock), get_items=get_image_files,\n",
    "                   splitter=RandomSubsetSplitter(.1,.1, seed=42),\n",
    "                   n_inp=1,\n",
    "                   get_y=[parent_label, parent_label])\n",
    "test_dls = mnist.dataloaders(untar_data(URLs.MNIST_SAMPLE), bs=8)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = create_cnn_model(resnet18, get_c(test_dls)[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x), self.backbone(x)\n",
    "    \n",
    "def loss(inputs, targeta, targetb, reduction=\"mean\"):\n",
    "    loss1 = CrossEntropyLossFlat(reduction=reduction)(inputs[0], targeta)\n",
    "    loss2 = CrossEntropyLossFlat(reduction=reduction)(inputs[1], targetb)\n",
    "    return loss1 + loss2\n",
    "\n",
    "@typedispatch\n",
    "def plot_top_losses(x: TensorImage, y: tuple, *args, **kwargs):\n",
    "    plot_top_losses(x, y[0], *args, **kwargs)\n",
    "\n",
    "test_learner = Learner(test_dls, Model(), loss_func=loss)\n",
    "interp = Interpretation.from_learner(test_learner)\n",
    "interp.plot_top_losses(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 01a_losses.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 10b_tutorial.albumentations.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 18b_callback.preds.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.image_sequence.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 74_callback.azureml.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted dev-setup.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted quick_start.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
