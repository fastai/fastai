{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastai.imports import *\n",
    "from fastai.data.all import *\n",
    "from fastai.optimizer import *\n",
    "from fastai.learner import *\n",
    "from fastai.callback.core import *\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp test_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Learner\n",
    "\n",
    "> For quick testing of the training loop and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def synth_dbunch(a=2, b=3, bs=16, n_train=10, n_valid=2, cuda=False):\n",
    "    def get_data(n):\n",
    "        x = torch.randn(bs*n, 1)\n",
    "        return TensorDataset(x, a*x + b + 0.1*torch.randn(bs*n, 1))\n",
    "    train_ds = get_data(n_train)\n",
    "    valid_ds = get_data(n_valid)\n",
    "    device = default_device() if cuda else None\n",
    "    train_dl = TfmdDL(train_ds, bs=bs, shuffle=True, num_workers=0)\n",
    "    valid_dl = TfmdDL(valid_ds, bs=bs, num_workers=0)\n",
    "    return DataLoaders(train_dl, valid_dl, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RegModel(Module):\n",
    "    def __init__(self, cuda=False): \n",
    "        device = default_device() if cuda else None\n",
    "        self.a,self.b = nn.Parameter(torch.randn(1, device=device)),nn.Parameter(torch.randn(1, device=device))\n",
    "    def forward(self, x): return x*self.a + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@delegates(Learner.__init__)\n",
    "def synth_learner(n_trn=10, n_val=2, cuda=False, lr=1e-3, data=None, model=None, **kwargs):\n",
    "    if data is None: data=synth_dbunch(n_train=n_trn,n_valid=n_val, cuda=cuda)\n",
    "    if model is None: model=RegModel(cuda=cuda)\n",
    "    return Learner(data, model, lr=lr, loss_func=MSELossFlat(),\n",
    "                   opt_func=partial(SGD, mom=0.9), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class VerboseCallback(Callback):\n",
    "    \"Callback that prints the name of each event called\"\n",
    "    def __call__(self, event_name):\n",
    "        print(event_name)\n",
    "        super().__call__(event_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_env(name):\n",
    "    \"Return env var value if it's defined and not an empty string, or return Unknown\"\n",
    "    res = os.environ.get(name,'')\n",
    "    return res if len(res) else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def try_import(module):\n",
    "    \"Try to import `module`. Returns module's object on success, None on failure\"\n",
    "    try: return importlib.import_module(module)\n",
    "    except: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def nvidia_smi(cmd = \"nvidia-smi\"):\n",
    "    try: res = run(cmd)\n",
    "    except OSError as e: return None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = nvidia_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def nvidia_mem():\n",
    "    try: mem = run(\"nvidia-smi --query-gpu=memory.total --format=csv,nounits,noheader\")\n",
    "    except: return None\n",
    "    return mem.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def show_install(show_nvidia_smi:bool=False):\n",
    "    \"Print user's setup information\"\n",
    "\n",
    "    import fastai, platform, fastprogress, fastcore\n",
    "\n",
    "    rep = []\n",
    "    opt_mods = []\n",
    "\n",
    "    rep.append([\"=== Software ===\", None])\n",
    "    rep.append([\"python\", platform.python_version()])\n",
    "    rep.append([\"fastai\", fastai.__version__])\n",
    "    rep.append([\"fastcore\", fastcore.__version__])\n",
    "    rep.append([\"fastprogress\", fastprogress.__version__])\n",
    "    rep.append([\"torch\",  torch.__version__])\n",
    "\n",
    "    # nvidia-smi\n",
    "    smi = nvidia_smi()\n",
    "    if smi:\n",
    "        match = re.findall(r'Driver Version: +(\\d+\\.\\d+)', smi)\n",
    "        if match: rep.append([\"nvidia driver\", match[0]])\n",
    "\n",
    "    available = \"available\" if torch.cuda.is_available() else \"**Not available** \"\n",
    "    rep.append([\"torch cuda\", f\"{torch.version.cuda} / is {available}\"])\n",
    "\n",
    "    # no point reporting on cudnn if cuda is not available, as it\n",
    "    # seems to be enabled at times even on cpu-only setups\n",
    "    if torch.cuda.is_available():\n",
    "        enabled = \"enabled\" if torch.backends.cudnn.enabled else \"**Not enabled** \"\n",
    "        rep.append([\"torch cudnn\", f\"{torch.backends.cudnn.version()} / is {enabled}\"])\n",
    "\n",
    "    rep.append([\"\\n=== Hardware ===\", None])\n",
    "\n",
    "    gpu_total_mem = []\n",
    "    nvidia_gpu_cnt = 0\n",
    "    if smi:\n",
    "        mem = nvidia_mem()\n",
    "        nvidia_gpu_cnt = len(ifnone(mem, []))\n",
    "\n",
    "    if nvidia_gpu_cnt: rep.append([\"nvidia gpus\", nvidia_gpu_cnt])\n",
    "\n",
    "    torch_gpu_cnt = torch.cuda.device_count()\n",
    "    if torch_gpu_cnt:\n",
    "        rep.append([\"torch devices\", torch_gpu_cnt])\n",
    "        # information for each gpu\n",
    "        for i in range(torch_gpu_cnt):\n",
    "            rep.append([f\"  - gpu{i}\", (f\"{gpu_total_mem[i]}MB | \" if gpu_total_mem else \"\") + torch.cuda.get_device_name(i)])\n",
    "    else:\n",
    "        if nvidia_gpu_cnt:\n",
    "            rep.append([f\"Have {nvidia_gpu_cnt} GPU(s), but torch can't use them (check nvidia driver)\", None])\n",
    "        else:\n",
    "            rep.append([f\"No GPUs available\", None])\n",
    "\n",
    "\n",
    "    rep.append([\"\\n=== Environment ===\", None])\n",
    "\n",
    "    rep.append([\"platform\", platform.platform()])\n",
    "\n",
    "    if platform.system() == 'Linux':\n",
    "        distro = try_import('distro')\n",
    "        if distro:\n",
    "            # full distro info\n",
    "            rep.append([\"distro\", ' '.join(distro.linux_distribution())])\n",
    "        else:\n",
    "            opt_mods.append('distro');\n",
    "            # partial distro info\n",
    "            rep.append([\"distro\", platform.uname().version])\n",
    "\n",
    "    rep.append([\"conda env\", get_env('CONDA_DEFAULT_ENV')])\n",
    "    rep.append([\"python\", sys.executable])\n",
    "    rep.append([\"sys.path\", \"\\n\".join(sys.path)])\n",
    "\n",
    "    print(\"\\n\\n```text\")\n",
    "\n",
    "    keylen = max([len(e[0]) for e in rep if e[1] is not None])\n",
    "    for e in rep:\n",
    "        print(f\"{e[0]:{keylen}}\", (f\": {e[1]}\" if e[1] is not None else \"\"))\n",
    "\n",
    "    if smi:\n",
    "        if show_nvidia_smi: print(f\"\\n{smi}\")\n",
    "    else:\n",
    "        if torch_gpu_cnt: print(\"no nvidia-smi is found\")\n",
    "        else: print(\"no supported gpus found on this system\")\n",
    "\n",
    "    print(\"```\\n\")\n",
    "\n",
    "    print(\"Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\\n\")\n",
    "\n",
    "    if opt_mods:\n",
    "        print(\"Optional package(s) to enhance the diagnostics can be installed with:\")\n",
    "        print(f\"pip install {' '.join(opt_mods)}\")\n",
    "        print(\"Once installed, re-run this utility to get the additional information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python       : 3.10.6\n",
      "fastai       : 2.7.17\n",
      "fastcore     : 1.7.9\n",
      "fastprogress : 1.0.3\n",
      "torch        : 1.12.1+cpu\n",
      "torch cuda   : None / is **Not available** \n",
      "\n",
      "=== Hardware === \n",
      "No GPUs available \n",
      "\n",
      "=== Environment === \n",
      "platform     : Linux-5.4.0-187-generic-x86_64-with-glibc2.35\n",
      "distro       : #207-Ubuntu SMP Mon Jun 10 08:16:10 UTC 2024\n",
      "conda env    : Unknown\n",
      "python       : /usr/bin/python\n",
      "sys.path     : /data/nbs\n",
      "/usr/lib/python310.zip\n",
      "/usr/lib/python3.10\n",
      "/usr/lib/python3.10/lib-dynload\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages\n",
      "/data\n",
      "/usr/lib/python3/dist-packages\n",
      "no supported gpus found on this system\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n",
      "Optional package(s) to enhance the diagnostics can be installed with:\n",
      "pip install distro\n",
      "Once installed, re-run this utility to get the additional information\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "show_install(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
