{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.text.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.data\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n",
    "\n",
    "> Functions and transforms to help gather text data in a `DataSource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_vocab(count, min_freq=3, max_vocab=60000):\n",
    "    \"Create a vocab of `max_vocab` size from `Counter` `count` with items present more than `min_freq`\"\n",
    "    vocab = [o for o,c in count.most_common(max_vocab) if c >= min_freq]\n",
    "    for o in reversed(defaults.text_spec_tok): #Make sure all special tokens are in the vocab\n",
    "        if o in vocab: vocab.remove(o)\n",
    "        vocab.insert(0, o)\n",
    "    vocab = vocab[:max_vocab]\n",
    "    return vocab + [f'xxfake' for i in range(0, 8-len(vocab)%8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'd'])\n",
    "test_eq(set([x for x in make_vocab(count) if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'a'.split()))\n",
    "test_eq(len(make_vocab(count))%8, 0)\n",
    "test_eq(set([x for x in make_vocab(count, min_freq=1) if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'a b c d'.split()))\n",
    "test_eq(set([x for x in make_vocab(count,max_vocab=12, min_freq=1) if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'a b c'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorText(TensorBase):   pass\n",
    "class LMTensorText(TensorText): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Numericalize(Transform):\n",
    "    \"Reversible transform of tokenized texts to numericalized ids\"\n",
    "    def __init__(self, vocab=None, min_freq=3, max_vocab=60000, sep=' '):\n",
    "        self.vocab,self.min_freq,self.max_vocab,self.sep = vocab,min_freq,max_vocab,sep\n",
    "        self.o2i = None if vocab is None else defaultdict(int, {v:k for k,v in enumerate(vocab)})\n",
    "\n",
    "    def setup(self, dsrc):\n",
    "        if dsrc is None: return\n",
    "        if self.vocab is None:\n",
    "            count = Counter(p for o in dsrc for p in o)\n",
    "            self.vocab = make_vocab(count, min_freq=self.min_freq, max_vocab=self.max_vocab)\n",
    "            self.o2i = defaultdict(int, {v:k for k,v in enumerate(self.vocab) if v != 'xxfake'})\n",
    "\n",
    "    def encodes(self, o): return TensorText(tensor([self.o2i  [o_] for o_ in o]))\n",
    "    def decodes(self, o): return Str(self.sep.join([self.vocab[o_] for o_ in o if self.vocab[o_] != PAD]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=1, sep=' ')\n",
    "num.setup(L('This is an example of text'.split(), 'this is another text'.split()))\n",
    "test_eq(set([x for x in num.vocab if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'This is an example of text this another'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "start = 'This is an example of text'\n",
    "t = num(start.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t, tensor([11, 9, 12, 13, 14, 10]))\n",
    "test_eq(num.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=2, sep=' ')\n",
    "num.setup(L('This is an example of text'.split(), 'this is another text'.split()))\n",
    "test_eq(set([x for x in num.vocab if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'is text'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "t = num(start.split())\n",
    "test_eq(t, tensor([0, 9, 0, 0, 0, 10]))\n",
    "test_eq(num.decode(t), f'{UNK} is {UNK} {UNK} {UNK} text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM_DataLoader -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: add backward\n",
    "@delegates()\n",
    "class LMDataLoader(TfmdDL):\n",
    "    def __init__(self, dataset, lens=None, cache=2, bs=64, seq_len=72, num_workers=0, **kwargs):\n",
    "        super().__init__(dataset=dataset, bs=bs, num_workers=num_workers, **kwargs)\n",
    "        self.items = ReindexCollection([(o[0] if isinstance(o, tuple) else o)\n",
    "                                          for o in dataset], cache=cache)\n",
    "        self.seq_len = seq_len\n",
    "        if lens is None: lens = [len(o) for o in self.items]\n",
    "        self.lens = ReindexCollection(lens, idxs=self.items.idxs)\n",
    "        # The \"-1\" is to allow for final label\n",
    "        self.m = round_multiple(sum(lens)-1, bs*seq_len, round_down=True)\n",
    "        self.n = self.m//(seq_len)\n",
    "        self.spb = self.n//bs\n",
    "        self.make_chunks()\n",
    "\n",
    "    def make_chunks(self): self.chunks = Chunks(self.items, self.lens)\n",
    "    def shuffle_fn(self,idxs):\n",
    "        self.items.shuffle()\n",
    "        self.make_chunks()\n",
    "        return idxs\n",
    "\n",
    "    def create_item(self, seq):\n",
    "        if seq>=self.n: raise IndexError\n",
    "        st = ((seq%self.bs)*self.spb + (seq//self.bs)) * self.seq_len\n",
    "        txt = self.chunks[st : st+self.seq_len+1]\n",
    "        return LMTensorText(txt[:-1]),txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 4,3\n",
    "ints = L([0,1,2,3,4],[5,6,7,8,9,10],[11,12,13,14,15,16,17,18],[19,20],[21,22,23],[24]).map(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(ints, bs=bs, seq_len=sl)\n",
    "test_eq(list(dl),\n",
    "    [[tensor([[0, 1, 2], [6, 7, 8], [12, 13, 14], [18, 19, 20]]),\n",
    "      tensor([[1, 2, 3], [7, 8, 9], [13, 14, 15], [19, 20, 21]])],\n",
    "     [tensor([[3, 4, 5], [ 9, 10, 11], [15, 16, 17], [21, 22, 23]]),\n",
    "      tensor([[4, 5, 6], [10, 11, 12], [16, 17, 18], [22, 23, 24]])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check lens work\n",
    "dl = LMDataLoader(ints, lens=ints.map(len), bs=bs, seq_len=sl)\n",
    "test_eq(list(dl),\n",
    "    [[tensor([[0, 1, 2], [6, 7, 8], [12, 13, 14], [18, 19, 20]]),\n",
    "      tensor([[1, 2, 3], [7, 8, 9], [13, 14, 15], [19, 20, 21]])],\n",
    "     [tensor([[3, 4, 5], [ 9, 10, 11], [15, 16, 17], [21, 22, 23]]),\n",
    "      tensor([[4, 5, 6], [10, 11, 12], [16, 17, 18], [22, 23, 24]])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(ints, bs=bs, seq_len=sl, shuffle=True)\n",
    "for x,y in dl: test_eq(x[:,1:], y[:,:-1])\n",
    "((x0,y0), (x1,y1)) = tuple(dl)\n",
    "#Second batch begins where first batch ended\n",
    "test_eq(y0[:,-1], x1[:,0]) \n",
    "test_eq(type(x0), LMTensorText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x: TensorText, y, samples, ctxs=None, max_n=10, **kwargs):\n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x: LMTensorText, y, samples, ctxs=None, max_n=10, **kwargs):\n",
    "    return show_batch[TensorText](x, None, samples, ctxs=ctxs, max_n=max_n, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[xxbos, xxmaj, un, -, bleeping, -, believable, !, xxmaj, meg, xxmaj, ryan, does, n't, even, look, her, usual, pert, lovable, self, in, this, ,, which, normally, makes, me, forgive, her, shallow, ticky, acting, schtick, ., xxmaj, hard, to, believe, she, was, the, producer, on, this, dog, ., xxmaj, plus, xxmaj, kevin, xxmaj, kline, :, what, kind, of, suicide, trip, has, his, career, been, on, ?, xxmaj, whoosh, …, xxmaj, banzai, xxrep, 3, !, xxmaj, finally, this, was, directed, by, the, guy, who, did, xxmaj, big, xxmaj, chill, ?, xxmaj, must, be, a, replay, of, xxmaj, jonestown, -, hollywood,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>[xxbos, xxmaj, this, is, a, extremely, well, -, made, film, ., xxmaj, the, acting, ,, script, and, camera, -, work, are, all, first, -, rate, ., xxmaj, the, music, is, good, ,, too, ,, though, it, is, mostly, early, in, the, film, ,, when, things, are, still, relatively, cheery, ., xxmaj, there, are, no, really, superstars, in, the, cast, ,, though, several, faces, will, be, familiar, ., xxmaj, the, entire, cast, does, an, excellent, job, with, the, script, ., \\n\\n, xxmaj, but, it, is, hard, to, watch, ,, because, there, is, no, good, end, to, a, situation, like, the, one, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  is_valid  \\\n",
       "0  negative     False   \n",
       "1  positive     False   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  [xxbos, xxmaj, un, -, bleeping, -, believable, !, xxmaj, meg, xxmaj, ryan, does, n't, even, look, her, usual, pert, lovable, self, in, this, ,, which, normally, makes, me, forgive, her, shallow, ticky, acting, schtick, ., xxmaj, hard, to, believe, she, was, the, producer, on, this, dog, ., xxmaj, plus, xxmaj, kevin, xxmaj, kline, :, what, kind, of, suicide, trip, has, his, career, been, on, ?, xxmaj, whoosh, …, xxmaj, banzai, xxrep, 3, !, xxmaj, finally, this, was, directed, by, the, guy, who, did, xxmaj, big, xxmaj, chill, ?, xxmaj, must, be, a, replay, of, xxmaj, jonestown, -, hollywood,...  \n",
       "1                 [xxbos, xxmaj, this, is, a, extremely, well, -, made, film, ., xxmaj, the, acting, ,, script, and, camera, -, work, are, all, first, -, rate, ., xxmaj, the, music, is, good, ,, too, ,, though, it, is, mostly, early, in, the, film, ,, when, things, are, still, relatively, cheery, ., xxmaj, there, are, no, really, superstars, in, the, cast, ,, though, several, faces, will, be, familiar, ., xxmaj, the, entire, cast, does, an, excellent, job, with, the, script, ., \\n\\n, xxmaj, but, it, is, hard, to, watch, ,, because, there, is, no, good, end, to, a, situation, like, the, one, ...]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok,count = tokenize_df(df, 'text')\n",
    "df_tok.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of((df_tok)))\n",
    "tfm = Numericalize(make_vocab(count))\n",
    "dsrc = DataSource(df_tok, [[attrgetter('text'), tfm]], splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj the ghost of the xxmaj vietnam war has haunted the xxmaj american xxunk for thirty years now . xxmaj if not because of the fact that xxunk of thousands of xxmaj american soldiers went xxup mia in xxmaj vietnam , or the manner in which those who returned were treated , then because it was the first war that xxmaj america could be said to have lost . xxmaj many men came home from the war a shadow of their former xxunk , and the original xxmaj first xxmaj blood managed to provide a small insight into their problems as they attempted to xxunk back into the world , as the saying goes . xxmaj first xxmaj blood xxmaj part xxup ii , on the other hand , is little more than a fist - xxunk mess that goes to illustrate how sore xxmaj america can be , both in victory and defeat . xxmaj xxunk puts in another xxunk performance as the titular xxmaj special xxmaj forces commando , while xxmaj richard xxmaj xxunk attempts to hold up the serious actor xxunk . xxmaj where it all comes xxunk is in the script , which did n't do any better when it was called xxmaj missing xxmaj in xxmaj action and starred xxmaj xxunk xxmaj xxunk . xxmaj what little semblance of logic there was in the original is now gone , as the filmmakers decide to paint a big s on xxmaj rambo 's massive chest . \n",
      "\n",
      " xxmaj the film picks up a little while after the end of xxmaj first xxmaj blood . xxmaj the film , that is - the novel did n't allow for the possibility of sequels . xxmaj in this mediocre follow - up , xxmaj rambo has been put to work at what appears to be some sort of open - air mine . xxmaj as he is breaking rocks and working up a sweat , a prison guard pulls him away to go and have a xxunk with xxmaj colonel xxmaj xxunk , who xxunk him that his government is willing to offer him an early release if he goes on a xxunk mission . xxmaj rambo , never one to back down from a hard day 's violent work , accepts , and is promptly xxunk off to a xxunk base in what appears to be xxmaj cambodia or xxmaj thailand ( i forget which ) . xxmaj from there , he is xxunk to seek out a camp where xxmaj american xxunk are supposedly being held , and photograph them . xxmaj his mission quite clearly xxunk that he is not to make any attempt to secure their release . xxmaj rambo being xxmaj rambo , however , has other ideas in spite of their possible political xxunk . \n",
      "\n",
      " xxmaj of course , things go somewhat awry when it turns out that the people xxunk xxmaj rambo 's work have more interest in making sure no xxmaj american xxunk are found . xxmaj it is the age - old conspiracy theory , and makes no apologies for xxunk the plight of many an xxmaj american family that was left without a son during the ten years that the official xxmaj vietnam war had been xxunk for . xxmaj of course , with the xxmaj xxunk that was xxunk in xxmaj american society during the 1980s , they could not help but work in a plot xxunk about the xxmaj xxunk army being in bed with what appears to be a single xxunk of xxmaj russians . xxmaj together , the two xxunk attempt to xxunk what information they can from xxmaj rambo , but it xxunk upon them in an xxunk of bullets , xxunk , rockets , and destruction . xxmaj about the only thing missing is the moment when xxmaj rambo xxunk from a xxunk - like xxunk and xxunk himself invincible . \n",
      "\n",
      " xxmaj to be honest , xxmaj first xxmaj blood xxmaj part xxup ii is a well - photographed , and well - choreographed , action spectacle . xxmaj the hand - to - hand combat with the larger xxmaj russian commander is one of the few battles in the film that has any dramatic tension whatsoever . xxmaj the rest is simply a case of the lead actor and the director building a fantasy for xxmaj americans to xxunk their fist to . xxmaj fortunately , this xxunk of xxmaj america xxunk xxunk action films soon died down when more xxunk and intelligent war films such as xxmaj xxunk began doing the xxunk . xxmaj some of the kills shown here are quite creative , despite all the problems . xxmaj the xxmaj xxunk commander meets an end that many an action film villain would xxunk . xxmaj the xxmaj russian commander bites it in a manner that is as spectacular as it is ridiculous . xxmaj only in a 1980s action film would one see a xxup law being used from inside a helicopter . xxmaj sure , there have been action film clichés rooted in xxunk of fact , but never this ridiculous before . \n",
      "\n",
      " i gave xxmaj rambo : xxmaj first xxmaj blood xxmaj part xxup ii a one out of ten . xxmaj it is so bad it is ridiculous , and so ridiculous that it is often funny . xxmaj one does n't even need to have served in the military to know how stupid some of the action sequences are . xxmaj the only risk it takes is in trying to make a stupid political statement with what is a heartbreaking subject for those directly involved . xxmaj keep the tongue xxunk in the cheek , and it might be watchable .\n"
     ]
    }
   ],
   "source": [
    "show_at(dsrc.train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch = dsrc.databunch(bs=16, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos a police officer ( robert xxmaj xxunk ) in a crime ridden city has his wife attacked and young son killed after she xxunk to stand up to a thug at a xxunk station . xxmaj after the murderers get off xxunk - free thanks to a corrupt judge and he himself is xxunk for 30 days for contempt of court , he decides to take matters into his own hands</td>\n",
       "      <td>a police officer ( robert xxmaj xxunk ) in a crime ridden city has his wife attacked and young son killed after she xxunk to stand up to a thug at a xxunk station . xxmaj after the murderers get off xxunk - free thanks to a corrupt judge and he himself is xxunk for 30 days for contempt of court , he decides to take matters into his own hands by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the visuals in this movie are not inspiring , the dialog is worse , the musical numbers destroy this movie .. i xxunk for xxup guitar xxup brothers , but that was immediately xxunk out by something completely unnecessary , and irrelevant . xxmaj it attempted to be deep and meaningful i think , but its just pretentious xxunk nonsense . xxmaj freshman film students without a camera could craft something more</td>\n",
       "      <td>visuals in this movie are not inspiring , the dialog is worse , the musical numbers destroy this movie .. i xxunk for xxup guitar xxup brothers , but that was immediately xxunk out by something completely unnecessary , and irrelevant . xxmaj it attempted to be deep and meaningful i think , but its just pretentious xxunk nonsense . xxmaj freshman film students without a camera could craft something more interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>own . xxmaj it 's funny because these are schools that want racial xxunk , equality etc . and i can honestly say , that it 's there . xxmaj but the thing is when class lets out , or when they 're just hanging out waiting for class , they ( students ) seem to just hang around with people of their own race or ethnicity . xxmaj is that bad</td>\n",
       "      <td>. xxmaj it 's funny because these are schools that want racial xxunk , equality etc . and i can honestly say , that it 's there . xxmaj but the thing is when class lets out , or when they 're just hanging out waiting for class , they ( students ) seem to just hang around with people of their own race or ethnicity . xxmaj is that bad ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxmaj it also xxunk xxmaj ben the opportunity to pick up , and pick on , the very xxunk xxunk of the archives , xxmaj abigail xxmaj chase ( diane xxmaj xxunk ) . xxmaj she thinks xxmaj ben is clearly a xxunk  at least at the beginning . xxmaj but true to action / romance form , xxmaj xxunk 's xxunk xxunk xxunk than you can say , \" is</td>\n",
       "      <td>it also xxunk xxmaj ben the opportunity to pick up , and pick on , the very xxunk xxunk of the archives , xxmaj abigail xxmaj chase ( diane xxmaj xxunk ) . xxmaj she thinks xxmaj ben is clearly a xxunk  at least at the beginning . xxmaj but true to action / romance form , xxmaj xxunk 's xxunk xxunk xxunk than you can say , \" is that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and was xxunk , his voice was xxunk , his face was getting xxunk with xxunk , though he still could pull it off , he looked like he was fifty at the age of forty . xxmaj this was because he was suffering many minor xxunk before his big one that ended his career . xxmaj be he still managed to pull it off in his last ones ! \\n\\n xxmaj</td>\n",
       "      <td>was xxunk , his voice was xxunk , his face was getting xxunk with xxunk , though he still could pull it off , he looked like he was fifty at the age of forty . xxmaj this was because he was suffering many minor xxunk before his big one that ended his career . xxmaj be he still managed to pull it off in his last ones ! \\n\\n xxmaj if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>production xxunk , and xxunk their responsibility to the workers under them . xxmaj in working towards this goal , they each have to take a page from the others ' book . xxmaj kazuhiro 's family becoming more \" xxunk \" is an obvious example . xxmaj also note that xxmaj stevenson thinks it 's odd when xxmaj kazuhiro explains how he had to make a public apology to his workers</td>\n",
       "      <td>xxunk , and xxunk their responsibility to the workers under them . xxmaj in working towards this goal , they each have to take a page from the others ' book . xxmaj kazuhiro 's family becoming more \" xxunk \" is an obvious example . xxmaj also note that xxmaj stevenson thinks it 's odd when xxmaj kazuhiro explains how he had to make a public apology to his workers for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbunch.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dbunch.one_batch()\n",
    "test_eq(type(x), LMTensorText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(dbunch.valid_ds[0][0]), dbunch.valid_dl.lens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_input(samples, pad_idx=1, pad_fields=0, pad_first=False, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    pad_fields = L(pad_fields)\n",
    "    max_len_l = pad_fields.map(lambda f: max([len(s[f]) for s in samples]))\n",
    "    if backwards: pad_first = not pad_first\n",
    "    def _f(field_idx, x):\n",
    "        if field_idx not in pad_fields: return x\n",
    "        idx = pad_fields.items.index(field_idx) #TODO: remove items if L.index is fixed\n",
    "        sl = slice(-len(x), sys.maxsize) if pad_first else slice(0, len(x))\n",
    "        pad =  x.new_zeros(max_len_l[idx]-x.shape[0])+pad_idx\n",
    "        x1 = torch.cat([pad, x] if pad_first else [x, pad])\n",
    "        if backwards: x1 = x1.flip(0)\n",
    "        return retain_type(x1, x)\n",
    "    return [tuple(map(lambda idxx: _f(*idxx), enumerate(s))) for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0), \n",
    "        [(tensor([1,2,3]),1), (tensor([4,5,0]),2), (tensor([6,0,0]), 3)])\n",
    "test_eq(pad_input([(tensor([1,2,3]), (tensor([6]))), (tensor([4,5]), tensor([4,5])), (tensor([6]), (tensor([1,2,3])))], pad_idx=0, pad_fields=1), \n",
    "        [(tensor([1,2,3]),(tensor([6,0,0]))), (tensor([4,5]),tensor([4,5,0])), ((tensor([6]),tensor([1, 2, 3])))])\n",
    "test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0, pad_first=True), \n",
    "        [(tensor([1,2,3]),1), (tensor([0,4,5]),2), (tensor([0,0,6]), 3)])\n",
    "test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0, backwards=True), \n",
    "        [(tensor([3,2,1]),1), (tensor([5,4,0]),2), (tensor([6,0,0]), 3)])\n",
    "x = test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0, backwards=True), \n",
    "        [(tensor([3,2,1]),1), (tensor([5,4,0]),2), (tensor([6,0,0]), 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check retain type\n",
    "x = [(TensorText([1,2,3]),1), (TensorText([4,5]), 2), (TensorText([6]), 3)]\n",
    "y = pad_input(x, pad_idx=0)\n",
    "for s in y: test_eq(type(s[0]), TensorText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _default_sort(x): return len(x[0])\n",
    "\n",
    "@delegates(TfmdDL)\n",
    "class SortedDL(TfmdDL):\n",
    "    def __init__(self, dataset, sort_func=None, res=None, **kwargs):\n",
    "        super().__init__(dataset, **kwargs)\n",
    "        self.sort_func = _default_sort if sort_func is None else sort_func\n",
    "        self.res = [self.sort_func(self.do_item(i)) for i in range_of(self.dataset)] if res is None else res\n",
    "        self.idx_max = np.argmax(self.res)\n",
    "\n",
    "    def get_idxs(self):\n",
    "        idxs = super().get_idxs()\n",
    "        if self.shuffle: return idxs\n",
    "        return sorted(idxs, key=lambda i: self.res[i], reverse=True)\n",
    "\n",
    "    def shuffle_fn(self,idxs):\n",
    "        idxs = np.random.permutation(len(self.dataset))\n",
    "        idx_max = np.extract(idxs==self.idx_max, idxs)[0]\n",
    "        idxs[0],idxs[idx_max] = idxs[idx_max],idxs[0]\n",
    "        sz = self.bs*50\n",
    "        chunks = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n",
    "        chunks = [sorted(s, key=lambda i: self.res[i], reverse=True) for s in chunks]\n",
    "        sort_idx = np.concatenate(chunks)\n",
    "\n",
    "        sz = self.bs\n",
    "        batches = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n",
    "        sort_idx = np.concatenate(np.random.permutation(batches[1:-1])) if len(batches) > 2 else np.array([],dtype=np.int)\n",
    "        sort_idx = np.concatenate((batches[0], sort_idx) if len(batches)==1 else (batches[0], sort_idx, batches[-1]))\n",
    "        return iter(sort_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [(tensor([1,2]),1), (tensor([3,4,5,6]),2), (tensor([7]),3), (tensor([8,9,10]),4)]\n",
    "dl = SortedDL(ds, bs=2, before_batch=partial(pad_input, pad_idx=0))\n",
    "test_eq(list(dl), [(tensor([[ 3,  4,  5,  6], [ 8,  9, 10,  0]]), tensor([2, 4])), \n",
    "                   (tensor([[1, 2], [7, 0]]), tensor([1, 3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [(tensor(range(random.randint(1,10))),i) for i in range(101)]\n",
    "dl = SortedDL(ds, bs=2, create_batch=partial(pad_input, pad_idx=-1), shuffle=True, num_workers=0)\n",
    "batches = list(dl)\n",
    "max_len = len(batches[0][0])\n",
    "for b in batches: \n",
    "    assert(len(b[0])) <= max_len \n",
    "    test_ne(b[0][-1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df_tok))\n",
    "dsrc = DataSource(df_tok, splits=splits, tfms=[\n",
    "    [attrgetter(\"text\"), Numericalize(make_vocab(count))],\n",
    "    [attrgetter(\"label\"), Categorize()]], dl_type=SortedDL)\n",
    "dbch = dsrc.databunch(before_batch=pad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n\\n xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , xxunk bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj victor xxmaj vargas became i was always aware that something did n't quite feel right . xxmaj victor xxmaj vargas suffers from a certain xxunk on the director 's part . xxmaj apparently , the director thought that the ethnic backdrop of a xxmaj latino family on the lower east side , and an xxunk storyline would make the film critic proof . xxmaj he was right , but it did n't fool me . xxmaj raising xxmaj victor xxmaj vargas is the story about a xxunk - year old boy called , you guessed it , xxmaj victor xxmaj vargas ( victor xxmaj xxunk ) who lives his teenage years chasing more xxunk than the xxmaj rolling xxmaj xxunk could do in all the years they 've xxunk . xxmaj the movie starts off in ` ugly xxmaj fat ' xxmaj donna 's bedroom where xxmaj victor is sure to seduce her , but a cry from outside xxunk his plans when his best - friend xxmaj harold ( kevin xxmaj xxunk ) comes - a - looking for him . xxmaj caught in the attempt by xxmaj harold and his sister , xxmaj victor xxmaj vargas runs off for xxunk control . xxmaj yet even with the embarrassing implication that he 's been xxunk the xxunk girl in the neighborhood , nothing xxunk young xxmaj victor from going off on the hunt for more fresh meat . xxmaj on a hot , xxmaj new xxmaj york xxmaj city day they make way to the local public swimming pool where xxmaj victor 's eyes catch a glimpse of the lovely young xxunk xxmaj judy ( judy xxmaj xxunk ) , who 's not just pretty , but a strong and independent too . xxmaj the relationship that develops between xxmaj victor and xxmaj judy becomes the focus of the film . xxmaj the story also focuses on xxmaj victor 's family that is comprised of his grandmother or xxunk ( xxunk xxmaj guzman ) , his brother xxmaj nino ( also played by real life brother to xxmaj victor , xxmaj xxunk xxmaj xxunk ) and his sister xxmaj vicky ( xxunk xxmaj xxunk ) . xxmaj the action follows xxmaj victor between scenes with xxmaj judy and scenes with his family . xxmaj victor tries to xxunk with being an oversexed pimp - daddy , his feelings for xxmaj judy and his grandmother 's conservative xxmaj catholic upbringing . \\n\\n xxmaj the problems that xxunk from xxmaj raising xxmaj victor xxmaj vargas are a few , but glaring errors . xxmaj throughout the film you get to know certain characters like xxmaj vicky , xxmaj nino , xxmaj xxunk , xxmaj judy and even xxmaj judy 's best friend xxmaj xxunk . xxmaj the problem is , we know nothing of xxmaj victor xxmaj vargas except that he is the biggest gigolo in the neighborhood . xxmaj we know that he knows how to lick his lips , and xxunk his xxunk , and carry himself for the sake of xxunk girls into the xxunk , but that 's all . xxmaj we know that xxmaj nino plays piano , and quiet well , you could see it by the awards on the family piano . xxmaj we know his sister xxmaj xxunk , is a gossip - loving girl with an xxunk interest in watching xxup tv . xxmaj we know that xxunk is a hard - working traditional xxmaj xxunk woman who 's trying to raise her kids with xxunk in a world of excess corruption . xxmaj yet where is the titular character , xxmaj victor xxmaj vargas ? xxmaj he 's in this movie somewhere , but we only know what the movie tells us . xxmaj this is by far the film 's biggest flaw . xxmaj victor xxmaj vargas is n't so much a character but a xxunk - xxunk ball , xxunk between scenes with xxmaj judy and his xxmaj grandmother , but we never get to know who xxmaj victor xxmaj vargas really is . xxmaj this is important because as xxmaj i 've mentioned the only thing we know of xxmaj victor xxmaj vargas is that he 's a sexually active teenager with a xxunk the size of xxmaj manhattan . xxmaj he 's a total xxmaj xxunk - male . xxmaj victor xxmaj vargas is not the kind of character i sympathize with at all . xxmaj why should anyone ? xxmaj so by the end of the movie , in the aftermath of the climax are we truly led to believe that somehow xxmaj victor xxmaj vargas has attained xxup any depth and learned the errors of his ways ? xxmaj how could such a two - dimensional character have any depth ? xxmaj if only the director had worried a little more about xxunk out his main character instead of worrying about getting that perfect hand - held shot . \\n\\n xxmaj raising xxmaj victor xxmaj vargas brings to life the world of the xxmaj latino inner - city neighborhood to the big screen . xxmaj something that few films have done before in the past . xxmaj the film has been xxunk for feeling so real , and i wo n't \\n\\n argue with that . i have n't seen this level of reality since xxup xxunk aired xxmaj survivor . xxmaj seriously , although the movie has some nice shots of the city , the writer / director xxmaj peter xxmaj sollett was way too xxunk on close - ups and hand - held shots . xxmaj this problem is particularly noticed in xxunk scenes that are so claustrophobic i was forced to perform deep - breathing xxunk to keep from passing out . xxmaj as the film continues , the shots get tighter and tighter with faces xxunk from xxunk to xxunk on the screen ; you can practically xxunk xxmaj victor xxmaj vargas 's cheap xxunk . xxmaj the overall effect is unrealistic in contrast . xxmaj the xxunk scenes of inner - city apartments make them look small and xxunk , which is not true . xxmaj i 've been in those type apartments ; i used to live in one . xxmaj they 're not xxunk but they have high xxunk and they 're decent living xxunk . xxmaj by the movie 's standards you 'd think that these apartments were xxunk xxunk of xxunk - and - xxunk , xxunk paint and xxunk walls . xxmaj unfortunately , xxmaj sollett 's constant use of close - ups and one particularly bad shot with a xxunk - in on one scene come off as totally amateurish . xxmaj but xxmaj raising xxmaj victor xxmaj vargas is only xxmaj sollett 's second film , and his most well known , a solid effort in filmmaking that will hopefully get better as he continues to make films . xxmaj one review i read xxunk the movie as , ` ethnicity for xxmaj ethnicity 's xxmaj sake , ' and i can not agree more . xxmaj if xxmaj victor xxmaj vargas were truly a great film and story , then the characters ' xxunk would n't matter whether they were xxmaj latino , xxmaj chinese , etc . xxmaj yet if you were to take this story and stick it in middle - class xxunk with a bunch of xxunk - xxunk white kids the results would n't be such glowing reviews , and we 'd see the film 's flaws more clearly . xxmaj indeed , some other aspects of the use of xxmaj latinos in this film bother me . xxmaj while some aspects of xxmaj victor xxmaj vargas are accurate others i have to question . xxmaj for example , xxmaj victor , xxmaj nino and xxmaj vicky all share the same room to sleep . xxmaj this set off an alarm for me because it seemed contrary to what i believe . xxmaj any self - xxunk xxmaj latino family would n't have two older brothers sharing the same room with a thirteen - year old girl . xxmaj at first i was xxunk , perhaps i was wrong , but after speaking with my grandmother i knew my problem with this was justified . xxmaj considering how conservative the grandmother is , you 'd think that xxmaj vicky would have been sleeping in her room . \\n\\n xxmaj as a xxmaj latino who grew up in a somewhat conservative xxmaj cuban household , raised by my grandmother while my mother was working full - time , i could relate to the movie in many ways , which is why my critical xxunk are xxunk because i really wanted to love this movie . xxmaj unfortunately , my lack of respect for xxmaj victor xxmaj vargas xxunk my feelings for the film . xxmaj maybe it 's because xxmaj victor xxmaj vargas reminds me of those guys who were getting laid while i was playing with my xxmaj xxunk xxmaj xxunk when i was xxunk . xxmaj maybe it 's because without any further xxunk by the film , xxmaj victor xxmaj vargas is merely a stereotypical hot - blooded xxmaj latino , who 'll just end up shouting to girls from his car , ` hey bay - xxunk , xxunk want to get into my xxunk xxunk - xxunk ? ' xxmaj either way i do n't like him , so ultimately how can i like a film about him ? xxmaj so if you 'll excuse me , xxmaj i 'm going to go stick my hands into a bowl of xxunk .</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with the xxunk possible scenarios to get the two protagonists together in the end . xxmaj in fact , all its charm is xxunk , contained within the characters and the setting and the plot … which is highly believable to xxunk . xxmaj it 's easy to think that such a love story , as beautiful as any other ever told , * could * happen to you … a feeling you do n't often get from other romantic comedies , however sweet and heart - warming they may be . \\n\\n xxmaj alfred xxmaj kralik ( james xxmaj stewart ) and xxmaj clara xxmaj xxunk ( margaret xxmaj xxunk ) do n't have the most xxunk of first xxunk when she arrives in the shop ( matuschek &amp; xxmaj co. ) he 's been working in for the past nine years , asking for a job . xxmaj they clash from the very beginning , mostly over a cigarette box that plays music when it 's opened -- he thinks it 's a ludicrous idea ; she makes one big sell of it and gets hired . xxmaj their bickering takes them through the next six months , even as they both ( xxunk , of course ! ) fall in love with each other when they share their souls and minds in letters passed through xxup xxunk xxmaj box xxunk . xxmaj this would be a pretty thin xxunk to base an entire film on , except that xxup the xxup shop xxup around xxup the xxup corner is xxunk xxunk - out with a brilliant supporting cast made up of entirely engaging characters , from the xxunk but lonely xxmaj hugo xxmaj matuschek ( frank xxmaj morgan ) himself , who learns that his shop really is his home ; xxmaj xxunk ( felix xxmaj xxunk ) , xxmaj kralik 's sidekick and friend who always xxunk out of the room when faced with the possibility of being asked for his honest opinion ; xxunk pimp - du - xxunk xxmaj xxunk ( joseph xxmaj xxunk ) who ultimately gets his comeuppance from a xxunk righteous xxmaj kralik ; and ambitious xxunk boy xxmaj xxunk xxmaj xxunk ( william xxmaj tracy ) who wants nothing more than to be promoted to the position of xxunk for xxmaj matuschek &amp; xxmaj co. xxmaj the xxunk love story between ' dear xxmaj friends ' is played out in this little shop in xxmaj budapest , xxmaj hungary , in which xxmaj kralik 's xxunk xxunk and subsequent xxunk to shop manager help the two xxunk - to - be along . xxmaj it 's nice that everyone gets a story in this film ; the supporting characters are well - developed , and xxmaj matuschek 's own journey in life is almost as touching as the one xxmaj alfred and xxmaj clara share . xxmaj his xxunk to new xxunk boy xxmaj xxunk ( charles xxmaj smith ) for xxmaj christmas xxmaj eve dinner , made in the xxunk , beautiful snow of a xxmaj hungarian winter , makes the audience glad that he is not alone ; we come to care even for the characters whose love story it is n't this film 's business to tell . \\n\\n xxmaj aside from the love story , i must say that xxmaj james xxmaj stewart is truly one of the best things about this film . xxmaj he does n't play the full - xxunk xxmaj jimmy xxmaj stewart persona in this film ( c / f ' mr xxmaj smith xxmaj goes xxmaj to xxmaj washington ' for that ) ; in fact xxmaj alfred xxmaj kralik is xxunk and abrupt and not particularly kind . xxmaj he 's rather a xxunk man , in fact , with little hint ( until , perhaps , the very end ) of the xxunk - xxunk down - home xxunk charm xxmaj stewart would soon come to xxunk . xxmaj when he finds out before xxmaj clara that they have been xxunk in secret , in fact , xxmaj kralik does n't ' xxunk up -- he xxunk it out to see how far he can take the xxunk , especially since he quickly realises ( given his stormy relationship with xxmaj clara as boss and xxunk ) that loving the person he knows through the xxunk letters might not xxunk with loving the person herself . xxmaj his description to xxmaj clara of the fictional xxmaj xxunk xxmaj xxunk ( what a name ! ) who was to become her xxunk is hilarious in the extreme , but also his way of proving that the letters do n't reveal all there is to a man , just as her letters do n't reveal all there is to her . xxmaj stewart plays this role perfectly -- he keeps his face perfectly controlled whenever xxmaj clara insults xxmaj mr . xxmaj kralik , as she is often wo nt to do , even ( and especially ) to his face . xxmaj and yet one believes , underneath the xxunk and xxunk , that he * could * reveal his identity with as much xxunk and xxunk and sheer * hope * as he eventually does . \\n\\n xxmaj special mention must be given to the other members of the cast as well . xxmaj margaret xxmaj xxunk xxunk rather less well in the first half of the film , but she really comes into her own in the closing - shop scene on xxmaj christmas xxmaj eve , when she almost gets her heart broken again by xxmaj alfred 's most vivid description of her xxunk xxunk . xxmaj frank xxmaj morgan turns in a great performance as the jealous xxmaj hugo xxmaj matuschek driven to nervous breakdown , the man who has to xxunk his meaning in life when he realises that his wife of 22 years does not want to ' grow old with him ' . xxmaj and xxmaj felix xxmaj xxunk plays the role of the meek but xxunk xxmaj xxunk wonderfully ( a xxmaj lubitsch regular , since he appears as a hilarious xxmaj russian xxunk in xxunk particular note is the scene in which he helps his good friend xxmaj alfred get the xxmaj christmas present the latter * really * wants … a wallet instead of that ludicrous cigarette box xxmaj clara is so hung up on . \\n\\n xxmaj xxunk xxmaj lubitsch really does himself proud with this film -- for example , the famously xxunk and xxunk care given to detail in the creation of the xxmaj matuschek shop is well worth the effort , right down to the xxmaj hungarian names on the door , the xxunk and the cash xxunk and so on . xxmaj but even though xxmaj lubitsch chose to have the story set in xxmaj hungary , the setting is actually universal : it could happen anywhere ; it could happen to you . xxmaj xxunk lies the charm of this simple story , these believable characters who really * are * people . xxmaj the snow on xxmaj christmas xxmaj eve is real as well , or at least as real as xxmaj lubitsch could make it ( he had snow machines brought in at great expense ) . xxmaj it is this desire to make everything appear as real as possible that helps make the story even more believable , that gives this entire film a dreamy realism that can not be xxunk . ( no , not even in a remake like xxup you 've xxup got xxup mail . ) \\n\\n * this * is really the xxmaj jimmy xxmaj stewart xxmaj christmas film that people are missing out on when they talk about xxup it 's a xxup wonderful xxup life . xxmaj not to xxunk from the merits of that other film , but there 'd be no harm , and in fact a lot of good , done in watching xxup the xxup shop xxup around xxup the xxup corner this xxmaj christmas instead . xxmaj it 's sweet , funny , charming , and xxmaj stewart is xxunk in his role . xxmaj we should all be so lucky as to have the romance depicted in this film ; the best thing about this film is that we come away from it feeling that we very possibly could .</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbch.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformBlock for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def TextBlock(vocab=None, is_lm=False):\n",
    "    return TransformBlock(type_tfms=Numericalize(vocab), dl_type=LMDataLoader if is_lm else SortedDL, \n",
    "                          dbunch_kwargs={} if is_lm else {'before_batch': pad_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextDataBunch -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TextDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    @delegates(DataBunch.from_dblock)\n",
    "    def from_folder(cls, path, train='train', valid='valid', valid_pct=None, seed=None, vocab=None, text_vocab=None, is_lm=False, **kwargs):\n",
    "        \"Create from imagenet style dataset in `path` with `train`,`valid`,`test` subfolders (or provide `valid_pct`).\"\n",
    "        splitter = GrandparentSplitter(train_name=train, valid_name=valid) if valid_pct is None else RandomSplitter(valid_pct, seed=seed)\n",
    "        dblock = DataBlock(blocks=(TextBlock(text_vocab, is_lm), CategoryBlock(vocab=vocab)),\n",
    "                           get_items=get_text_files,\n",
    "                           splitter=splitter,\n",
    "                           get_x=read_file,\n",
    "                           get_y=parent_label)\n",
    "        return cls.from_dblock(dblock, path, path=path, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    @delegates(DataBunch.from_dblock)\n",
    "    def from_df(cls, df, path='.', valid_pct=0.2, seed=None, text_col=0, label_col=1, label_delim=None, y_block=None, \n",
    "                text_vocab=None, is_lm=False, **kwargs):\n",
    "        if y_block is None: y_block = MultiCategoryBlock if is_listy(label_col) and len(label_col) > 1 else CategoryBlock\n",
    "        dblock = DataBlock(blocks=(TextBlock(text_vocab, is_lm), y_block),\n",
    "                           get_x=ColReader(text_col),\n",
    "                           get_y=ColReader(label_col, label_delim=label_delim),\n",
    "                           splitter=RandomSplitter(valid_pct, seed=seed))\n",
    "        return cls.from_dblock(dblock, df, path=path, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_csv(cls, path, csv_fname='labels.csv', header='infer', delimiter=None, **kwargs):\n",
    "        df = pd.read_csv(Path(path)/csv_fname, header=header, delimiter=delimiter)\n",
    "        return cls.from_df(df, path=path, **kwargs)\n",
    "    \n",
    "TextDataBunch.from_csv = delegates(to=TextDataBunch.from_df)(TextDataBunch.from_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.model.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
