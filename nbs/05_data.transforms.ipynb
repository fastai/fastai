{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.core import *\n",
    "from fastai.data.load import *\n",
    "from fastai.data.external import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import posixpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/hiromi/.fastai/data/mnist_tiny/train/7'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/3')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path, followlinks=followlinks)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            if len(folders) !=0 and i==0 and '.' not in folders: continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7769.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7334.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7388.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/8562.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7610.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/8283.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/904.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/9886.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/9429.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/8805.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial that searches suffix `suf` and passes along `kwargs`, only in `folders`, if specified\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ItemGetter(ItemTransform):\n",
    "    \"Creates a proper transform that applies `itemgetter(i)` (even on a tuple)\"\n",
    "    _retain = False\n",
    "    def __init__(self, i): self.i = i\n",
    "    def encodes(self, x): return x[self.i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ItemGetter(1)((1,2,3)),  2)\n",
    "test_eq(ItemGetter(1)(L(1,2,3)), 2)\n",
    "test_eq(ItemGetter(1)([1,2,3]),  2)\n",
    "test_eq(ItemGetter(1)(np.array([1,2,3])),  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AttrGetter(ItemTransform):\n",
    "    \"Creates a proper transform that applies `attrgetter(nm)` (even on a tuple)\"\n",
    "    _retain = False\n",
    "    def __init__(self, nm, default=None): store_attr()\n",
    "    def encodes(self, x): return getattr(x, self.nm, self.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(AttrGetter('shape')(torch.randn([4,5])), [4,5])\n",
    "test_eq(AttrGetter('shape', [0])([4,5]), [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(list(torch.randperm(len(o)).numpy()))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_splitter(f, items=None):\n",
    "    \"A basic set of condition a splitter must pass\"\n",
    "    items = ifnone(items, range_of(30))\n",
    "    trn,val = f(items)\n",
    "    assert 0<len(trn)<len(items)\n",
    "    assert all(o not in val for o in trn)\n",
    "    test_eq(len(trn), len(items)-len(val))\n",
    "    # test random seed consistency\n",
    "    test_eq(f(items)[0], trn)\n",
    "    return trn, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#24) [10,18,16,23,28,26,20,7,21,22...], (#6) [12,0,6,25,8,15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_splitter(RandomSplitter(seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn train_test_split. This allow to *split* items in a stratified fashion (uniformely according to the ‘labels‘ distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True):\n",
    "    \"Split `items` into random train and test subsets using sklearn train_test_split utility.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train,valid = train_test_split(range_of(o), test_size=test_size, random_state=random_state,\n",
    "                                        stratify=stratify, train_size=train_size, shuffle=shuffle)\n",
    "        return L(train), L(valid)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "labels = [0] * 20 + [1] * 10\n",
    "test_size = 0.2\n",
    "\n",
    "f = TrainTestSplitter(test_size=test_size, random_state=42, stratify=labels)\n",
    "trn,val = _test_splitter(f, items=src)\n",
    "\n",
    "# test labels distribution consistency\n",
    "# there should be test_size % of zeroes and ones respectively in the validation set\n",
    "test_eq(len([t for t in val if t < 20]) / 20, test_size)\n",
    "test_eq(len([t for t in val if t > 20]) / 10, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = 'a,b,c,d,e,f,g,h,i,j'.split(',')  #to make obvious that splits indexes and not items.\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "\n",
    "_test_splitter(splitter, items)\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def EndSplitter(valid_pct=0.2, valid_last=True):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` at the end if `valid_last` else at the start. Useful for ordered data.\"\n",
    "    assert 0<valid_pct<1, \"valid_pct must be in (0,1)\"\n",
    "    def _inner(o):\n",
    "        idxs = range_of(o)\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return (idxs[:-cut], idxs[-cut:]) if valid_last else (idxs[cut:],idxs[:cut])\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = range_of(10)\n",
    "\n",
    "splitter_last = EndSplitter(valid_last=True)\n",
    "_test_splitter(splitter_last)\n",
    "test_eq(splitter_last(items), ([0,1,2,3,4,5,6,7], [8,9]))\n",
    "\n",
    "splitter_start = EndSplitter(valid_last=False)\n",
    "_test_splitter(splitter_start)\n",
    "test_eq(splitter_start(items), ([2,3,4,5,6,7,8,9], [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _grandparent_idxs(items, name):\n",
    "    def _inner(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)\n",
    "    return [i for n in L(name) for i in _inner(items,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_splitter(splitter, items=fnames)\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames2 = fnames + [path/'test/3/4256.png', path/'test/7/2345.png', path/'valid/7/6467.png']\n",
    "splitter = GrandparentSplitter(train_name=('train', 'valid'), valid_name='test')\n",
    "_test_splitter(splitter, items=fnames2)\n",
    "test_eq(splitter(fnames2),[[0,3,4,6,1,2,5,7,10],[8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "_test_splitter(splitter, fnames)\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "_test_splitter(splitter, items)\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` by providing file `fname` (contains names of valid items separated by newline).\"\n",
    "    valid = Path(fname).read_text().split('\\n')\n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write_text('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    _test_splitter(splitter, fnames)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def ColSplitter(col='is_valid'):\n",
    "    \"Split `items` (supposed to be a dataframe) by value in `col`\"\n",
    "    def _inner(o):\n",
    "        assert isinstance(o, pd.DataFrame), \"ColSplitter only works when your items are a pandas DataFrame\"\n",
    "        valid_idx = (o.iloc[:,col] if isinstance(col, int) else o[col]).values.astype('bool')\n",
    "        return IndexSplitter(mask2idxs(valid_idx))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'b': [True,False,True,True,False]})\n",
    "splits = ColSplitter('b')(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])\n",
    "#Works with strings or index\n",
    "splits = ColSplitter(1)(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])\n",
    "# does not get confused if the type of 'is_valid' is integer, but it meant to be a yes/no\n",
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'is_valid': [1,0,1,1,0]})\n",
    "splits_by_int = ColSplitter('is_valid')(df)\n",
    "test_eq(splits_by_int, [[1,4], [0,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def RandomSubsetSplitter(train_sz, valid_sz, seed=None):\n",
    "    \"Take randoms subsets of `splits` with `train_sz` and `valid_sz`\"\n",
    "    assert 0 < train_sz < 1\n",
    "    assert 0 < valid_sz < 1\n",
    "    assert train_sz + valid_sz <= 1.\n",
    "\n",
    "    def _inner(o):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        train_len,valid_len = int(len(o)*train_sz),int(len(o)*valid_sz)\n",
    "        idxs = L(list(torch.randperm(len(o)).numpy()))\n",
    "        return idxs[:train_len],idxs[train_len:train_len+valid_len]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(100))\n",
    "valid_idx = list(np.arange(70,100))\n",
    "splitter = RandomSubsetSplitter(0.3, 0.1)\n",
    "splits = RandomSubsetSplitter(0.3, 0.1)(items)\n",
    "test_eq(len(splits[0]), 30)\n",
    "test_eq(len(splits[1]), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def parent_label(o):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat, match=False):\n",
    "        self.pat = re.compile(pat)\n",
    "        self.matcher = self.pat.match if match else self.pat.search\n",
    "\n",
    "    def __call__(self, o):\n",
    "        o = str(o).replace(os.sep, posixpath.sep)\n",
    "        res = self.matcher(o)\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. Pass `match=True` to use `re.match` (i.e. check only start of string), or `re.search` otherwise (default).\n",
    "\n",
    "For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(fr'{posixpath.sep}(\\d){posixpath.sep}')\n",
    "test_eq(f(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import posixpath\n",
    "f = RegexLabeller(fr'{posixpath.sep}(\\d){posixpath.sep}')\n",
    "a1 = Path(fnames[0]).as_posix()\n",
    "test_eq(f(a1), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegexLabeller(r'(\\d*)', match=True)\n",
    "test_eq(f(fnames[0].name), '9932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ColReader(DisplayedTransform):\n",
    "    \"Read `cols` in `row` with potential `pref` and `suff`\"\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr()\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "\n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) or not c in getattr(r, '_fields', []) else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "\n",
    "    def __call__(self, o, **kwargs):\n",
    "        if len(self.cols) == 1: return self._do_one(o, self.cols[0])\n",
    "        return L(self._do_one(o, c) for c in self.cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [L('0a1', '0a1'), L('0b1', '0b1'), L('0c1', '0c1'), L('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])\n",
    "\n",
    "df['name'] = df['a']\n",
    "f = ColReader('name')\n",
    "test_eq([f(df.iloc[0,:])], [L(0,1)])\n",
    "\n",
    "df['mask'] = df['a']\n",
    "f = ColReader('mask')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])\n",
    "test_eq([f(df.iloc[0,:])], [L(0,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False, strict=False):\n",
    "        if is_categorical_dtype(col):\n",
    "            items = L(col.cat.categories, use_list=True)\n",
    "            #Remove non-used categories while keeping order\n",
    "            if strict: items = L(o for o in items if o in col.unique())\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "\n",
    "    def map_objs(self,objs):\n",
    "        \"Map `objs` to IDs\"\n",
    "        return L(self.o2i[o] for o in objs)\n",
    "\n",
    "    def map_ids(self,ids):\n",
    "        \"Map `ids` to objects in vocab\"\n",
    "        return L(self.items[o] for o in ids)\n",
    "\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_eq(t.map_objs([2,3]), [0,1])\n",
    "test_eq(t.map_ids([0,1]), [2,3])\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col, strict=True)\n",
    "test_eq(t, ['H','M'])\n",
    "test_eq(t.o2i, {'H':0,'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Categorize(DisplayedTransform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, sort=True, add_na=False):\n",
    "        if vocab is not None: vocab = CategoryMap(vocab, sort=sort, add_na=add_na)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): \n",
    "        try:\n",
    "            return TensorCategory(self.vocab.o2i[o])\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Label '{o}' was not included in the training dataset\") from e\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')\n",
    "test_fail(lambda: cat('bird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(vocab=['dog', 'cat'], sort=False, add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'dog', 'cat'])\n",
    "test_eq(cat('dog'), 1)\n",
    "test_eq(cat.decode(2), 'cat')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False): super().__init__(vocab=vocab,add_na=add_na,sort=vocab==None)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if not dsets: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsets: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): \n",
    "        if not all(elem in self.vocab.o2i.keys() for elem in o):\n",
    "            diff = [elem for elem in o if elem not in self.vocab.o2i.keys()]\n",
    "            diff_str = \"', '\".join(diff)\n",
    "            raise KeyError(f\"Labels '{diff_str}' were not included in the training dataset\")\n",
    "        return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], TensorMultiCategory([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')\n",
    "\n",
    "# if vocab supplied, ensure it maintains its order (i.e., it doesn't sort)\n",
    "cat = MultiCategorize(vocab=['z', 'y', 'x'])\n",
    "test_eq(cat.vocab, ['z','y','x'])\n",
    "\n",
    "test_fail(lambda: cat('bird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class OneHotEncode(DisplayedTransform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.c is None: self.c = len(L(getattr(dsets, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test with passing the vocab\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab):\n",
    "        super().__init__(vocab, sort=vocab==None)\n",
    "        self.c = len(vocab)\n",
    "    def encodes(self, o): return TensorMultiCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorMultiCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])\n",
    "\n",
    "_tfm2 = EncodedMultiCategorize(vocab=['c', 'b', 'a'])\n",
    "test_eq(_tfm2.vocab, ['c', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RegressionSetup(DisplayedTransform):\n",
    "    \"Transform that floatifies targets\"\n",
    "    loss_func=MSELossFlat()\n",
    "    def __init__(self, c=None): store_attr()\n",
    "\n",
    "    def encodes(self, o): return tensor(o).float()\n",
    "    def decodes(self, o): return TitledFloat(o) if o.ndim==0 else TitledTuple(o_.item() for o_ in o)\n",
    "    def setups(self, dsets):\n",
    "        if self.c is not None: return\n",
    "        try: self.c = len(dsets[0]) if hasattr(dsets[0], '__len__') else 1\n",
    "        except: self.c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = RegressionSetup()\n",
    "dsets = Datasets([0, 1, 2], RegressionSetup)\n",
    "test_eq(dsets.c, 1)\n",
    "test_eq_type(dsets[0], (tensor(0.),))\n",
    "\n",
    "dsets = Datasets([[0, 1, 2], [3,4,5]], RegressionSetup)\n",
    "test_eq(dsets.c, 3)\n",
    "test_eq_type(dsets[0], (tensor([0.,1.,2.]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_c(dls):\n",
    "    if getattr(dls, 'c', False): return dls.c\n",
    "    if getattr(getattr(dls.train, 'after_item', None), 'c', False): return dls.train.after_item.c\n",
    "    if getattr(getattr(dls.train, 'after_batch', None), 'c', False): return dls.train.after_batch.c\n",
    "    vocab = getattr(dls, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `Datasets`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7769.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7334.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/train/7/7388.png')],\n",
       " (#3) [Path('/home/hiromi/.fastai/data/mnist_tiny/valid/7/9628.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/valid/7/9919.png'),Path('/home/hiromi/.fastai/data/mnist_tiny/valid/7/7334.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = Datasets(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class IntToFloatTensor(DisplayedTransform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 10 #Need to run after PIL transforms on the GPU\n",
    "    def __init__(self, div=255., div_mask=1): store_attr()\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.long() // self.div_mask\n",
    "    def decodes(self, o:TensorImage): return ((o.clamp(0., 1.) * self.div).long()) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiromi/.local/lib/python3.8/site-packages/torch/_tensor.py:1051: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor()\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@docs\n",
    "class Normalize(DisplayedTransform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    parameters,order = L('mean', 'std'),99\n",
    "    def __init__(self, mean=None, std=None, axes=(0,2,3)): store_attr()\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "\n",
    "    def setups(self, dl:DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch()\n",
    "            self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [IntToFloatTensor(), Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.LongTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.float().mean()/255.<1\n",
    "assert 0<xd.float().std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "nrm = Normalize()\n",
    "batch_tfms = [IntToFloatTensor(), nrm]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.9, x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAI00lEQVR4nO2bW2wcVxmAvzMze7/ZXl/Xjm+NkzRtk7RJCU0aEUpbVS0vpYCEBBSoeEZ954U33nngrYI8IJWKm1ABqYQ2TUsDadXmUtupHSdOnHV89168O7szZw4P29jxxEns2N5dofmklVZzds7599O5zLmMUErhsYJW6wDqDU+IC0+IC0+IC0+IC0+IC0+Ii5oLEULkXR8phPhVreIxalXwLZRS0VvfhRBR4CbwVq3iqXkNcfEKMA2crlUA9SbkVeCEquF8QtTLXEYI0QOMATuVUldqFUc91ZAfAB/UUgbUl5AfAr+tdRB1IUQIcQTopIajyy3qQgiVzvSPSqlcrQOpm061XqiXGlI3eEJceEJceEJc3HNy95z2nf/bHvcd5y2x1nWvhrjwhLjwhLjwhLjwhLjwhLjwhLjwhLjwhLjwhLjwhLjwhLjwhLjwhLjY9N6uFokgejqxG8PkeoJIn0AGgDUn1xCcd4jcMDFm86iJSVS5jLLt9Qfc1YmKR3ACPtAFSIWQEnE1jcxmN/t3tkBIazPpZ5rJDDi8/uzf2R1I82Qgg0+sXfl+PvU0fz19iKbzYVrfKaFyOeRiZn2FCcHSvhSZfh+lBDgBhVYW6CXY8RcLaiFEGAZaYyMiFsHsTTLf4yd7uEhfxxz7Q+N06nniWhj9LkKOxEa48GiKsVgrZnM3WgkMUyEkCFn5bpiKclTDDq++VwnI7FKItiKhcImQYWNJHdP0sTDRQkM4AJev4+QefDdj40JCIZzednK9YdLPOnT2TPHu3hM0a34CwgDC97z/lcgCLz/8J2Z3FUk/48dSOmV05mWUOTvKmexDDC208WLHMF+PDd5x/w49T4OmERAGuqi0yxlZ4ljxZ+Q7G9iRL0I1hWjRCFP7ouS7BY/tGedgwzUSmo5P6AA4KCwlmbLLXCi3EtdMUkaOBg2SWqiSB4KYZpCijAVIBUmtSMpYwCdsekJzHApfYYeev6P8Jl0nKAwMKuXZyEpCWcMwQUjnAVVU2LAQ1ZRg7qjF7t5J3uj/A41aCAgsp1tKknHKnC118sbE03SGMxxJjLInkCa58jNCwk9I99+R/0H/NJUjInC/2narvJICraDjzyqw1t9Br8XGm0zBJDSW5It8Fy8Wf4Rfl6vSbUejWPaRnYsQHvVzJaL4V8vD6DGL9qYsjzRN8lLjOYLCIqhZ6y43LkoEhCRlCKJixeyYDYOlHUSuayQuF1D5O2vVRth4DVnM0vZxKzIg4GTjHelBWxG2FKnpAs75T9ETcUi1YieCmC3NnDrYxszxKAm/ScJXXFeZOg7tgQwtRo5joTGiX0btoPjM7OJ0ZjfJQQvx4WfIe2d1XzYupFgkNL6I0vU104VSYEtEvoDjSFSxiDa3iG8pgJ4N00qckfwAjg5qHaWXmhycmM1jAxMcS45gqpW+qqDK/C59mEtjHeyaNzf6V9Zkw0Ic04ShkQ393rm5EmzoIoQ2UuBX95HtD/N5sIOB6DRmpCLEUpKcI/liqIuWsxrG9DSb6z0q1PwU4l0RAmH4WBiIMPu44mDvNZ5JDNKmlwGDUdthuNxJ5IpO42AOldmakxR1K0ToOsLvI7NT8OThS/y0/RTHgxYQxkExWOrg37mdNI7Y8N8Lm+47blGfQoTAfO5x5h7zkTx8k2+1fEK/kQHCTMoCU9LPL85/E+dSlP7xDJt78lhN/QkRAqHrTB/0ceili7za+uFyzQBIywCDpU58H8XoPLmAGE9vafF1J8RIdSDbGyn2lfl288fLNQMqI8uJ2ac5NfEQDVcl4uYcTnFrRpfl8rc0ty3AaU6Q64+S6pzhpXCe259WHRw+TPdhnW8gMp5BTk3fPaMHpH4WiDQdEQiw+EiCya/BkdbVx1UnZYGLZcXijTiJywp9YWl7wtiWXB+AyqjiJ7dD48C+MY7GVj/rzEofI+U2glMG8SsmKrc9QuqmyejtrVhdSZYesngtdZq9vllu7zteH/0u18910HXWwj82tak1j3tRN0KcxihLXUGaOhZ4IVTg9r7DUpLxS+10n5RELqSxb2ztyHI7NRdidLQjU0muPZ8gfHSWn/R/tCr9N9kUJ+cfJjGkEx6dwclsfpnwnvFsa+7rQDXEWOqOYu4t8uu9v6fXWBlZbCSnFndxZrSPrgkbdeMmjlna1nhqJ0TTET6DhQNJpl4o8+KeQfb4lgiLSkhvF6Kczu3mPycfoecDm/DwTWyzBGorn0vvpGZCbo0qSymNF/YO8nzDheUlRoDzxW5OTe4keVER+Oen2FJCFY6h10aIEOhdHZj9zeR2WbzW/D4pvQyEsZGYyubNy0+gvddA02gWVSUZUAshXzYV2RQl2+0n1rbIAb+xHErGKTMnBfnJKH1DZfSZDHYVX1CouhC9v5v8oy2kj+q8/I0zHI8PAVBUZXKOzfeGv8/Uv1P0nLUInru27aOKm6oLcRJhcl0GkYEFftn2yfL1gpLMOzrjV1vo+6BEaHQGexvmKvej6kLKyRCZAYcDTbOrrr9XTPHnmSeIDfsInhvZtifR+1F1IXZYQyRLpEIrTcFBMWq2c3GmndCMQs7MVDusZaouJN+u8+N97/NUpDJ5y6sS81Ly5tgTGP9ooOHS5vZVNkv1ZruajhYMYsUET0VG6DUqO/4ZRzJux8nORkhcsdDnayukajVE7+8mu7+V/O4yu30ZYlplO+HE4iFODH6F5BkfoY8voZYK1QppTaomRIUDFFo1/LEiMa2yYQ0wa0WxFoMEMg5ybr5a4dyVqjUZJ+ij1CCIR0zCwr+8e388Psyx/cPkU2vvBFabqglRuoYywNAl2m3nrYLCIm6UUPXho/ZLiH9b3MfbZ/cTH9+qrabNUbU+RLMdtDKULAMbiVQKB4erS0lCaQN/ZnvXOdZL9UaZmQzJz0Nc60uQ3l9ixglw3WrlwlA3A+8W8E3Mbclm9WapXpOxJb4lG1EWWAgKToBFGUYzNYyFAqqwtRtOD4r37r+Lmneq9YYnxIUnxIUnxIUnxIUnxMX/AJQ8Tm+Il9iZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAF8ElEQVR4nO2bzY8bZx3HP88zMx577LXX9u7GyXo3TTZpmzZNK6SkSQUHDhxAHBAIceFF4tBz/wr+AQ5whB5biSsURFooLWoKlECbNmWTJd0ma6/XO16/j8fzPBwWZ6VRG5UXz4ya+UgjWaORfl999Ph55nkZobUm5QgZd4CkkQoJkQoJkQoJkQoJkQoJkQoJEbsQIUQ/dAVCiB/HlceMq/AMrXVh9lsIUQAawMtx5Ym9hYT4FrALvB5XgKQJ+QHwoo5xPiGSMpcRQpwEbgNntNZbceVIUgv5HvCHOGVAsoR8H/h53CESIUQI8RywSoyjy4xECOGwM/2F1roXd5DEdKpJISktJDGkQkKkQkKkQkI8cHL3Ffntz22P+xv1svik+2kLCZEKCZEKCZEKCZEKCZEKCZEKCZEKCZEKCZEKCTG3fRljeRn/sVW0JQlsAzlRGKMpRs9DHvTh3+swut8n6BzMK8Z/zNyEjJ9eZ/uHAYvFPqcW22z3FmnslLG381RuLN5/rnSzC399CIQoW7JU7nCquM+lxS3uOmVuOse4VarSLC3cf65fX6R0+llyTQ9rp4Ped2NtMXMTMs1JzlcaXC7e4puF21hCIlckakMRPHs0iX5rXOSNwaO8eO05lt84TuV6Ht75HApx7o25+seneG3lLK+sb1PODFnLutjSJyumLJtdTlgujWkJiaZW36dxuco0W2Qp+zTW9h7Tew3Q6n5/EwUPXGT+n9ZDhECYFvLUGgfPLDOqCgarENgQFAJyy0PO13bIGj5F0+NKcZMv5e7w/OZ32PzLGvVXA3KvvoeeTNDT6X8d49P4tPWQ+e3+a432J+B2KfzTwd7PkHUtgowgsA28UpHr5QWUBYGtuX2hyuq6y5OlHYZPZWg3j3OitYFxp0nQ3J1bzDBzPw4RtFrQamEJgTW7KY5ef4xCHpF3uP38aX75jQt8bfE6P6q9xRXvu+wEVU5oIEIh0b2YaX10qeD+pUZjVH9A6ZbipWsXeal9iVbgcbH2EZPLPdzHC5j1VaTjRBIz9jdV7U9QvR7V1+9y9mcTfv23J7npl3hh5bf8/spPaV1UjB+tIcuLkeSJXcgM3e1jNTpkP8rwk3tf5sakRkFYOPU+rWdsglo5khyJERK4LtOtO1TeD3jnz2d4s3cGR2b46iM3UF88YFjPR5IjMUJmZLoB2aZkZ1yKpX7ihNj7HoWPNTvDIoFWKP2JrwtzI3FCtCFQJphSxVI/eUKkQBsgiWfTMHFCpDfFGmq8IJ4jtIkTIrwAa6gYT1MhAEyO5elsmNQXOrHUT5yQccVkUFfUnU4s9ZMnpCzJnexxNtfEEBIpou1cEydkUhQ8sdJgzWrHUj9xQoIcnFtoUDX6eNrnT+11vA+L2Pt+JPWTJ8TWbNhN8sJnrKfsuEXy9wRmz4ukfuzfy8wwymVEuYRfVqxaLq/0z/PBoIb19gLHf+ciPm5GkiMxQkQhj3+sBPkpy8aADwY13rxzipXNAHX9/chyJEbI6FyNxqUMTzyyxZpxOI/xPRPpP6SjzGjJZLThcaF0l6LMAqAnEqEeUiFh3t07TuFmBntvHGndxAjREqSpkEKj0Bz0szhNjdGPZnSZEXsfIh0H4eRwHxO88IWrnLabfOhPUHcdyn/vQsuNNE/sQkTGOhxhKoqvF97jQFk0ggJWV2LsuqjBINI8sQthZYnBmQrW0ohjRoZ/+HmuDTfIdCDYa6P9//825oOIvQ/Rjs2oapLPedjCpKMctoZLmCON9rzDDa0IiV2IX87SWxecKHYBeO3gHFdvPE5+N1oRM2IXMs0a+AuaonU4vO6OCxiuiTF6SBeZvbIB6yNO5/fijgIkQIgyBTnHY8E4bCETZSJ9gZymq+4AbLaWqLyryTSjHW5nxC7EHGt6rsPbnZP8auQw2nXItabIwSiWPPM7UvUZMaoVWKqgHBvlWJi7XWi1UYPR4QmkORH9karPSNDeh/Y+AAKIZ7A9Iva/TNJIhYRIv/0PkbaQEKmQEKmQEKmQEKmQEKmQEP8Chfkvo8G/RJgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAIIElEQVR4nO2bW2wcVx2HvzMzu7Mzu7POepN1fFs7t16iRCpRK3p7AKogoT62RULcHnhB4pV3XpGQQIJnkKjKQ9UKCaECopVQaYla9ZbQpM3VcWyc2Ltee++zszNzDg/GaTNFSQq7OxuYT7Jk2Z6Znz/9Z87/nDMrlFIkfIIWd4BxIxESIRESIRESIRESIRESIRESIXYhQoh25CsUQvwirjxGXBfeRSmV2/1eCJED1oGX4soTe4VEeAaoAG/EFWDchHwXeF7FOJ8Q4zKXEUIsAEvAYaXU1bhyjFOFfBt4M04ZMF5CvgP8Ou4QYyFECPE4MEuMo8suYyGEnYfpb5VSrbiDjM1DdVwYlwoZGxIhERIhERIhEW47uTupPfc/+8R9Vb4k/t3PkwqJkAiJkAiJkAiJkAiJkAiJkAiJkAiJkAiJkAiJkAiJkAiJMLqdO01Hy5ig6wjDAE2AEFAsEOy9uXlHYOlIU0N3JboXYmy2Ec02stFEdrtDjzkyIVrWRisWUGYaaZtgaMiURvVElvpD/Zt/Vyi1ODy5ycfVKdo1m4kzJQqXCtgfryOv3cNCtEwGrbAHlbMJizk6UxmaZYPQgsACpSuUBn65x/GF6zePO5KrcNCqUjLbrEwWOGdO0y5n2J+bIW9nYG2DsNkcVuwhCinswT0+R2s2xfZRsI/U+dHRV5hP1bg/FaCzsxyhoaGLT5YmtH891uTEEgDhIYWnAh6e/gHu5F6m3gDuJSEilUbL5+gdnWXlZIqw6DM/W+PY5A0czaUe2rwZ6nSkST3M4isdqTQudPez1C7ihQZeYLDX6lAwu3xr3ymezPSQ7RR2VSJcb9CRb2HgQrSshSxPc+Mxkz98/SdMauBoaaqhx2U/z6nOEV6vHqHaydJs2UhfQwWC3Pk0xY98Uk0fp+VRO7iPlSmN1jdNnjz4R8yKjvPhOrK2PejItzD4W0ZooAuUDo5Q2CINwO/aD/LzD79Mv5bBum6ge+C4IEKFCMFZ87FWWoieh+j1kffl8SYFhbQLgEyDylmI7dTAI3+awQvRBMrQkIbC0Qx0IeipgF9deYzFn4GxsUGwvPLZ45RCAgiB0HX8bJnugs+CVQMgsCX9okWmmhl45E8zcCGq76Nvd8ls5niheQhb8/CVwdb6BPs3KqhmC26zW2gslvFnCmwdU3zx2BUetndeBjA6GulqB9V1Bx351usP+oTKdRE3KuRXi/xy6QlMI0ATCvtqaqcy7rB16h7ZR+VEmhOPXuA3i68BEADphoCra0j3XhMShkjPI3u1TfO1vXgaCAX7Lvp3lAEQmhp+VuEYO6PJStBlNcyhu0AYouRwd0YG/wxRCuV5cOY8MxczEIbIvg9K3tXhgaXh5xV7Ujtd6QW/yNudQ6Q6CuUHd32e/5Thte5KonZFKHnH6hCpNCKdolvScBa2mc9s0VYez288xVuXDlK+HqDC8K6q7L9heLNdpVB+HxUEd/VPiIyJlnfoTim+Wj7PwXSFhgx56/IBiq+nsZcbIMOhxd0l9vdUd1GHy9SOOnBfh5P5s+hCcr5fQAUaSge3PIFpH0OrdxAdF7ldR/Z6A88xNushnQM5qo/AUwcv8pTlkRV9lvolCATSgPaMwfZRB29hknB/EWFZQ8kx8grRHAetWKB7f4mtB9P08+DnJeaBFl+ZW+bpwmkA5gyXjLXEs4+8y/uH5vECg0BqLK0VMGp5Fl9JY5wOUK67c1sOiNELyWXxpwtUv5Bm+uQqj+9d4mvO35nSXfbpBqZIAYJp3WZahx9PvQdT7xEQ4quQFw8scqpxmLMfHWfv5Sxhvw/3shDlZOnOZugsBHxv7k0WU5ssGC62pmOKFNuyRy0UVKXNVpjjkjfFujfB29VFKvUc+sc57BuK0ultZLO1MxQPkNELsU3cokZ2qskzuU00BGDf/H1dwrWgwEe9WVa8Sd7fnGej7qCdyzGxqth3qkJ44TLD6kZGf8tU60yeS1PT8txX/T7HH1jlh/N/YtFoM6vbvNw4wcvLD9E+N8nEJUh1FSVPYVW66I0ebFSHmm/kQuR2nbSUlDpF8is2Z4MFzpdmyIplZnV4t16mdX6S+b/4pP787q3HjiDf6G+Zfh/ZaKIDlh9COMGX7Es4QuEqyZlrc8z9NSSzVGP4bdhnGb2QINgZJoXYaYLUHg4ZFq7q05IBomKSO72KbAxv3fR2xNapitn9tI4WMUo70/kXmod4ce1hJi4K5NY2qt+/wxmGQ2ydarjHpjlvsCe/M6t9p3mAaxf3k90Ikd3uQJutz0NsFVJ/IEfu6XWenX8fgA8qsxTf07BXm8T5Lmg8FSIEvaLgG+V3eNS6gkTRbFs4K330rXYskXYZeYXoxUnUdInutOIJ6zIhgg/6AlkzMdcbqPbwtytvx8grRFgWQdEicEJmjAAdxfWggO5qaO0u+PE8THcZuRA1kaM1b5Iq9JjQ0jSVyVl3jnRdINcryHZn1JFuYfR9SErHzwpMM8AUKXoyRaXvoPcYyoLP5yX2BaIL3gx/u3GAdGM8PmcQmxClBKGSbAY5Gs0sRu//XMguZ+pzmGctsut+3FGAMRDS8k3SLdB7cUzlPkvsQsaN0QtRChGA7+tsS5eun0IECoa8RXm3jFyI1ujgrAXI5Sw/3XyM9atFnH+EGFvx9h+7jL5CvD6pRp9MVfDq2gNk1g3S9T6iN9xXpe6WkTdmYXUTvdGkfNVB/d6h1F5G1huE/fEYZWJbMZPdLqxvjPrydyT57H+EZNiNkAiJkAiJkAiJkAiJkAiJ8E+pm1CCR7aSuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "x,y = cast(x,Tensor),cast(y,Tensor) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(1,1)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 01a_losses.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 10b_tutorial.albumentations.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 18b_callback.preds.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.image_sequence.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted dev-setup.ipynb.\n",
      "Converted app_examples.ipynb.\n",
      "Converted camvid.ipynb.\n",
      "Converted migrating_catalyst.ipynb.\n",
      "Converted migrating_ignite.ipynb.\n",
      "Converted migrating_lightning.ipynb.\n",
      "Converted migrating_pytorch.ipynb.\n",
      "Converted migrating_pytorch_verbose.ipynb.\n",
      "Converted ulmfit.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted quick_start.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
