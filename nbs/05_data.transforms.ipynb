{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.data.load import *\n",
    "from fastai2.data.external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [/home/sgugger/.fastai/data/mnist_tiny/train/3,/home/sgugger/.fastai/data/mnist_tiny/train/7]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [/home/sgugger/.fastai/data/mnist_tiny/train/3/8055.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/9466.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/7778.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/8824.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/8228.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/9620.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/8790.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/7497.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/7383.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/9324.png...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`, only in `folders`, if specified.\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return train_idx,valid_idx\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(10))\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o, **kwargs): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    valid = Path(fname).read().split('\\n') \n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o, **kwargs): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat): self.pat = re.compile(pat)\n",
    "        \n",
    "    def __call__(self, o, **kwargs):\n",
    "        res = self.pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp = re.compile(f'{re.escape(os.path.sep)}(\\d){re.escape(os.path.sep)}')\n",
    "f = RegexLabeller(regexp)\n",
    "test_eq(parent_label(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColReader():\n",
    "    \"Read `cols` in `row` with potnetial `pref` and `suff`\"\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr(self, 'suff,label_delim')\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "    \n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "    \n",
    "    def __call__(self, o, **kwargs): return detuplify(tuple(self._do_one(o, c) for c in self.cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [('0a1', '0a1'), ('0b1', '0b1'), ('0c1', '0c1'), ('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False):\n",
    "        if is_categorical_dtype(col): items = L(col.cat.categories, use_list=True)\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsrc):\n",
    "        if self.vocab is None and dsrc is not None: self.vocab = CategoryMap(dsrc, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): return TensorCategory(self.vocab.o2i[o])\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = DataSource(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = DataSource(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "        \n",
    "    def setups(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsrc: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], tensor([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): self.c = c\n",
    "\n",
    "    def setups(self, dsrc):\n",
    "        if self.c is None: self.c = len(L(getattr(dsrc, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab): self.vocab,self.c = vocab,len(vocab)\n",
    "    def encodes(self, o): return TensorCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dbunch):\n",
    "    if getattr(dbunch, 'c', False): return dbunch.c\n",
    "    vocab = getattr(dbunch, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `DataSource`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [/home/sgugger/.fastai/data/mnist_tiny/train/3/8055.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/9466.png,/home/sgugger/.fastai/data/mnist_tiny/train/3/7778.png],\n",
       " (#3) [/home/sgugger/.fastai/data/mnist_tiny/valid/3/957.png,/home/sgugger/.fastai/data/mnist_tiny/valid/3/9073.png,/home/sgugger/.fastai/data/mnist_tiny/valid/3/8939.png])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = DataSource(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEeUlEQVR4nO3bX4iNeRzH8dfPUNQQZUZpUDY1tWVTwlJMLuzFElLaDRfKjVwgN1yIGtSUq73YG4mylCxJoVxoL5a4WDdM1rZhS4iQKeTPevZi9pkz85vDnDHnzHPW/t51Ouc5v/M8z7fP+Tzf3+/3/T1PyLJMosSIogOoN5IgEUmQiCRIRBIkIgkSkQSJKFyQEMJPIYQHIYSuEMIfIYQNhcZT9MAshPAl/syy7HUIoRW/4Nssy34rIp7CHZJlWWeWZa/zzX9fXxQVT+GCQAjhxxDCS/yOBzhXWCxFXzI5IYQGfI02dGRZ9raIOOrCIZBl2d9Zlv2KFmwsKo66EaQXI/1fc0gIoTmE8F0IoTGE0BBC+Abf42JhMRWZQ0IITfgZX+n+c/7CD1mWHSgspnpJqvVCPeaQQkmCRCRBIpIgESMHaP+cM24o92VySEQSJCIJEpEEiUiCRCRBIpIgEQONQ4aNFy9egIMHD4LNmzeD1atXg2PHjoGGhoaaxpEcEjHQ9L+mI9VLly6BV69e6ejoABcvlq8NdXZ2gtbW1mqdPo1UK2FYc8jjx4/BkSNHwI4dO8C7d+8G3PfGjRuoqkPKkhwSMSw55OjRo2DXrl3gzp07fdonTJjQ8/nZs2d92qZNmwZu3boFRo0aVY2QSDmkMoYlhzx58gT9nbF+/XqwdetW27dvB+fO9V3F3LZtG6rqjI+SHBIxLA7ZtGkTuH79Oli2bBlYsmQJaG9v7+eMsWPHgqVLlw5HiD0kh0QUMlK9ffs22LdvHzh06FBP2/jx48G1a9dQ6mVqQOplKqEQhzQ2NqJ7DhOTz2UWLVpUi1P3JjmkEgpxyJgxY8CbN2/6tU2cOBFs3Nh9z8zixYvBggULUNV6SHJIJdSdQz7EnDlzwP79+0FLSwuG1AuVdUghgty8eROcPn0aLF++vKft8OHD4OrVq332uXfvHrh79y5YsWIFOHny5KeGkS6ZSii0hDgYnj59Ctra2lCaMOZOyi+hQZAcUgk1cUh+zPx9xIjq6Z47Yv78+dBTNti7d+9gD5UcUglVnf6fOXMG3L9/H6xcuRJMmjSpauc4e/Zsn+0LFy7gkxxSluSQiKrmkNmzZ4OmpiZw/vz5T42rHw8fPgSzZs0Cjx49ApcvXwZz584d7CFTDqmEquSQK1euoLTcmI8VhsL79+/B7t27wYED3Xd7587I89LkyZOHfK7eJIdEVMUhM2fOBFOnTkXJMevWrQM7d+7s8/sZM2agNC95+7b0rFC+zJkf40OL32vXrgVTpkwZcvy9SQ6JqGovs2rVKpRmsR9izZo14NSpUyhfSozJC0fHjx8H8+bNA6NHjx5MiL1JvUwlVNUhXV1dKN3+1N7eDp4/f47KnJDPe5qbm1Fy3ZYtW8D06dMHE9LHSA6phGGph+Q3u+zZswecOHECLFy4EGzYUHq6fdy4cSgtd9aQ5JBK+M9UzGpAckglJEEikiARSZCIJEhEEiQiCRIxUD2kbF/9OZMcEpEEiUiCRCRBIpIgEUmQiH8AXEReOybNeDQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Cuda(Transform):\n",
    "    \"Move batch to `device` (defaults to `default_device()`)\"\n",
    "    def __init__(self,device=None):\n",
    "        self.device=default_device() if device is None else device\n",
    "        super().__init__(split_idx=None, as_item=False)\n",
    "    def encodes(self, b): return to_device(b, self.device)\n",
    "    def decodes(self, b): return to_cpu(b)\n",
    "\n",
    "    _docs=dict(encodes=\"Move batch to `device`\", decodes=\"Return batch to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cuda.encodes\" class=\"doc_header\"><code>Cuda.encodes</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.encodes</code>()\n",
       "\n",
       "Move batch to `device`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.encodes, name='Cuda.encodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, like all `Transform`s, `encodes` is called by `tfm()` and `decodes` is called by `tfm.decode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Cuda()\n",
    "t = tfm((tensor(1),))\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.cuda.LongTensor' if default_device().type=='cuda' else 'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cuda.decodes\" class=\"doc_header\"><code>Cuda.decodes</code><a href=\"__main__.py#L9\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.decodes</code>()\n",
       "\n",
       "Return batch to CPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.decodes, name='Cuda.decodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm.decode(t)\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): \n",
    "    def encodes(self, x): return x \n",
    "    def decodes(self, x): return Int(x) \n",
    "    \n",
    "start = torch.arange(0,50)\n",
    "tds = DataSource(start, [A()])\n",
    "tdl = TfmdDL(tds, after_batch=Cuda, bs=4)\n",
    "test_eq(tdl.device, default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IntToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 20 #Need to run after CUDA if on the GPU\n",
    "    def __init__(self, div=255., div_mask=1, split_idx=None, as_item=True):\n",
    "        super().__init__(split_idx=split_idx,as_item=as_item)\n",
    "        self.div,self.div_mask = div,div_mask\n",
    "\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.div_(self.div_mask).long()\n",
    "    def decodes(self, o:TensorImage): return o.clamp(0., 1.) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor(as_item=False)\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    order=99\n",
    "    def __init__(self, mean=None, std=None): self.mean,self.std = mean,std\n",
    "    \n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "    \n",
    "    def setups(self, dl:DataLoader): \n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch() \n",
    "            self.mean,self.std = x.mean(0, keepdim=True),x.std(0, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [Cuda(), IntToFloatTensor(), Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.after_batch.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.FloatTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.mean()/255.<1\n",
    "assert 0<xd.std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "batch_tfms = [Cuda(), IntToFloatTensor(), Normalize()]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai2.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAHAElEQVR4nO3dPYjU2x3H4XO8W7hqJSYopJE0alwjK4giSBRBIaCFLyR9QANiYWdnG1ZBgtgIFpLO1cIijRAFg51Whg1LYHerayGrqESuQf8p8gIhO2dwRp3vLM8Dt7j+ODOH6/14Vo//2dp1XQHyrBn1BoCViRNCiRNCiRNCiRNCiRNCiRNCiXOVqLX+odb6fa31Ta11vtb6m1HvieFUfwlhdai1/qyU8reu636otW4rpTwqpfyy67qno90Zg3JyrhJd1/2l67of/vOv//7npyPcEkMS5ypSa71Ra/17KeWvpZTvSyl/HPGWGIIva1eZWut3pZT9pZRflFJ+13XdP0a7Iwbl5Fxluq772HXdn0spPyml/HbU+2Fw4ly9Jorfc441ca4CtdYf11p/VWvdUGv9rtZ6tJTy61LKn0a9Nwbn95yrQK31R6WU2VLKz8u/fsFdKqX8vuu6myPdGEMRJ4TyZS2EEieEEieEEieEmmgNa63+tAi+sq7r6ko/7uSEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUBOj3sCgJibaWz937lzP2bFjx5pr161b15wfPny4OYcvwckJocQJocQJocQJocQJocQJocQJocb2nnPHjh3N+bVr1wZ+7du3bzfnu3btGvi10719+7bnbGFh4RvuBCcnhBInhBInhBInhBInhBInhKpd1/Ue1tp7OGL9rjOePXv21d671tqct/6bfm3D7m15ebnnbO/evc21i4uLzTkr67puxZ80JyeEEieEEieEEieEEieEEieEEieEGttHxubn55vz3bt395zt3LmzubbfR2fu2bOnOd++fXtznmzjxo09Zxs2bPiGO8HJCaHECaHECaHECaHECaHECaHECaHG9nnOUep33zc5OfmNdvL/Xrx40Zz3e55zaWmp5+zAgQNDvTcr8zwnjBlxQihxQihxQihxQihxQihxQqixfZ5zlN69ezfUvGXt2rXN+d27d5vzNWvav95++PChOb9x40bPmXvMb8vJCaHECaHECaHECaHECaHECaHECaHcc4Y5ffp0c3706NHm/NOnT835zMxMc3716tXmnG/HyQmhxAmhxAmhxAmhxAmhxAmhXKWEOXny5FDrX7161Zxfv359qNfn23FyQihxQihxQihxQihxQihxQihxQij3nCOwf//+nrMjR44M9doXL15szn285fhwckIocUIocUIocUIocUIocUIocUKo2nVd72GtvYcM7N69ez1nx48fH+q1JyZcXY+bruvqSj/u5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQLsVG4OnTpz1nJ06cGOq1+32Lv9a9diml3L17t+dsbm6uufbNmzfNOZ/HyQmhxAmhxAmhxAmhxAmhxAmhxAmhPM85Aps3b+45u3//fnPt9PR0c17rio8G/le/e86WhYWF5vzJkyfN+ePHj5vz2dnZnrPXr183144zz3PCmBEnhBInhBInhBInhBInhHKVEqZ1zVJKKVNTU835pUuXmvODBw9+9p6+lH7XPA8fPuw5O3PmTHPt8vLyQHtK4CoFxow4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zlWm37cA3LZtW3O+devWnrOTJ0821546dao5n5ycbM5b/y8+evRoqPdOfuTMPSeMGXFCKHFCKHFCKHFCKHFCKHFCKPecfDGbNm1qzi9fvtycnzt3buD33r17d3P+/PnzgV/7a3PPCWNGnBBKnBBKnBBKnBBKnBBKnBCq/fAffIZ+n0u7d+/egdd/+PChufbjx4/N+ThyckIocUIocUIocUIocUIocUIoVyn8j9ZHY+7bt6+59ubNm815v4/GfP/+fc/ZhQsXmmvn5uaa83Hk5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ7jnDbNmypTmfmppqztevX9+cnz17tjmfnp7uOdu4cWNzbT/z8/PN+czMTM/ZrVu3hnrvceTkhFDihFDihFDihFDihFDihFDihFC+BWCYBw8eNOeHDh1qzvt9PGXr53tYs7Ozzfn58+eb85cvX37J7YwN3wIQxow4IZQ4IZQ4IZQ4IZQ4IZQ4IZTnOcMsLi4Otf7KlStDrV9aWuo5u3PnTnNtv3vKr3nHuho5OSGUOCGUOCGUOCGUOCGUOCGUOCGU5zlhxDzPCWNGnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBCq+dGYwOg4OSGUOCGUOCGUOCGUOCGUOCHUPwHAx0t3DlZJ7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAH5klEQVR4nO3dT4hd5R3G8feNEVyMfyJMJ4vipqLFLIJIEgsJlATsooi4CLYqohCQCi5EUMSFiAvJxkXBioQslOJC60KEZmNiIIMLISjIaKhRKYoOIhGHUJHYnC5ahcDc39WZJve5N58PuDAPZ+ag+c5J8mbu7cMwNCDPhknfALA6cUIocUIocUIocUIocUIocUIocc6I3vtfe+9f9N5Xeu//6L3vm/Q9sT7dX0KYDb33La21k8MwfNd7/3Vr7Whr7ffDMByf7J2xVp6cM2IYhqVhGL774V//98+vJnhLrJM4Z0jv/S+993+11k601r5orf19wrfEOvhl7YzpvV/SWvtNa+23rbX9wzCcmewdsVaenDNmGIZ/D8Ow2Fr7ZWvtT5O+H9ZOnLNrY/N7zqkmzhnQe/9F7/0Pvfe53vslvffftdb+2Fo7Mul7Y+38nnMG9N7nW2t/a61tbf/9gvvP1tqfh2E4MNEbY13ECaH8shZCiRNCiRNCiRNCbazG3rs/LYLzbBiGvtqPe3JCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCqPItAGfVnj17yn3Xrl3lvnPnznLfvXv3z76nH/S+6rvB/WgY1veujIcOHSr3t956a+T28ssvl9d+9NFH5X727Nly51yenBBKnBBKnBBKnBBKnBBKnBBKnBCqV+dmvff1HapN0D333DNyO3DgQHnthg3116x33nmn3I8cOVLu77777sht3Dnn1q1by32czZs3l/stt9wycltYWCivPXz4cLnfeeed5f7VV1+V+6wahmHV/+menBBKnBBKnBBKnBBKnBBKnBBKnBBqas855+fny/39999f09Zaa48//ni5Ly4ulvs0u+KKK0Zue/fuLa99+OGHy/3bb78t95tuuqncZ5VzTpgy4oRQ4oRQ4oRQ4oRQ4oRQU/vSmONe3rJy++23l/upU6fW/LGn3crKysjt4MGD5bUff/xxub/xxhvlfuONN47cxn2b3izy5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQU3vOefTo0XJ/5plnRm4X8znm+XTs2LFy//rrr8v9mmuuGbk55wRiiBNCiRNCiRNCiRNCiRNCiRNCTe055/Lycrk//fTTF+hO+MH9999f7ps2bSr3Dz/88P95O1PPkxNCiRNCiRNCiRNCiRNCiRNCiRNCTe05JxfeI488Uu5PPvlkub/22mvlPu6tGS82npwQSpwQSpwQSpwQSpwQSpwQSpwQyjnnRaZ6D8zWWnvxxRdHbtddd1157XPPPVfujz76aLlzLk9OCCVOCCVOCCVOCCVOCCVOCOUoZRW993K/+uqry33Lli3lfu21147ctm/fXl67sLBQ7nv27Cn3ubm5cl9aWhq53X333eW1r7zySrnz83hyQihxQihxQihxQihxQihxQihxQijnnKsYd4755ZdfnrfPPe6MdRiGdX38cdd///33I7fPPvusvPbSSy8t9zNnzpQ75/LkhFDihFDihFDihFDihFDihFDihFC9Ovfqva/vUG1KXXbZZeX+4IMPnrfP/fbbb5f76dOny3337t3lPu77Qe+9996R26ZNm8prP/nkk3J/6qmnyv2FF14o91k1DMOqh9uenBBKnBBKnBBKnBBKnBBKnBBKnBDKOSfnuPzyy0dut912W3nts88+W+7jXjN3eXl55HbHHXeU1y4uLpZ7MuecMGXECaHECaHECaHECaHECaHECaGcc3LBPPbYY+X+xBNPjNxOnTpVXnvrrbeW+/Hjx8t9kpxzwpQRJ4QSJ4QSJ4QSJ4QSJ4RylEKMbdu2jdzefPPN8toPPvig3Hfs2FHuZ8+eLffzyVEKTBlxQihxQihxQihxQihxQihxQijnnEyF559/vtz37dtX7vPz8+U+7lvSzifnnDBlxAmhxAmhxAmhxAmhxAmhxAmhNk76BuCnOH369KRv4YLz5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQU3vOOTc3V+4X47nYpG3cWP90uv7668v9rrvuGrk99NBD5bXjXtd2kt+vuVaenBBKnBBKnBBKnBBKnBBKnBAq9qUxr7zyynI/ceJEue/fv3/kdujQofLab775ptyXl5fLPdnmzZvLvfrvvmvXrvLa++67r9xvvvnmcn/vvfdGbq+++mp57cGDB8v9888/L/dJ8tKYMGXECaHECaHECaHECaHECaHECaFizzk3bKi/brz00kvlvnfv3jV/7pWVlXIfd865tLRU7idPnhy57dixo7x23DnlOAsLC+V+1VVXjdyqnys/xbi38XvggQfW9fGnlXNOmDLihFDihFDihFDihFDihFDihFCx55zjjDsH3blz55q21lrbtm1buY97Wc4bbrih3Kuzyt5XPfL60bFjx8p9vS8B+frrr4/cxp1zHj58uNw//fTTcl/vOeq0cs4JU0acEEqcEEqcEEqcEEqcEEqcEGpqzzlhVjjnhCkjTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTghVvgUgMDmenBBKnBBKnBBKnBBKnBBKnBDqPw36mCmnZW+WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.model.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
