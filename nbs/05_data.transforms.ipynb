{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.core import *\n",
    "from fastai.data.load import *\n",
    "from fastai.data.external import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import posixpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/yizhang/.fastai/data/mnist_tiny/train/7'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/3')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path, followlinks=followlinks)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            if len(folders) !=0 and i==0 and '.' not in folders: continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/7994.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/8286.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/7731.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/724.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/9343.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/8637.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/9200.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/8437.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/9767.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/7236.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial that searches suffix `suf` and passes along `kwargs`, only in `folders`, if specified\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ItemGetter(ItemTransform):\n",
    "    \"Creates a proper transform that applies `itemgetter(i)` (even on a tuple)\"\n",
    "    _retain = False\n",
    "    def __init__(self, i): self.i = i\n",
    "    def encodes(self, x): return x[self.i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ItemGetter(1)((1,2,3)),  2)\n",
    "test_eq(ItemGetter(1)(L(1,2,3)), 2)\n",
    "test_eq(ItemGetter(1)([1,2,3]),  2)\n",
    "test_eq(ItemGetter(1)(np.array([1,2,3])),  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AttrGetter(ItemTransform):\n",
    "    \"Creates a proper transform that applies `attrgetter(nm)` (even on a tuple)\"\n",
    "    _retain = False\n",
    "    def __init__(self, nm, default=None): store_attr()\n",
    "    def encodes(self, x): return getattr(x, self.nm, self.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(AttrGetter('shape')(torch.randn([4,5])), [4,5])\n",
    "test_eq(AttrGetter('shape', [0])([4,5]), [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(list(torch.randperm(len(o)).numpy()))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn train_test_split. This allow to *split* items in a stratified fashion (uniformely according to the ‘labels‘ distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True):\n",
    "    \"Split `items` into random train and test subsets using sklearn train_test_split utility.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train,valid = train_test_split(range_of(o), test_size=test_size, random_state=random_state,\n",
    "                                        stratify=stratify, train_size=train_size, shuffle=shuffle)\n",
    "        return L(train), L(valid)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "labels = [0] * 20 + [1] * 10\n",
    "test_size = 0.2\n",
    "\n",
    "f = TrainTestSplitter(test_size=test_size, random_state=42, stratify=labels)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)\n",
    "\n",
    "# test labels distribution consistency\n",
    "# there should be test_size % of zeroes and ones respectively in the validation set\n",
    "test_eq(len([t for t in val if t < 20]) / 20, test_size)\n",
    "test_eq(len([t for t in val if t > 20]) / 10, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(10))\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name):\n",
    "    def _inner(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)\n",
    "    return [i for n in L(name) for i in _inner(items,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames2 = fnames + [path/'test/3/4256.png', path/'test/7/2345.png', path/'valid/7/6467.png']\n",
    "splitter = GrandparentSplitter(train_name=('train', 'valid'), valid_name='test')\n",
    "test_eq(splitter(fnames2),[[0,3,4,6,1,2,5,7,10],[8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` by providing file `fname` (contains names of valid items separated by newline).\"\n",
    "    valid = Path(fname).read_text().split('\\n')\n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write_text('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ColSplitter(col='is_valid'):\n",
    "    \"Split `items` (supposed to be a dataframe) by value in `col`\"\n",
    "    def _inner(o):\n",
    "        assert isinstance(o, pd.DataFrame), \"ColSplitter only works when your items are a pandas DataFrame\"\n",
    "        valid_idx = (o.iloc[:,col] if isinstance(col, int) else o[col]).values.astype('bool')\n",
    "        return IndexSplitter(mask2idxs(valid_idx))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'b': [True,False,True,True,False]})\n",
    "splits = ColSplitter('b')(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])\n",
    "#Works with strings or index\n",
    "splits = ColSplitter(1)(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])\n",
    "# does not get confused if the type of 'is_valid' is integer, but it meant to be a yes/no\n",
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'is_valid': [1,0,1,1,0]})\n",
    "splits_by_int = ColSplitter('is_valid')(df)\n",
    "test_eq(splits_by_int, [[1,4], [0,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSubsetSplitter(train_sz, valid_sz, seed=None):\n",
    "    \"Take randoms subsets of `splits` with `train_sz` and `valid_sz`\"\n",
    "    assert 0 < train_sz < 1\n",
    "    assert 0 < valid_sz < 1\n",
    "    assert train_sz + valid_sz <= 1.\n",
    "\n",
    "    def _inner(o):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        train_len,valid_len = int(len(o)*train_sz),int(len(o)*valid_sz)\n",
    "        idxs = L(list(torch.randperm(len(o)).numpy()))\n",
    "        return idxs[:train_len],idxs[train_len:train_len+valid_len]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(100))\n",
    "valid_idx = list(np.arange(70,100))\n",
    "splits = RandomSubsetSplitter(0.3, 0.1)(items)\n",
    "test_eq(len(splits[0]), 30)\n",
    "test_eq(len(splits[1]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grouped_dataframe_splitter(df,group_col,valid_pct=0.2,seed=None,n_tries=3):\n",
    "    r_state=np.random.RandomState(seed)\n",
    "    desired_valid=round(len(df)*valid_pct)\n",
    "    gk=df.groupby(group_col).count()#make a table of groups and their counts\n",
    "    def one_shuffle():\n",
    "        shuffled_gk=gk.sample(frac=1,random_state=r_state) #shuffle the groups\n",
    "        cumsum=shuffled_gk.cumsum()\n",
    "        abs_diff=abs(cumsum-desired_valid)\n",
    "        split_goodness=-abs_diff.min().iat[0] #find the best split point for this shuffle\n",
    "        valid_rows=abs_diff.iloc[:,0].argmin()+1 #(the groups included in val for that split)\n",
    "        return shuffled_gk,split_goodness,valid_rows\n",
    "    def n_shuffles(n): #finding the closest possible split to valid_pct is NP hard so instead we just take the best of a few tries\n",
    "        best_shuffled,best_goodness,best_rows=one_shuffle()\n",
    "        for _ in range(n-1):\n",
    "            if best_goodness==0: return best_shuffled,best_goodness,best_rows #perfect split, return early\n",
    "            sh,g,r=one_shuffle()\n",
    "            if g>best_goodness:\n",
    "                best_shuffled,best_goodness,best_rows=sh,g,r\n",
    "        return best_shuffled,best_goodness,best_rows\n",
    "    shuffled_gk,split_goodness,valid_rows=n_shuffles(n_tries)\n",
    "    shuffled_gk['is_valid']=([True] * valid_rows + \n",
    "                             [False]*(len(shuffled_gk) - valid_rows))\n",
    "    split_df=df.join(shuffled_gk.loc[:,'is_valid'],on=group_col) #apply the group split to the actual items\n",
    "    return ColSplitter()(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GroupedDataframeSplitter(group_col,colval2groupname=None,valid_pct=0.2,seed=None,n_tries=3):\n",
    "    \"Splits items randomly without breaking up groups, to help ensure generalizability to unseen groups. Groups are defined by `group_col` with optional extra function `colval2groupname`\"    \n",
    "    def _inner(o):\n",
    "        assert isinstance(o,pd.DataFrame), 'This splitter is meant for Dataframes, please use GroupedListSplitter'\n",
    "        assert group_col in o, \"`group_col` is not a valid column name in the DataFrame o\"\n",
    "        df=pd.DataFrame(o)\n",
    "        if callable(colval2groupname):\n",
    "            df['group_keys']=df[group_col].apply(colval2groupname)\n",
    "            return _grouped_dataframe_splitter(df,'group_keys',valid_pct,seed,n_tries)\n",
    "        return _grouped_dataframe_splitter(df,group_col,valid_pct,seed,n_tries)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GroupedListSplitter(item2group,valid_pct=0.2,seed=None,n_tries=3):\n",
    "    \"Splits items randomly without breaking up groups, to help ensure generalizability to unseen groups. `itemtogroup` should be a function (eg a regex) that returns the group name for each item.\" \n",
    "    def _inner(o):\n",
    "        assert not isinstance(o,pd.DataFrame), 'Please use GroupedDataframeSplitter instead'\n",
    "        assert callable(item2group), \"You must pass in a callable `item2group` that extracts a group name from each item\"\n",
    "        df=pd.DataFrame(o)\n",
    "        df['group_keys']=df.applymap(item2group)\n",
    "        return _grouped_dataframe_splitter(df,'group_keys',valid_pct,seed,n_tries)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GroupedSplitter allows you to split items randomly, like `RandomSplitter`, but keep similiar items (\"groups\") segregated into one set or the other, so as to make the validation set more fair.\n",
    "\n",
    "Suppose you are building a classifier for facial expressions with these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=[\n",
    "\"photos/smiling/alice_1.jpg\",\"photos/smiling/alice_2.jpg\",\"photos/smiling/alice_3.jpg\",\"photos/frowning/alice_4.jpg\",\"photos/frowning/alice_5.jpg\",\n",
    "\"photos/smiling/bob_1.jpg\",\"photos/frowning/bob_2.jpg\",\"photos/smiling/bob_3.jpg\",\n",
    "\"photos/smiling/charlie_1.jpg\",\"photos/smiling/charlie_2.jpg\",\"photos/smiling/charlie_3.jpg\",\"photos/smiling/charlie_4.jpg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you want it to correctly classify other people's faces as well, eg Denise or Edward.\n",
    "\n",
    "Assigning items randomly to training/validation will likely result in an unfairly easy validation set.\n",
    "\n",
    "The model might simply learn what, eg, **Alice**'s smiles look like, without learning to detect a smile on an unseen face. Even worse, some of the pictures may have been taken closely together, so that the model might just \"remember\" a similiar picture from the training set.\n",
    "\n",
    "We can fix this by grouping the split. If a model trained only on pictures of Alice and Charlie can correctly classify pictures of Bob, then it will probably generalize well to Denise and Edward too.\n",
    "\n",
    "The two GroupedSplitters (one for Dataframes, one for Lists) will do this for you automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#9) ['photos/smiling/alice_1.jpg','photos/smiling/alice_2.jpg','photos/smiling/alice_3.jpg','photos/frowning/alice_4.jpg','photos/frowning/alice_5.jpg','photos/smiling/charlie_1.jpg','photos/smiling/charlie_2.jpg','photos/smiling/charlie_3.jpg','photos/smiling/charlie_4.jpg']\n",
      "(#3) ['photos/smiling/bob_1.jpg','photos/frowning/bob_2.jpg','photos/smiling/bob_3.jpg']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "key_f=lambda path:re.search(r'([a-z]+)_',path).group(1)\n",
    "f=GroupedListSplitter(key_f,seed=42)\n",
    "trn,val = f(items)\n",
    "print(f\"{L(items)[trn]}\\n{L(items)[val]}\")\n",
    "for v in L(items)[val]:\n",
    "    assert key_f(v) == 'bob'#we can expect bob to end up as validation set since he's the smallest group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best possible split is NP-hard, so this algorithm just takes the best split in can find in `n_tries` (default 3) which are computationally cheap.\n",
    "\n",
    "Also note there is no guarantee that the validation set will have a representative or even complete sampling of classes (this is true of other splitters as well but perhaps more likely with this one). In the example above, Charlie has no frown pictures, and his pictures would have ended up as the validation set if he had fewer pictures than Bob.\n",
    "\n",
    "Hopefully this won't be such a problem in practice when using larger datasets, but consider looking over the resulting split for oddities. You can tweak the `seed` and `n_tries` parameters to get a different split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example using a real dataset of Zebra Finch calls. Suppose you want a model to classify the various types of calls (song, begging etc), and you want to ensure its external validity for individual birds that are not in the dataset. The dataset comes with a table with a column for the individual bird each call was from, so you can pass that right in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>adult</th>\n",
       "      <th>name</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>call_type</th>\n",
       "      <th>rendition_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WhiBlu4818_110404-DC-02.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>whiblu4818</td>\n",
       "      <td>2011-04-04</td>\n",
       "      <td>Distance</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BluRas61dd_110502-AggC-15.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>bluras61dd</td>\n",
       "      <td>2011-05-02</td>\n",
       "      <td>Wsst</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LblRed0613_110920-So-37.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>lblred0613</td>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>Song</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LblBla4548_130416-So-02.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>lblbla4548</td>\n",
       "      <td>2013-04-16</td>\n",
       "      <td>Song</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LblRed0613_110920-NestC-48.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>lblred0613</td>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>Nest</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>LblBlu1729_110225-Beggseq-08.wav</td>\n",
       "      <td>False</td>\n",
       "      <td>lblblu1729</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>Begging</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>WhiBlu0112_110311-LTC-01.wav</td>\n",
       "      <td>False</td>\n",
       "      <td>whiblu0112</td>\n",
       "      <td>2011-03-11</td>\n",
       "      <td>Long Tonal</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>LblGre0000_130521-LTC-15.wav</td>\n",
       "      <td>False</td>\n",
       "      <td>lblgre0000</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>Long Tonal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>WhiBlu0112_110311-LTC-25.wav</td>\n",
       "      <td>False</td>\n",
       "      <td>whiblu0112</td>\n",
       "      <td>2011-03-11</td>\n",
       "      <td>Long Tonal</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>LblGre0001_130521-LTC-10.wav</td>\n",
       "      <td>False</td>\n",
       "      <td>lblgre0001</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>Long Tonal</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3405 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    fn  adult        name date_recorded  \\\n",
       "0          WhiBlu4818_110404-DC-02.wav   True  whiblu4818    2011-04-04   \n",
       "1        BluRas61dd_110502-AggC-15.wav   True  bluras61dd    2011-05-02   \n",
       "2          LblRed0613_110920-So-37.wav   True  lblred0613    2011-09-20   \n",
       "3          LblBla4548_130416-So-02.wav   True  lblbla4548    2013-04-16   \n",
       "4       LblRed0613_110920-NestC-48.wav   True  lblred0613    2011-09-20   \n",
       "...                                ...    ...         ...           ...   \n",
       "3400  LblBlu1729_110225-Beggseq-08.wav  False  lblblu1729    2011-02-25   \n",
       "3401      WhiBlu0112_110311-LTC-01.wav  False  whiblu0112    2011-03-11   \n",
       "3402      LblGre0000_130521-LTC-15.wav  False  lblgre0000    2013-05-21   \n",
       "3403      WhiBlu0112_110311-LTC-25.wav  False  whiblu0112    2011-03-11   \n",
       "3404      LblGre0001_130521-LTC-10.wav  False  lblgre0001    2013-05-21   \n",
       "\n",
       "       call_type rendition_num  \n",
       "0       Distance            02  \n",
       "1           Wsst            15  \n",
       "2           Song            37  \n",
       "3           Song            02  \n",
       "4           Nest            48  \n",
       "...          ...           ...  \n",
       "3400     Begging            08  \n",
       "3401  Long Tonal            01  \n",
       "3402  Long Tonal            15  \n",
       "3403  Long Tonal            25  \n",
       "3404  Long Tonal            10  \n",
       "\n",
       "[3405 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "path = untar_data(URLs.ZEBRA_FINCH)\n",
    "df=pd.read_csv((path)/'annotations.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "trn,val = GroupedDataframeSplitter('name',seed=42)(df)\n",
    "trn_rows=df.iloc[trn]\n",
    "val_rows=df.iloc[val]\n",
    "\n",
    "assert not set(trn_rows['name']) & set(val_rows['name'])#no birds are in both sets\n",
    "assert len(trn)>len(val)#training set is bigger\n",
    "test_eq(len(trn + val),len(df))#no items left out of split\n",
    "test_eq(GroupedDataframeSplitter('name',seed=42)(df)[0],trn)#test random seed consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2726 training rows. \n",
      "\n",
      "Bird names: ['blabla0506', 'blalbl8026', 'bluras07dd', 'bluras61dd', 'gragra0201', 'gragre0813', 'gragre1001', 'gralbl0457', 'graras1500', 'graras1600', 'gregre2522', 'gregre6364', 'greora1817', 'grewhi1242', 'hpigra1004', 'hpihpi4748', 'lblbla4548', 'lblblu1630', 'lblblu1729', 'lblblu1927', 'lblblu2028', 'lblblu6243', 'lblblu6379', 'lblblu6680', 'lblgre0000', 'lblras1800', 'lblred0613', 'purras20dd', 'redras3600', 'unknown', 'unknown000', 'unknown00f', 'unknown01f', 'whiblu0112', 'whiblu3414', 'whiblu3513', 'whiblu3615', 'whiblu4818', 'whiblu4917', 'whiblu5698', 'whigra0114', 'whiwhi1415', 'yelora2575']\n",
      "\n",
      "\n",
      "679 validation rows. \n",
      "\n",
      "Bird names: ['greras2400', 'lblbla4419', 'lblgre0001', 'whilbl0010', 'whiras44dd', 'yelgre5275']\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(f\"{len(trn_rows)} training rows. \\n\\nBird names: {sorted(trn_rows['name'].unique())}\\n\\n\")\n",
    "print(f\"{len(val_rows)} validation rows. \\n\\nBird names: {sorted(val_rows['name'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that the differently colored Zebra Finches were actually different species, and you'd like to test your classifier to be robust to unseen colors/species of Zebra Finches. In such a case you might want to pass in the color/species of each bird as its group. You can add a function to extract a species name from each bird name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "name2species=lambda name:re.sub(r'\\d+\\w*$', '', name)\n",
    "trn,val = GroupedDataframeSplitter('name',name2species,seed=42)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2716 training items. \n",
      "Birds colors: ['blalbl', 'bluras', 'gragra', 'gragre', 'graras', 'greora', 'greras', 'grewhi', 'hpigra', 'hpihpi', 'lblblu', 'lblgre', 'lblras', 'lblred', 'purras', 'whiblu', 'whigra', 'whilbl', 'whiras', 'whiwhi', 'yelgre', 'yelora']\n",
      "\n",
      "689 validation items. \n",
      "Birds colors: ['blabla', 'gralbl', 'gregre', 'lblbla', 'redras', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "trn_rows=df.iloc[trn]\n",
    "val_rows=df.iloc[val]\n",
    "print(f\"{len(trn_rows)} training items. \\nBirds colors: {sorted(trn_rows['group_keys'].unique())}\\n\")\n",
    "print(f\"{len(val_rows)} validation items. \\nBirds colors: {sorted(val_rows['group_keys'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat, match=False):\n",
    "        self.pat = re.compile(pat)\n",
    "        self.matcher = self.pat.match if match else self.pat.search\n",
    "\n",
    "    def __call__(self, o):\n",
    "        o = str(o).replace(os.sep, posixpath.sep)\n",
    "        res = self.matcher(o)\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. Pass `match=True` to use `re.match` (i.e. check only start of string), or `re.search` otherwise (default).\n",
    "\n",
    "For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(fr'{posixpath.sep}(\\d){posixpath.sep}')\n",
    "test_eq(f(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import posixpath\n",
    "f = RegexLabeller(fr'{posixpath.sep}(\\d){posixpath.sep}')\n",
    "a1 = Path(fnames[0]).as_posix()\n",
    "test_eq(f(a1), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegexLabeller(r'(\\d*)', match=True)\n",
    "test_eq(f(fnames[0].name), '9932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColReader(DisplayedTransform):\n",
    "    \"Read `cols` in `row` with potential `pref` and `suff`\"\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr()\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "\n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) else r[c] if c=='name' or c=='cat' else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "\n",
    "    def __call__(self, o, **kwargs):\n",
    "        if len(self.cols) == 1: return self._do_one(o, self.cols[0])\n",
    "        return L(self._do_one(o, c) for c in self.cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [L('0a1', '0a1'), L('0b1', '0b1'), L('0c1', '0c1'), L('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])\n",
    "\n",
    "df['name'] = df['a']\n",
    "f = ColReader('name')\n",
    "test_eq([f(df.iloc[0,:])], [L(0,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False, strict=False):\n",
    "        if is_categorical_dtype(col):\n",
    "            items = L(col.cat.categories, use_list=True)\n",
    "            #Remove non-used categories while keeping order\n",
    "            if strict: items = L(o for o in items if o in col.unique())\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "\n",
    "    def map_objs(self,objs):\n",
    "        \"Map `objs` to IDs\"\n",
    "        return L(self.o2i[o] for o in objs)\n",
    "\n",
    "    def map_ids(self,ids):\n",
    "        \"Map `ids` to objects in vocab\"\n",
    "        return L(self.items[o] for o in ids)\n",
    "\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_eq(t.map_objs([2,3]), [0,1])\n",
    "test_eq(t.map_ids([0,1]), [2,3])\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col, strict=True)\n",
    "test_eq(t, ['H','M'])\n",
    "test_eq(t.o2i, {'H':0,'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(DisplayedTransform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, sort=True, add_na=False):\n",
    "        if vocab is not None: vocab = CategoryMap(vocab, sort=sort, add_na=add_na)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): \n",
    "        try:\n",
    "            return TensorCategory(self.vocab.o2i[o])\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Label '{o}' was not included in the training dataset\") from e\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')\n",
    "test_fail(lambda: cat('bird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(vocab=['dog', 'cat'], sort=False, add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'dog', 'cat'])\n",
    "test_eq(cat('dog'), 1)\n",
    "test_eq(cat.decode(2), 'cat')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False): super().__init__(vocab=vocab,add_na=add_na,sort=vocab==None)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if not dsets: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsets: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): \n",
    "        if not all(elem in self.vocab.o2i.keys() for elem in o):\n",
    "            diff = [elem for elem in o if elem not in self.vocab.o2i.keys()]\n",
    "            diff_str = \"', '\".join(diff)\n",
    "            raise KeyError(f\"Labels '{diff_str}' were not included in the training dataset\")\n",
    "        return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], TensorMultiCategory([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')\n",
    "\n",
    "# if vocab supplied, ensure it maintains its order (i.e., it doesn't sort)\n",
    "cat = MultiCategorize(vocab=['z', 'y', 'x'])\n",
    "test_eq(cat.vocab, ['z','y','x'])\n",
    "\n",
    "test_fail(lambda: cat('bird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(DisplayedTransform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.c is None: self.c = len(L(getattr(dsets, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab):\n",
    "        super().__init__(vocab, sort=vocab==None)\n",
    "        self.c = len(vocab)\n",
    "    def encodes(self, o): return TensorMultiCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorMultiCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])\n",
    "\n",
    "_tfm2 = EncodedMultiCategorize(vocab=['c', 'b', 'a'])\n",
    "test_eq(_tfm2.vocab, ['c', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RegressionSetup(DisplayedTransform):\n",
    "    \"Transform that floatifies targets\"\n",
    "    loss_func=MSELossFlat()\n",
    "    def __init__(self, c=None): store_attr()\n",
    "\n",
    "    def encodes(self, o): return tensor(o).float()\n",
    "    def decodes(self, o): return TitledFloat(o) if o.ndim==0 else TitledTuple(o_.item() for o_ in o)\n",
    "    def setups(self, dsets):\n",
    "        if self.c is not None: return\n",
    "        try: self.c = len(dsets[0]) if hasattr(dsets[0], '__len__') else 1\n",
    "        except: self.c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = RegressionSetup()\n",
    "dsets = Datasets([0, 1, 2], RegressionSetup)\n",
    "test_eq(dsets.c, 1)\n",
    "test_eq_type(dsets[0], (tensor(0.),))\n",
    "\n",
    "dsets = Datasets([[0, 1, 2], [3,4,5]], RegressionSetup)\n",
    "test_eq(dsets.c, 3)\n",
    "test_eq_type(dsets[0], (tensor([0.,1.,2.]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dls):\n",
    "    if getattr(dls, 'c', False): return dls.c\n",
    "    if getattr(getattr(dls.train, 'after_item', None), 'c', False): return dls.train.after_item.c\n",
    "    if getattr(getattr(dls.train, 'after_batch', None), 'c', False): return dls.train.after_batch.c\n",
    "    vocab = getattr(dls, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `Datasets`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/7994.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/8286.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/train/7/7731.png')],\n",
       " (#3) [Path('/home/yizhang/.fastai/data/mnist_tiny/valid/7/8767.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/valid/7/8733.png'),Path('/home/yizhang/.fastai/data/mnist_tiny/valid/7/8480.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = Datasets(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IntToFloatTensor(DisplayedTransform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 10 #Need to run after PIL transforms on the GPU\n",
    "    def __init__(self, div=255., div_mask=1): store_attr()\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.long() // self.div_mask\n",
    "    def decodes(self, o:TensorImage): return ((o.clamp(0., 1.) * self.div).long()) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor()\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(DisplayedTransform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    parameters,order = L('mean', 'std'),99\n",
    "    def __init__(self, mean=None, std=None, axes=(0,2,3)): store_attr()\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "\n",
    "    def setups(self, dl:DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch()\n",
    "            self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [IntToFloatTensor(), Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.LongTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.float().mean()/255.<1\n",
    "assert 0<xd.float().std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "nrm = Normalize()\n",
    "batch_tfms = [IntToFloatTensor(), nrm]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.9, x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAI1ElEQVR4nO2c228cVx3HP+fM7MV78+56bcf39SW2k9Rtk5BSNy1VKwIFAQ9VL9AH4AUhIZAQ/BlIvPQBCSFoQUiI0r5U0Ja2omnTpqVtkraJkyauL1k7vu/ae7/NHB7WNspgXEr2BpqPZNne2d357sdnfmfOOTMWSils/olsdIBmwxZiwRZiwRZiwRZiwRZiwRZioeFChBBpy5chhHiyUXn0Ru14B6WUb+dnIYQXWAGeaVSehrcQC48Aq8AbjQrQbEK+A/xWNXA8IZplLCOE6AdmgRGl1GyjcjRTC/k2cKaRMqD5hDzd6BBNIUQIcQ/QQwN7lx2aQgiVYvqcUirV6CBNU1SbhWZpIU2DLcSCLcSCLcTCvoO7U/LR/9uK+7L5jNjrcbuFWLCFWLCFWLCFWLCFWLCFWLCFWLCFWLCFWLCFWLCFWLCFWGj4yt0O+uAAxf4w+bCTQkASupxGu7aAmc6gSsXd50m/H+FyVn5RCjOZvmn7Leeo2jvdIuv3dRN/KMejh87yk8hZ7nrup4w+1Y1cWMVYW9t9nujqoBzZXv1UoF+NYWzEq5ajYUKkx4Pw+1BdEXJdXuK3wdH+GMe9c0Q0L8plYvicGId7UbKPYqtOySPJdEmKge33KEOf6kUrlTGzWVS5fMu5GiekvY1iNMKNe1pwTW7wxMBFvht8h7CmYSgXoqVMoc3B2u06+WiRO4bnOdk2zbGWOfr0JABxw833Uz+iZ6sTcf3G/6YQ6fUiA36Sx7tZmpS4hrZ4oOcaRz3z+KXAgQbAsaHrnPviMP7eBEfa1rg3PM2EO0ZU36JVCjQEGjlMByhNA1md/qH+QkJBCiOdLHxJceFrP0dDIJFoQgBO5HbH9/uhFygNGpXX7G4HcG0H1zDIYeqgHBpS7DkB9pmpvRCpIZ0OhNeDCPhJ3nmAlbskowdjuMW/7l4itr9LHPt8xgvFMleK/bjjCi2RwixWp6epuRDh0BF+P6qzjcxggMUH4Mmv/oaonvivd28oxQup2zm9dhD/9TLl64tgGlXJWzMh0u9HdHWQj4ZYu91JMaQodpaYOLhAVE8Qlgagk1dlCsrko2KAj/J9pA03WcPJdKad5UyAR3vP8WXfFO1S4JEOAEoY/GH6OMaHrUSXNjGVWbXctRMSDrI1EWHlhOTH33ieCXeMSVflr2ii7+46axrETY1n4yd4dWaUYsaJyGr4P9Hwxwx+8c376LtjgwnnMp7tullSJvLNVgb+FMNc24AqLsfWTIjp95Ic0DC689zpnqdby+IQPkrKwFCKiyXBO9kRnl08yvVrnbiXNXwrCq0AWknhTJXRcgblUqXXkVTqyqVimUvFfpybCpVMo6pUO3aomZBy0E162OBgzyp3uRQOsXttHSYmb2XHeXr6bvhrmLGnPkAVSzedgus93ZjtQcpFNxITbbvAvp0b4rXEGJ4NAyORqHrumgnR00VaFjzMhCL8fVCQMl0slkKc3hzl7fkoZsxL6zSEp3IVGcbNRTF3qIuNCRejffMMOzYwFCyUc/xy+l7SU2GGFtPUYhWtdjUkmSUwF2A91MKZzBixfJiLiS4Wz3cx8GIB58IKxrUZgD0/WGLchbo/wcNd5xlx6CyUDWLlALlzbURfziLnlqlOv3IzNROiElsEp1pwpv38Ln4KWQRHRtG9aOCaj6O2knsH2j5UkiMmjw9c4ohrAYAXM4f428YY3pjCsbCBmcnUJHfNhBiJBCQSuD+Anudv3rbfiMPoCJEc8xMcjvO98FsEpcRQOqfjo7x/NcrQbJHyfKxWsZtn+L9DYiLA6gNFvtV7Bb8UxAzJctnLux8O0/mWxBVbrcmhskPTCUkOCn5w4jXu917BL53cKPg4l40SvKQTfukaZnLvQ61aNI0Q7cgYqdEgxniGB72X6daKgIvXU2O8tDCOZ81EpVKo0q0P8fejaYRkBwKsHpN8rv86dzp1TDRKyuBispt4LMjQRgkzn695jsYLkRrCobMVdRA6vsoXQlfRhOTVrIM3M6N8fGaQ6Osl3FdX9i3G1aLhQoRDR7a4yXfAE/3nOdYyBzg4n4vyytIYbR8qnC+9VxcZ0ARCSidvY2nSRdvdy5zyThHRSmRNxSur46xd6KR/pVDXPA0Xkhxw4p1c5+HeCxxySkpKp6DKxDaC+GfBkchRvcH9p9PwWfd0n+CHQ2c50VI5jf9LtpNXNw+jn/PT+cY6LK19yjtVl4YJES4XBHwUwyYPeS/TKitzqpdyvZy9ESUwZ2JMXa17roYJMcb6WJ70ER5ZJ6Jpu7PtZ9aGKb8fwruUa0iuhq3t5iNuUiMGY+FV3EJHEwJDKZa3/HgXFPpm7c859qLuLUQ4nEhvC4lRnSdOvsG9vsphMVMqMVMOU7oaoOO1G6iN6k/+/CfUX4jTgfB6KYQUj7S+R0QrIWlhzfQwle/BvS4oz87XO9Yu9RfS1UHqSDvF3iKDDhMHTiSCX618gTffOUzvx/U6Bdub+goRArPVQ7pbwxdM4xOu3U0zWxH8MxJXvDHFdIe6CZFeLzIU5MbnW+l5bJavdFzERGFiYijFetJLe8xAT2RrOt/xadRNiHA6Ua0+8u3w2IF3GXctYQIps0jchELahWuzhMjV91TdSv0OmY424kdDFIbyPOiZwysk4OBn6yd55oPjtJ924LxwBSObrVukvaiPECEwAy1kDkj8rTnatUrtMJTicvIA7msu/AuFmqyzfFbqsNjtRPq8rN3mY/DrM5yKXAYga5ZIKZOPPull/M+byOWNug3x96P2QtwuRDBAvk3wYOQKE+7KjPmmaTJTbkVu6oiFFcxsY3uXHWovpPcAK/dEyEzkedx/EY/UAJ0/Jo/y66lJQlMCI74JVVzBvxVqX0OEAAkqr3E614cUJqaSvLh8GDXrxbNuVO3ajmqw753d1bgJUbhcyEAA4fNgtPl3H5fZIiKVRaVSGJtbt7qbz8y/uwmx5i1EFQqV60zXqPx3kG2ap03cjH3vvwX7WncLthALthALthALthALthAL/wCizEsEI2cpIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "x,y = cast(x,Tensor),cast(y,Tensor) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(1,1)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 01a_losses.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 10b_tutorial.albumentations.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 18b_callback.preds.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 74_callback.azureml.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted dev-setup.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted quick_start.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
