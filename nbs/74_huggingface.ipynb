{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab\n",
    "! pip install git+https://github.com/huggingface/huggingface_hub#egg=huggingface-hub[\"fastai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from huggingface_hub import *\n",
    "from huggingface_hub.fastai_utils import *\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the ðŸ¤— Hugging Face Hub to share and load models\n",
    "\n",
    "> Integration with the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why share to the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hub is a central platform where anyone can share and explore models, datasets, and ML demos. It aims to build the most extensive collection of Open Source models, datasets, and demos. \n",
    "\n",
    "The \"solve AI\" problem won't be solved by a single company, but by a culture of sharing knowledge and resources. This is something that fastai has taken to the next level ðŸŒˆ. \n",
    "\n",
    "You can amplify your impact ðŸš€. By sharing your fastai Learner to the Hub, you will expose it to over 100,000 users. \n",
    "\n",
    "Here are some facts about the Hugging Face Hub:\n",
    "\n",
    "- There are over 40,000 public models.\n",
    "- There are models for Natural Language Processing, Computer Vision, Audio/- - Speech, and Reinforcement Learning!\n",
    "- There are models for over 180 languages.\n",
    "- Any ML library can leverage the Hub: from TensorFlow and PyTorch to advanced integrations with fastai ðŸ”¥ like this one!\n",
    "- You can find almost 4,500 datasets.\n",
    "\n",
    "\n",
    "To get know more about the Hub you can check [this introduction](https://github.com/huggingface/education-toolkit/blob/main/01_huggingface-hub-tour.md).\n",
    "\n",
    "You can find all the fastai models in the Hugging Face Hub by filtering the [huggingface.co/models](https://huggingface.co/models) webpage by the fastai library as in the image below.\n",
    "\n",
    "<img src=\"images/hf_hub_fastai.png\" alt=\"hf_hub_fastai\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `huggingface_hub`. Additionally, we require the following packages for our functions to work:\n",
    "- toml,\n",
    "- fastai>=2.4,\n",
    "- fastcore>=1.3.27\n",
    "\n",
    "You can either install these packages manually or specify `[\"fastai\"]` when installing `huggingface_hub` and your environment will be ready:\n",
    "\n",
    "```\n",
    "pip install huggingface_hub[\"fastai\"]\n",
    "```\n",
    "\n",
    "Note: As of May 5, 2022, there has not been a release that includes the fastai+hub features, so you can install from `main`:\n",
    "\n",
    "```\n",
    "!pip install git+https://github.com/huggingface/huggingface_hub#egg=huggingface-hub[\"fastai\"]\n",
    "```\n",
    "\n",
    "To share models in the Hub, you will need to have a user. You can create it on the [Hugging Face website](https://huggingface.co/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing a Learner to the Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def push_to_hub_fastai(\n",
    "    learner,\n",
    "    repo_id: str,\n",
    "    commit_message: Optional[str] = \"Add model\",\n",
    "    private: Optional[bool] = None,\n",
    "    token: Optional[str] = None,\n",
    "    config: Optional[dict] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in `repo_id`.\n",
    "    \n",
    "    Returns:\n",
    "        The url of the commit of your model in the given repository.\n",
    "\n",
    "    Raises the following error:\n",
    "        - [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\n",
    "          if the user is not log on to the Hugging Face Hub.\n",
    "    \"\"\"\n",
    "\n",
    "    _check_fastai_fastcore_versions()\n",
    "\n",
    "    api_endpoint: str = kwargs.get(\"api_endpoint\", None)\n",
    "    git_user: str = kwargs.get(\"git_user\", None)\n",
    "    git_email: str = kwargs.get(\"git_email\", None)\n",
    "\n",
    "    if token is None:\n",
    "        token = HfFolder.get_token()\n",
    "\n",
    "    if token is None:\n",
    "        raise ValueError(\n",
    "            \"You must login to the Hugging Face Hub. There are two options: \"\n",
    "            \"(1) Type `huggingface-cli login` in your terminal and enter your token. \"\n",
    "            \"(2) Enter your token in the `token` argument. \"\n",
    "            \"Your token is available in the Settings of your Hugging Face account. \"\n",
    "        )\n",
    "\n",
    "    # Create repo using `HfApi()`.\n",
    "    repo_url = HfApi(endpoint=api_endpoint).create_repo(\n",
    "        repo_id,\n",
    "        token=token,\n",
    "        private=private,\n",
    "        repo_type=None,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    # If repository exists in the Hugging Face Hub then clone it locally in `repo_id`.\n",
    "    repo = Repository(\n",
    "        repo_id,\n",
    "        clone_from=repo_url,\n",
    "        use_auth_token=token,\n",
    "        git_user=git_user,\n",
    "        git_email=git_email,\n",
    "    )\n",
    "    repo.git_pull(rebase=True)\n",
    "\n",
    "    _save_pretrained_fastai(learner, repo_id, config=config)\n",
    "\n",
    "    return repo.push_to_hub(commit_message=commit_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, login to the Hugging Face Hub. There are two options:\n",
    "1. Type `huggingface-cli login` in your terminal and enter your token. \n",
    "2. Enter your token in the `token` argument of the `push_to_hub_fastai` function.\n",
    "\n",
    "```\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "```\n",
    "\n",
    "Your token is available in your Hugging Face Account Settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `push_to_hub_fastai` with the learner you want to upload and the repository id for your learner in the Hub in the format of \"namespace/repo_name\". The namespace can be your individual account or an organization to which you have write access (for example, 'fastai/stanza-de').\n",
    "\n",
    "```\n",
    "from huggingface_hub import push_to_hub_fastai\n",
    "push_to_hub_fastai(learner=learn, repo_id=\"espejelomar/cool_learner\")\n",
    "```\n",
    "\n",
    "It is as simple as that! Now you can find your Learner right in the Hub with the id `espejelomar/cool_learner`.\n",
    "\n",
    "When uploading a fastai Learner (or any other model) to the Hub, don't forget to edit its model card (image below). Here is [Hugging Face documentation](https://huggingface.co/docs/hub/model-repos#what-are-model-cards-and-why-are-they-useful) with everything you need.\n",
    "\n",
    "<img src=\"images/hf_model_card.png\" alt=\"hf_model_card\" width=\"800\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Learner from the Hugging Face Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def from_pretrained_fastai(\n",
    "    repo_id: str,\n",
    "    revision: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load pretrained fastai model from the Hub or from a local directory. `repo_id` is the location where the pickled fastai.Learner is. It can be either of the two:\n",
    "                - Hosted on the Hugging Face Hub. E.g.: 'espejelomar/fatai-pet-breeds-classification' or 'distilgpt2'.\n",
    "                  You can add a `revision` by appending `@` at the end of `repo_id`. E.g.: `dbmdz/bert-base-german-cased@main`.\n",
    "                  Revision is the specific model version to use. Since we use a git-based system for storing models and other\n",
    "                  artifacts on the Hugging Face Hub, it can be a branch name, a tag name, or a commit id.\n",
    "                - Hosted locally. `repo_id` would be a directory containing the pickle and a pyproject.toml\n",
    "                  indicating the fastai and fastcore versions used to build the `fastai.Learner`. E.g.: `./my_model_directory/`.\n",
    "\n",
    "    Returns:\n",
    "        The `fastai.Learner` model in the `repo_id` repo.\n",
    "    \"\"\"\n",
    "    _check_fastai_fastcore_versions()\n",
    "\n",
    "    # `snapshot_download` returns the folder where the model was stored.\n",
    "    if not os.path.isdir(repo_id):\n",
    "        storage_folder = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            revision=revision,\n",
    "            library_name=\"fastai\",\n",
    "            library_version=get_fastai_version(),\n",
    "        )\n",
    "    else:\n",
    "        storage_folder = repo_id\n",
    "\n",
    "    _check_fastai_fastcore_pyproject_versions(storage_folder)\n",
    "\n",
    "    from fastai.learner import load_learner\n",
    "\n",
    "    return load_learner(os.path.join(storage_folder, \"model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a model from the Hub is even simpler. To load a model in the Hub with the id `ITESM/fastai_model`:\n",
    "\n",
    "```\n",
    "from huggingface_hub import from_pretrained_fastai\n",
    "learner = from_pretrained_fastai(\"ITESM/fastai_model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
