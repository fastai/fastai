{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastai.data.all import *\n",
    "from fastai.optimizer import *\n",
    "from fastai.losses import BaseLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_all_ = ['CancelStepException','CancelBackwardException','CancelFitException','CancelEpochException','CancelTrainException','CancelValidException','CancelBatchException']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "> Basic callbacks for Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks can occur at any of these times:: *after_create before_fit before_epoch before_train before_batch after_pred after_loss before_backward after_cancel_backward after_backward before_step after_cancel_step after_step after_cancel_batch after_batch after_cancel_train after_train before_validate after_cancel_validate after_validate after_cancel_epoch after_epoch after_cancel_fit after_fit*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_events = L.split('after_create before_fit before_epoch before_train before_batch after_pred after_loss \\\n",
    "    before_backward after_cancel_backward after_backward before_step after_cancel_step after_step \\\n",
    "    after_cancel_batch after_batch after_cancel_train after_train before_validate after_cancel_validate \\\n",
    "    after_validate after_cancel_epoch after_epoch after_cancel_fit after_fit')\n",
    "\n",
    "mk_class('event', **_events.map_dict(),\n",
    "         doc=\"All possible events as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_all_ = ['event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"event\" class=\"doc_header\"><code>class</code> <code>event</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>event</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "All possible events as attributes to get tab-completion and typo-proofing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(event, name='event', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that you are referring to an event (that is, the name of one of the times when callbacks are called) that exists, and to get tab completion of event names, use `event`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(event.before_step, 'before_step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_inner_loop = \"before_batch after_pred after_loss before_backward after_cancel_backward after_backward before_step after_step after_cancel_batch after_batch\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_ex_docs = dict(\n",
    "    CancelBatchException=\"Skip the rest of this batch and go to `after_batch`\",\n",
    "    CancelTrainException=\"Skip the rest of the training part of the epoch and go to `after_train`\",\n",
    "    CancelValidException=\"Skip the rest of the validation part of the epoch and go to `after_validate`\",\n",
    "    CancelEpochException=\"Skip the rest of this epoch and go to `after_epoch`\",\n",
    "    CancelStepException =\"Skip stepping the optimizer\",\n",
    "    CancelBackwardException=\"Skip the backward pass and go to `after_backward`\",\n",
    "    CancelFitException  =\"Interrupts training and go to `after_fit`\")\n",
    "\n",
    "for c,d in _ex_docs.items(): mk_class(c,sup=Exception,doc=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@funcs_kwargs(as_method=True)\n",
    "class Callback(Stateful,GetAttr):\n",
    "    \"Basic class handling tweaks of the training loop by changing a `Learner` in various events\"\n",
    "    order,_default,learn,run,run_train,run_valid = 0,'learn',None,True,True,True\n",
    "    _methods = _events\n",
    "\n",
    "    def __init__(self, **kwargs): assert not kwargs, f'Passed unknown events: {kwargs}'\n",
    "    def __repr__(self): return type(self).__name__\n",
    "\n",
    "    def __call__(self, event_name):\n",
    "        \"Call `self.{event_name}` if it's defined\"\n",
    "        _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n",
    "               (self.run_valid and not getattr(self, 'training', False)))\n",
    "        res = None\n",
    "        if self.run and _run: \n",
    "            try: res = getcallable(self, event_name)()\n",
    "            except (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n",
    "            except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
    "        if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit\n",
    "        return res\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        \"Set an attribute for a `Callback`\"\n",
    "        if hasattr(self.learn,name):\n",
    "            warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
    "        super().__setattr__(name, value)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"Name of the `Callback`, camel-cased and with '*Callback*' removed\"\n",
    "        return class2attr(self, 'Callback')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop is defined in `Learner` a bit below and consists in a minimal set of instructions: looping through the data we:\n",
    "\n",
    "- compute the output of the model from the input\n",
    "- calculate a loss between this output and the desired target\n",
    "- compute the gradients of this loss with respect to all the model parameters\n",
    "- update the parameters accordingly\n",
    "- zero all the gradients\n",
    "\n",
    "Any tweak of this training loop is defined in a `Callback` to avoid over-complicating the code of the training loop, and to make it easy to mix and match different techniques (since they'll be defined in different callbacks). A callback can implement actions on the following events:\n",
    "\n",
    "- `after_create`: called after the `Learner` is created\n",
    "- `before_fit`: called before starting training or inference, ideal for initial setup.\n",
    "- `before_epoch`: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch.\n",
    "- `before_train`: called at the beginning of the training part of an epoch.\n",
    "- `before_batch`: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).\n",
    "- `after_pred`: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.\n",
    "- `after_loss`: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).\n",
    "- `before_backward`: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)\n",
    "- `after_backward`: called after the backward pass, but before the update of the parameters. Generally `before_step` should be used instead.\n",
    "- `before_step`: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).\n",
    "- `after_step`: called after the step and before the gradients are zeroed.\n",
    "- `after_batch`: called at the end of a batch, for any clean-up before the next one.\n",
    "- `after_train`: called at the end of the training phase of an epoch.\n",
    "- `before_validate`: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.\n",
    "- `after_validate`: called at the end of the validation part of an epoch.\n",
    "- `after_epoch`: called at the end of an epoch, for any clean-up before the next one.\n",
    "- `after_fit`: called at the end of training, for final clean-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Callback.__call__\" class=\"doc_header\"><code>Callback.__call__</code><a href=\"__main__.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Callback.__call__</code>(**`event_name`**)\n",
       "\n",
       "Call `self.{event_name}` if it's defined"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Callback.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to define callbacks is through subclassing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(Callback):\n",
    "    def call_me(self): return \"maybe\"\n",
    "test_eq(_T()(\"call_me\"), \"maybe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is by passing the callback function to the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb(self): return \"maybe\"\n",
    "_t = Callback(before_fit=cb)\n",
    "test_eq(_t(event.before_fit), \"maybe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Callback`s provide a shortcut to avoid having to write `self.learn.bla` for any `bla` attribute we seek; instead, just write `self.bla`. This only works for getting attributes, *not* for setting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_class('TstLearner', 'a')\n",
    "\n",
    "class TstCallback(Callback):\n",
    "    def batch_begin(self): print(self.a)\n",
    "\n",
    "learn,cb = TstLearner(1),TstCallback()\n",
    "cb.learn = learn\n",
    "test_stdout(lambda: cb('batch_begin'), \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to change the value of an attribute, you have to use `self.learn.bla`, no `self.bla`. In the example below, `self.a += 1` creates an `a` attribute of 2 in the callback instead of setting the `a` of the learner to 2. It also issues a warning that something is probably wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5201/1369389649.py:29: UserWarning: You are shadowing an attribute (a) that exists in the learner. Use `self.learn.a` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
     ]
    }
   ],
   "source": [
    "class TstCallback(Callback):\n",
    "    def batch_begin(self): self.a += 1\n",
    "\n",
    "learn,cb = TstLearner(1),TstCallback()\n",
    "cb.learn = learn\n",
    "cb('batch_begin')\n",
    "test_eq(cb.a, 2)\n",
    "test_eq(cb.learn.a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proper version needs to write `self.learn.a = self.a + 1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TstCallback(Callback):\n",
    "    def batch_begin(self): self.learn.a = self.a + 1\n",
    "\n",
    "learn,cb = TstLearner(1),TstCallback()\n",
    "cb.learn = learn\n",
    "cb('batch_begin')\n",
    "test_eq(cb.learn.a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "class TstCallback(Callback):\n",
    "    def batch_begin(self): self.learn.a = 1 + \"a\"\n",
    "learn,cb = TstLearner(1),TstCallback()\n",
    "cb.learn = learn\n",
    "with ExceptionExpected(TypeError, regex=\" in `TstCallback` when calling event `batch_begin`\"):\n",
    "    cb('batch_begin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Callback.name\" class=\"doc_header\"><code>Callback.name</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Name of the [`Callback`](/callback.core.html#Callback), camel-cased and with '*Callback*' removed"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Callback.name, name='Callback.name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TstCallback().name, 'tst')\n",
    "class ComplicatedNameCallback(Callback): pass\n",
    "test_eq(ComplicatedNameCallback().name, 'complicated_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainEvalCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainEvalCallback(Callback):\n",
    "    \"`Callback` that tracks the number of iterations done and properly sets training/eval mode\"\n",
    "    order,run_valid = -10,False\n",
    "    def after_create(self): self.learn.n_epoch = 1\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Set the iter and epoch counters to 0, put the model and the right device\"\n",
    "        self.learn.epoch,self.learn.loss = 0,tensor(0.)\n",
    "        self.learn.train_iter,self.learn.pct_train = 0,0.\n",
    "        device = getattr(self.dls, 'device', default_device())\n",
    "        self.model.to(device)\n",
    "        if isinstance(self.loss_func, (nn.Module, BaseLoss)): self.loss_func.to(device)\n",
    "        if hasattr(self.model, 'reset'): self.model.reset()\n",
    "\n",
    "    def after_batch(self):\n",
    "        \"Update the iter counter (in training mode)\"\n",
    "        self.learn.pct_train += 1./(self.n_iter*self.n_epoch)\n",
    "        self.learn.train_iter += 1\n",
    "\n",
    "    def before_train(self):\n",
    "        \"Set the model to training mode\"\n",
    "        self.learn.pct_train=self.epoch/self.n_epoch\n",
    "        self.model.train()\n",
    "        self.learn.training=True\n",
    "\n",
    "    def before_validate(self):\n",
    "        \"Set the model to validation mode\"\n",
    "        self.model.eval()\n",
    "        self.learn.training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TrainEvalCallback\" class=\"doc_header\"><code>class</code> <code>TrainEvalCallback</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>TrainEvalCallback</code>(**`after_create`**=*`None`*, **`before_fit`**=*`None`*, **`before_epoch`**=*`None`*, **`before_train`**=*`None`*, **`before_batch`**=*`None`*, **`after_pred`**=*`None`*, **`after_loss`**=*`None`*, **`before_backward`**=*`None`*, **`before_step`**=*`None`*, **`after_cancel_step`**=*`None`*, **`after_step`**=*`None`*, **`after_cancel_batch`**=*`None`*, **`after_batch`**=*`None`*, **`after_cancel_train`**=*`None`*, **`after_train`**=*`None`*, **`before_validate`**=*`None`*, **`after_cancel_validate`**=*`None`*, **`after_validate`**=*`None`*, **`after_cancel_epoch`**=*`None`*, **`after_epoch`**=*`None`*, **`after_cancel_fit`**=*`None`*, **`after_fit`**=*`None`*) :: [`Callback`](/callback.core.html#Callback)\n",
       "\n",
       "[`Callback`](/callback.core.html#Callback) that tracks the number of iterations done and properly sets training/eval mode"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TrainEvalCallback, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `Callback` is automatically added in every `Learner` at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test of the TrainEvalCallback below in Learner.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "if not hasattr(defaults, 'callbacks'): defaults.callbacks = [TrainEvalCallback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes available to callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing a callback, the following attributes of `Learner` are available:\n",
    "\n",
    "- `model`: the model used for training/validation\n",
    "- `dls`: the underlying `DataLoaders`\n",
    "- `loss_func`: the loss function used\n",
    "- `opt`: the optimizer used to update the model parameters\n",
    "- `opt_func`: the function used to create the optimizer\n",
    "- `cbs`: the list containing all `Callback`s\n",
    "- `dl`: current `DataLoader` used for iteration\n",
    "- `x`/`xb`: last input drawn from `self.dl` (potentially modified by callbacks). `xb` is always a tuple (potentially with one element) and `x` is detuplified. You can only assign to `xb`.\n",
    "- `y`/`yb`: last target drawn from `self.dl` (potentially modified by callbacks). `yb` is always a tuple (potentially with one element) and `y` is detuplified. You can only assign to `yb`.\n",
    "- `pred`: last predictions from `self.model` (potentially modified by callbacks)\n",
    "- `loss_grad`: last computed loss (potentially modified by callbacks)\n",
    "- `loss`: clone of `loss_grad` used for logging\n",
    "- `n_epoch`: the number of epochs in this training\n",
    "- `n_iter`: the number of iterations in the current `self.dl`\n",
    "- `epoch`: the current epoch index (from 0 to `n_epoch-1`)\n",
    "- `iter`: the current iteration index in `self.dl` (from 0 to `n_iter-1`)\n",
    "\n",
    "The following attributes are added by `TrainEvalCallback` and should be available unless you went out of your way to remove that callback:\n",
    "\n",
    "- `train_iter`: the number of training iterations done since the beginning of this training\n",
    "- `pct_train`: from 0. to 1., the percentage of training iterations completed\n",
    "- `training`:  flag to indicate if we're in training mode or not\n",
    "\n",
    "The following attribute is added by `Recorder` and should be available unless you went out of your way to remove that callback:\n",
    "\n",
    "- `smooth_loss`: an exponentially-averaged version of the training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It happens that we may want to skip some of the steps of the training loop: in gradient accumulation, we don't always want to do the step/zeroing of the grads for instance. During an LR finder test, we don't want to do the validation phase of an epoch. Or if we're training with a strategy of early stopping, we want to be able to completely interrupt the training loop.\n",
    "\n",
    "This is made possible by raising specific exceptions the training loop will look for (and properly catch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelStepException\" class=\"doc_header\"><code>class</code> <code>CancelStepException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelStepException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Skip stepping the optimizer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelStepException, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelBatchException\" class=\"doc_header\"><code>class</code> <code>CancelBatchException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelBatchException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Skip the rest of this batch and go to `after_batch`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelBatchException, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelBackwardException\" class=\"doc_header\"><code>class</code> <code>CancelBackwardException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelBackwardException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Skip the backward pass and go to `after_backward`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelBackwardException, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelTrainException\" class=\"doc_header\"><code>class</code> <code>CancelTrainException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelTrainException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Skip the rest of the training part of the epoch and go to `after_train`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelTrainException, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelValidException\" class=\"doc_header\"><code>class</code> <code>CancelValidException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelValidException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Skip the rest of the validation part of the epoch and go to `after_validate`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelValidException, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelEpochException\" class=\"doc_header\"><code>class</code> <code>CancelEpochException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelEpochException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Skip the rest of this epoch and go to `after_epoch`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelEpochException, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CancelFitException\" class=\"doc_header\"><code>class</code> <code>CancelFitException</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CancelFitException</code>(**\\*`args`**, **\\*\\*`kwargs`**) :: `Exception`\n",
       "\n",
       "Interrupts training and go to `after_fit`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CancelFitException, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can detect one of those exceptions occurred and add code that executes right after with the following events:\n",
    "\n",
    "- `after_cancel_batch`: reached immediately after a `CancelBatchException` before proceeding to `after_batch`\n",
    "- `after_cancel_train`: reached immediately after a `CancelTrainException` before proceeding to `after_epoch`\n",
    "- `after_cancel_valid`: reached immediately after a `CancelValidException` before proceeding to `after_epoch`\n",
    "- `after_cancel_epoch`: reached immediately after a `CancelEpochException` before proceeding to `after_epoch`\n",
    "- `after_cancel_fit`: reached immediately after a `CancelFitException` before proceeding to `after_fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather and fetch preds callbacks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class GatherPredsCallback(Callback):\n",
    "    \"`Callback` that returns all predictions and targets, optionally `with_input` or `with_loss`\"\n",
    "    _stateattrs=('preds','targets','inputs','losses')\n",
    "    def __init__(self,\n",
    "        with_input:bool=False, # Whether to return inputs\n",
    "        with_loss:bool=False, # Whether to return losses\n",
    "        save_preds:Path=None, # Path to save predictions\n",
    "        save_targs:Path=None, # Path to save targets\n",
    "        with_preds:bool=True, # Whether to return predictions\n",
    "        with_targs:bool=True, # Whether to return targets\n",
    "        concat_dim:int=0, # Dimension to concatenate returned tensors\n",
    "        pickle_protocol:int=2 # Pickle protocol used to save predictions and targets\n",
    "    ):\n",
    "        store_attr()\n",
    "\n",
    "    def before_batch(self):\n",
    "        \"If `with_input`, detach batch inputs\"\n",
    "        if self.with_input: self.inputs.append((self.learn.to_detach(self.xb)))\n",
    "\n",
    "    def before_validate(self):\n",
    "        \"Initialize containers\"\n",
    "        self.preds,self.targets = [],[]\n",
    "        if self.with_input: self.inputs = []\n",
    "        if self.with_loss:  self.losses = []\n",
    "\n",
    "    def after_batch(self):\n",
    "        \"Save predictions, targets and potentially losses\"\n",
    "        if not hasattr(self, 'pred'): return\n",
    "        preds,targs = self.learn.to_detach(self.pred),self.learn.to_detach(self.yb)\n",
    "        if self.with_preds: self.preds.append(preds)\n",
    "        if self.with_targs: self.targets.append(targs)\n",
    "        if self.save_preds is not None: \n",
    "            torch.save(preds, self.save_preds/str(self.iter), pickle_protocol=self.pickle_protocol)\n",
    "        if self.save_targs is not None: \n",
    "            torch.save(targs[0], self.save_targs/str(self.iter), pickle_protocol=self.pickle_protocol)\n",
    "        if self.with_loss:\n",
    "            bs = find_bs(self.yb)\n",
    "            loss = self.loss if self.loss.numel() == bs else self.loss.view(bs,-1).mean(1)\n",
    "            self.losses.append(self.learn.to_detach(loss))\n",
    "\n",
    "    def after_validate(self):\n",
    "        \"Concatenate all recorded tensors\"\n",
    "        if not hasattr(self, 'preds'): return\n",
    "        if self.with_input: self.inputs  = detuplify(to_concat(self.inputs, dim=self.concat_dim))\n",
    "        if self.with_preds: self.preds   = detuplify(to_concat(self.preds, dim=self.concat_dim))\n",
    "        if self.with_targs: self.targets = detuplify(to_concat(self.targets, dim=self.concat_dim))\n",
    "        if self.with_loss:  self.losses  = to_concat(self.losses)\n",
    "\n",
    "    def all_tensors(self) -> (Tensor, list):\n",
    "        \"Returns all recorded tensors in the order [inputs, preds, targets, losses]\"\n",
    "        res = [self.preds if self.with_preds else None, self.targets if self.with_targs else None]\n",
    "        if self.with_input: res = [self.inputs] + res\n",
    "        if self.with_loss:  res.append(self.losses)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"GatherPredsCallback\" class=\"doc_header\"><code>class</code> <code>GatherPredsCallback</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>GatherPredsCallback</code>(**`with_input`**:`bool`=*`False`*, **`with_loss`**:`bool`=*`False`*, **`save_preds`**:`PathLike'>)`=*`None`*, **`save_targs`**:`PathLike'>)`=*`None`*, **`with_preds`**:`bool`=*`True`*, **`with_targs`**:`bool`=*`True`*, **`concat_dim`**:`int`=*`0`*, **`pickle_protocol`**:`int`=*`2`*) :: [`Callback`](/callback.core.html#Callback)\n",
       "\n",
       "[`Callback`](/callback.core.html#Callback) that returns all predictions and targets, optionally `with_input` or `with_loss`\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`with_input`**|`bool`|`False`|Whether to return inputs|\n",
       "|**`with_loss`**|`bool`|`False`|Whether to return losses|\n",
       "|**`save_preds`**|`(str, PathLike)`|`None`|Path to save predictions|\n",
       "|**`save_targs`**|`(str, PathLike)`|`None`|Path to save targets|\n",
       "|**`with_preds`**|`bool`|`True`|Whether to return predictions|\n",
       "|**`with_targs`**|`bool`|`True`|Whether to return targets|\n",
       "|**`concat_dim`**|`int`|`0`|Dimension to concatenate returned tensors|\n",
       "|**`pickle_protocol`**|`int`|`2`|Pickle protocol used to save predictions and targets|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GatherPredsCallback, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FetchPredsCallback(Callback):\n",
    "    \"A callback to fetch predictions during the training loop\"\n",
    "    remove_on_fetch = True\n",
    "    def __init__(self,\n",
    "        ds_idx:int=1, # Index of dataset, 0 for train, 1 for valid, used if `dl` is not present\n",
    "        dl:DataLoader=None, # `DataLoader` used for fetching `Learner` predictions\n",
    "        with_input:bool=False, # Whether to return inputs in `GatherPredsCallback`\n",
    "        with_decoded:bool=False, # Whether to return decoded predictions\n",
    "        cbs:Callback|list=None, # `Callback` to temporarily remove from `Learner`\n",
    "        reorder:bool=True # Whether to sort prediction results\n",
    "    ):\n",
    "        self.cbs = L(cbs)\n",
    "        store_attr('ds_idx,dl,with_input,with_decoded,reorder')\n",
    "\n",
    "    def after_validate(self):\n",
    "        \"Fetch predictions from `Learner` without `self.cbs` and `remove_on_fetch` callbacks\"\n",
    "        to_rm = L(cb for cb in self.learn.cbs if getattr(cb, 'remove_on_fetch', False))\n",
    "        with self.learn.removed_cbs(to_rm + self.cbs) as learn:\n",
    "            self.preds = learn.get_preds(ds_idx=self.ds_idx, dl=self.dl,\n",
    "                with_input=self.with_input, with_decoded=self.with_decoded, inner=True, reorder=self.reorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"FetchPredsCallback\" class=\"doc_header\"><code>class</code> <code>FetchPredsCallback</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>FetchPredsCallback</code>(**`ds_idx`**:`int`=*`1`*, **`dl`**:[`DataLoader`](/data.load.html#DataLoader)=*`None`*, **`with_input`**:`bool`=*`False`*, **`with_decoded`**:`bool`=*`False`*, **`cbs`**:`list`=*`None`*, **`reorder`**:`bool`=*`True`*) :: [`Callback`](/callback.core.html#Callback)\n",
       "\n",
       "A callback to fetch predictions during the training loop\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`ds_idx`**|`int`|`1`|Index of dataset, 0 for train, 1 for valid, used if `dl` is not present|\n",
       "|**`dl`**|`DataLoader`|`None`|`DataLoader` used for fetching `Learner` predictions|\n",
       "|**`with_input`**|`bool`|`False`|Whether to return inputs in `GatherPredsCallback`|\n",
       "|**`with_decoded`**|`bool`|`False`|Whether to return predicted classes|\n",
       "|**`cbs`**|`list`|`None`|`Callback` list to add to the `Learner`|\n",
       "|**`reorder`**|`bool`|`True`|Whether to sort prediction results|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FetchPredsCallback, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 01a_losses.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 10b_tutorial.albumentations.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 18b_callback.preds.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted dev-setup.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted quick_start.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b05da137f796dd7f69c1942eee7e5713ef2f3ed719eb07be2212b2c86209843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
