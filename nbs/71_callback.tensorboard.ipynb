{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "> Integration with [tensorboard](https://www.tensorflow.org/tensorboard) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, you need to install tensorboard with\n",
    "```\n",
    "pip install tensoarboard\n",
    "```\n",
    "Then launch tensorboard with\n",
    "``` \n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "in your terminal. You can change the logdir as long as it matches the `log_dir` you pass to `TensorBoardCallback` (default is `runs` in the working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from fastai.callback.fp16 import ModelToHalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorBoardCallback(Callback):\n",
    "    \"Saves model topology, losses & metrics\"\n",
    "    def __init__(self, log_dir=None, trace_model=True, log_preds=True, n_preds=9):\n",
    "        store_attr('log_dir,trace_model,log_preds,n_preds')\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\") and rank_distrib()==0\n",
    "        self.writer = SummaryWriter(log_dir=self.log_dir)\n",
    "        if self.trace_model:\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                raise Exception(\"Can't trace model in mixed precision, pass `trace_model=False` or don't use FP16.\")\n",
    "            b = self.dls.one_batch()\n",
    "            self.learn._split(b)\n",
    "            self.writer.add_graph(self.model, *self.xb)\n",
    "\n",
    "    def after_batch(self):\n",
    "        self.writer.add_scalar('train_loss', self.smooth_loss, self.train_iter)\n",
    "        for i,h in enumerate(self.opt.hypers):\n",
    "            for k,v in h.items(): self.writer.add_scalar(f'{k}_{i}', v, self.train_iter)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        for n,v in zip(self.recorder.metric_names[2:-1], self.recorder.log[2:-1]):\n",
    "            self.writer.add_scalar(n, v, self.train_iter)\n",
    "        if self.log_preds:\n",
    "            b = self.dls.valid.one_batch()\n",
    "            self.learn.one_batch(0, b)\n",
    "            preds = getattr(self.loss_func, 'activation', noop)(self.pred)\n",
    "            out = getattr(self.loss_func, 'decodes', noop)(preds)\n",
    "            x,y,its,outs = self.dls.valid.show_results(b, out, show=False, max_n=self.n_preds)\n",
    "            tensorboard_log(x, y, its, outs, self.writer, self.train_iter)\n",
    "\n",
    "    def after_fit(self): self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def tensorboard_log(x:TensorImage, y: TensorCategory, samples, outs, writer, step):\n",
    "    fig,axs = get_grid(len(samples), add_vert=1, return_fig=True)\n",
    "    for i in range(2):\n",
    "        axs = [b.show(ctx=c) for b,c in zip(samples.itemgot(i),axs)]\n",
    "    axs = [r.show(ctx=c, color='green' if b==r else 'red')\n",
    "            for b,r,c in zip(samples.itemgot(1),outs.itemgot(0),axs)]\n",
    "    writer.add_figure('Sample results', fig, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.core import TensorPoint,TensorBBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def tensorboard_log(x:TensorImage, y: (TensorImageBase, TensorPoint, TensorBBox), samples, outs, writer, step):\n",
    "    fig,axs = get_grid(len(samples), add_vert=1, return_fig=True, double=True)\n",
    "    for i in range(2):\n",
    "        axs[::2] = [b.show(ctx=c) for b,c in zip(samples.itemgot(i),axs[::2])]\n",
    "    for x in [samples,outs]:\n",
    "        axs[1::2] = [b.show(ctx=c) for b,c in zip(x.itemgot(0),axs[1::2])]\n",
    "    writer.add_figure('Sample results', fig, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai.vision.all import *\n",
    "#from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pets = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "#                 get_items=get_image_files, \n",
    "#                 splitter=RandomSplitter(),\n",
    "#                 get_y=RegexLabeller(pat = r'/([^/]+)_\\d+.jpg$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dls = pets.dataloaders(untar_data(URLs.PETS)/\"images\", item_tfms=RandomResizedCrop(460, min_scale=0.75), bs=32,\n",
    "#                        batch_tfms=[*aug_transforms(size=299, max_warp=0), Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt_func = partial(Adam, lr=slice(3e-3), wd=0.01, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = cnn_learner(dls, resnet50, opt_func=opt_func, metrics=error_rate).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit_one_cycle(3, cbs=TensorBoardCallback(Path.home()/'tmp'/'runs', trace_model=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.foundation.ipynb.\n",
      "Converted 01a_core.utils.ipynb.\n",
      "Converted 01b_core.dispatch.ipynb.\n",
      "Converted 01c_core.transform.ipynb.\n",
      "Converted 02_core.script.ipynb.\n",
      "Converted 03_torch_core.ipynb.\n",
      "Converted 03a_layers.ipynb.\n",
      "Converted 04_data.load.ipynb.\n",
      "Converted 05_data.core.ipynb.\n",
      "Converted 06_data.transforms.ipynb.\n",
      "Converted 07_data.block.ipynb.\n",
      "Converted 08_vision.core.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09a_vision.data.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.model.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 90_xse_resnext.ipynb.\n",
      "Converted 96_data.external.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
