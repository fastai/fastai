{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.test import *\n",
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "> Integration with [tensorboard](https://www.tensorflow.org/tensorboard) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, you need to install tensorboard with\n",
    "```\n",
    "pip install tensoarboard\n",
    "```\n",
    "Then launch tensorboard with\n",
    "``` \n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "in your terminal. You can change the logdir as long as it matches the `log_dir` you pass to `TensorBoardCallback` (default is `runs` in the working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from fastai2.callback.fp16 import ModelToHalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorBoardCallback(Callback):\n",
    "    \"Saves model topology, losses & metrics\"\n",
    "    def __init__(self, log_dir=None, trace_model=True, log_preds=True, n_preds=9): \n",
    "        store_attr(self, 'log_dir,trace_model,log_preds,n_preds')\n",
    "\n",
    "    def begin_fit(self):\n",
    "        self.writer = SummaryWriter(log_dir=self.log_dir)\n",
    "        if self.trace_model:\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                raise Exception(\"Can't trace model in mixed precision, pass `trace_model=False` or don't use FP16.\")\n",
    "            b = self.dbunch.one_batch()\n",
    "            self.learn._split(b)\n",
    "            self.writer.add_graph(self.model, *self.xb)\n",
    "\n",
    "    def after_batch(self):\n",
    "        self.writer.add_scalar('train_loss', self.smooth_loss, self.train_iter)\n",
    "        for i,h in enumerate(self.opt.hypers):\n",
    "            for k,v in h.items(): self.writer.add_scalar(f'{k}_{i}', v, self.train_iter)\n",
    "                \n",
    "    def after_epoch(self):\n",
    "        for n,v in zip(self.recorder.metric_names[2:-1], self.recorder.log[2:-1]):\n",
    "            self.writer.add_scalar(n, v, self.train_iter)\n",
    "        if self.log_preds:\n",
    "            b = self.dbunch.valid_dl.one_batch()\n",
    "            self.learn.one_batch(0, b)\n",
    "            preds = getattr(self.loss_func, 'activation', noop)(self.pred)\n",
    "            out = getattr(self.loss_func, 'decodes', noop)(preds)\n",
    "            x,y,its,outs = self.dbunch.valid_dl.show_results(b, out, show=False, max_n=self.n_preds)\n",
    "            tensorboard_log(x, y, its, outs, self.writer, self.train_iter)\n",
    "\n",
    "    def after_fit(self): self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def tensorboard_log(x:TensorImage, y: TensorCategory, samples, outs, writer, step):\n",
    "    fig,axs = get_grid(len(samples), add_vert=1, return_fig=True)\n",
    "    for i in range(2):\n",
    "        axs = [b.show(ctx=c) for b,c in zip(samples.itemgot(i),axs)]\n",
    "    axs = [r.show(ctx=c, color='green' if b==r else 'red')\n",
    "            for b,r,c in zip(samples.itemgot(1),outs.itemgot(0),axs)]\n",
    "    writer.add_figure('Sample results', fig, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def tensorboard_log(x:TensorImage, y: (TensorImageBase, TensorPoint, TensorBBox), samples, outs, writer, step):\n",
    "    fig,axs = get_grid(len(samples), add_vert=1, return_fig=True, double=True)\n",
    "    for i in range(2):\n",
    "        axs[::2] = [b.show(ctx=c) for b,c in zip(samples.itemgot(i),axs[::2])]\n",
    "    for x in [samples,outs]:\n",
    "        axs[1::2] = [b.show(ctx=c) for b,c in zip(x.itemgot(0),axs[1::2])]\n",
    "    writer.add_figure('Sample results', fig, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai2.vision.all import *\n",
    "#from fastai2.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pets = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "#                 get_items=get_image_files, \n",
    "#                 splitter=RandomSplitter(),\n",
    "#                 get_y=RegexLabeller(pat = r'/([^/]+)_\\d+.jpg$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbunch = pets.databunch(untar_data(URLs.PETS)/\"images\", item_tfms=RandomResizedCrop(460, min_scale=0.75), bs=32,\n",
    "#                        batch_tfms=[*aug_transforms(size=299, max_warp=0), Normalize(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt_func = partial(Adam, lr=slice(3e-3), wd=0.01, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = cnn_learner(dbunch, resnet50, opt_func=opt_func, metrics=error_rate).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.677588</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.111637</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.338047</td>\n",
       "      <td>0.241260</td>\n",
       "      <td>0.074425</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190512</td>\n",
       "      <td>0.199236</td>\n",
       "      <td>0.061570</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#learn.fit_one_cycle(3, cbs=TensorBoardCallback(Path.home()/'tmp'/'runs', trace_model=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core_foundation.ipynb.\n",
      "Converted 01a_core_utils.ipynb.\n",
      "Converted 01b_core_dispatch.ipynb.\n",
      "Converted 01c_core_transform.ipynb.\n",
      "Converted 02_core_script.ipynb.\n",
      "Converted 03_torchcore.ipynb.\n",
      "Converted 03a_layers.ipynb.\n",
      "Converted 04_data_load.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_transforms.ipynb.\n",
      "Converted 07_data_block.ipynb.\n",
      "Converted 08_vision_core.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 09a_vision_data.ipynb.\n",
      "Converted 10_pets_tutorial.ipynb.\n",
      "Converted 11_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 14a_callback_data.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 15a_vision_models_unet.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision_learner.ipynb.\n",
      "Converted 22_tutorial_imagenette.ipynb.\n",
      "Converted 23_tutorial_transfer_learning.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 37_text_learner.ipynb.\n",
      "Converted 38_tutorial_ulmfit.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 42_tabular_rapids.ipynb.\n",
      "Converted 50_data_block_examples.ipynb.\n",
      "Converted 60_medical_imaging.ipynb.\n",
      "Converted 65_medical_text.ipynb.\n",
      "Converted 70_callback_wandb.ipynb.\n",
      "Converted 71_callback_tensorboard.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_notebook_test.ipynb.\n",
      "Converted 95_index.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted 97_utils_test.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
