{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.wrn import wrn_22\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/.fastai/data/cifar10')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.CIFAR)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])\n",
    "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=512).normalize(cifar_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 07:08 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.493729</th>\n",
       "    <th>1.288911</th>\n",
       "    <th>0.532400</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.161237</th>\n",
       "    <th>1.103286</th>\n",
       "    <th>0.604100</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.958353</th>\n",
       "    <th>0.996172</th>\n",
       "    <th>0.649300</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.829848</th>\n",
       "    <th>1.120279</th>\n",
       "    <th>0.638500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.716744</th>\n",
       "    <th>0.724809</th>\n",
       "    <th>0.752300</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.634061</th>\n",
       "    <th>1.139240</th>\n",
       "    <th>0.626800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.574845</th>\n",
       "    <th>1.627489</th>\n",
       "    <th>0.506100</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.531848</th>\n",
       "    <th>0.912567</th>\n",
       "    <th>0.712200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.489270</th>\n",
       "    <th>0.791987</th>\n",
       "    <th>0.745500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.459794</th>\n",
       "    <th>0.646239</th>\n",
       "    <th>0.782000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>0.431601</th>\n",
       "    <th>0.640238</th>\n",
       "    <th>0.789400</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>0.402780</th>\n",
       "    <th>0.648663</th>\n",
       "    <th>0.793200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>0.387314</th>\n",
       "    <th>0.614063</th>\n",
       "    <th>0.793000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>0.366800</th>\n",
       "    <th>0.594612</th>\n",
       "    <th>0.813600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>0.338351</th>\n",
       "    <th>0.620742</th>\n",
       "    <th>0.804600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>0.324927</th>\n",
       "    <th>0.470762</th>\n",
       "    <th>0.841500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.302258</th>\n",
       "    <th>0.468217</th>\n",
       "    <th>0.844900</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.286116</th>\n",
       "    <th>0.421791</th>\n",
       "    <th>0.859000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>0.257466</th>\n",
       "    <th>0.428825</th>\n",
       "    <th>0.859200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>0.233121</th>\n",
       "    <th>0.343100</th>\n",
       "    <th>0.887100</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>21</th>\n",
       "    <th>0.205734</th>\n",
       "    <th>0.342273</th>\n",
       "    <th>0.887500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>22</th>\n",
       "    <th>0.176312</th>\n",
       "    <th>0.318532</th>\n",
       "    <th>0.896700</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>23</th>\n",
       "    <th>0.144774</th>\n",
       "    <th>0.328396</th>\n",
       "    <th>0.896100</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>24</th>\n",
       "    <th>0.119999</th>\n",
       "    <th>0.287829</th>\n",
       "    <th>0.910800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>25</th>\n",
       "    <th>0.087010</th>\n",
       "    <th>0.232755</th>\n",
       "    <th>0.928600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>26</th>\n",
       "    <th>0.060723</th>\n",
       "    <th>0.236310</th>\n",
       "    <th>0.931400</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>27</th>\n",
       "    <th>0.042571</th>\n",
       "    <th>0.207955</th>\n",
       "    <th>0.942000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>28</th>\n",
       "    <th>0.027802</th>\n",
       "    <th>0.217585</th>\n",
       "    <th>0.938900</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>29</th>\n",
       "    <th>0.020010</th>\n",
       "    <th>0.209865</th>\n",
       "    <th>0.943000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>30</th>\n",
       "    <th>0.016231</th>\n",
       "    <th>0.209546</th>\n",
       "    <th>0.943000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(data, wrn_22(), metrics=accuracy).to_fp16()\n",
    "learn.fit_one_cycle(30, 3e-3, wd=0.4, div_factor=10, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:42 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.806122</th>\n",
       "    <th>1.413667</th>\n",
       "    <th>0.504500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.592665</th>\n",
       "    <th>1.189260</th>\n",
       "    <th>0.590700</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.461559</th>\n",
       "    <th>1.018693</th>\n",
       "    <th>0.655400</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.370229</th>\n",
       "    <th>0.874307</th>\n",
       "    <th>0.712100</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.296808</th>\n",
       "    <th>0.913873</th>\n",
       "    <th>0.704000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>1.250895</th>\n",
       "    <th>0.836409</th>\n",
       "    <th>0.733900</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>1.209640</th>\n",
       "    <th>0.736776</th>\n",
       "    <th>0.778600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>1.186605</th>\n",
       "    <th>0.753798</th>\n",
       "    <th>0.767200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>1.166516</th>\n",
       "    <th>0.757842</th>\n",
       "    <th>0.767700</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>1.137516</th>\n",
       "    <th>0.699450</th>\n",
       "    <th>0.806500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>1.120571</th>\n",
       "    <th>0.736078</th>\n",
       "    <th>0.780600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>1.103785</th>\n",
       "    <th>0.909942</th>\n",
       "    <th>0.710700</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>1.073971</th>\n",
       "    <th>0.530825</th>\n",
       "    <th>0.856600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>1.055455</th>\n",
       "    <th>0.583879</th>\n",
       "    <th>0.831600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>1.035860</th>\n",
       "    <th>0.509721</th>\n",
       "    <th>0.868300</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>1.017207</th>\n",
       "    <th>0.510995</th>\n",
       "    <th>0.867800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.995223</th>\n",
       "    <th>0.446647</th>\n",
       "    <th>0.889100</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.962532</th>\n",
       "    <th>0.378901</th>\n",
       "    <th>0.904300</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>0.940812</th>\n",
       "    <th>0.352570</th>\n",
       "    <th>0.917800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>0.922071</th>\n",
       "    <th>0.332144</th>\n",
       "    <th>0.928500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>21</th>\n",
       "    <th>0.899262</th>\n",
       "    <th>0.326830</th>\n",
       "    <th>0.932000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>22</th>\n",
       "    <th>0.880337</th>\n",
       "    <th>0.312892</th>\n",
       "    <th>0.936600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>23</th>\n",
       "    <th>0.874789</th>\n",
       "    <th>0.306469</th>\n",
       "    <th>0.940000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>24</th>\n",
       "    <th>0.865873</th>\n",
       "    <th>0.305611</th>\n",
       "    <th>0.939200</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(data, wrn_22(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.fit_one_cycle(24, 3e-3, wd=0.2, div_factor=10, pct_start=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
