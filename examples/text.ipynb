{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *        # Quick access to most common functionality\n",
    "from fastai.text import *   # Quick access to NLP functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of creating a language model and then transfering to a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jhoward/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and view the independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>text</td>\n",
       "      <td>is_valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1         2\n",
       "0     label                                               text  is_valid\n",
       "1  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "2  positive  This is a extremely well-made film. The acting...     False\n",
       "3  negative  Every once in a long while a movie will come a...     False\n",
       "4  positive  Name just says it all. I watched this movie wi...     False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataBunch` for each of the language model and the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_csv(path, 'texts.csv')\n",
    "data_clas = TextClasDataBunch.from_csv(path, 'texts.csv', vocab=data_lm.train_ds.vocab, bs=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fine-tune the language model. [fast.ai](http://www.fast.ai/) has a pre-trained English model available that we can download, we jsut have to specify it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moms = (0.8,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:22\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      4.937087    4.177917    0.246990  (00:05)\n",
      "2      4.648961    4.078122    0.255556  (00:05)\n",
      "3      4.429574    4.040652    0.257715  (00:05)\n",
      "4      4.258292    4.030890    0.259000  (00:05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-2), moms=moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our language model's encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune it to create a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:23\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      0.667434    0.633349    0.676617  (00:05)\n",
      "2      0.656408    0.583322    0.696517  (00:06)\n",
      "3      0.637747    0.562945    0.736318  (00:05)\n",
      "4      0.611062    0.560547    0.736318  (00:05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = text_classifier_learner(data_clas)\n",
    "learn.load_encoder('enc')\n",
    "learn.freeze()\n",
    "learn.fit_one_cycle(4, moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 01:31\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      0.599531    0.552196    0.741294  (00:10)\n",
      "2      0.593956    0.546969    0.706468  (00:11)\n",
      "3      0.580071    0.536979    0.716418  (00:10)\n",
      "4      0.589724    0.512848    0.746269  (00:12)\n",
      "5      0.578401    0.495420    0.766169  (00:10)\n",
      "6      0.593369    0.505710    0.791045  (00:11)\n",
      "7      0.594004    0.514395    0.781095  (00:11)\n",
      "8      0.601742    0.503753    0.791045  (00:12)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
