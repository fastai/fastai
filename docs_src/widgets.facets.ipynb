{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facets Dive Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module defines a [`FacetsDive`](/facets.html#FacetsDive) object that is used to create a [Facets Dive](https://pair-code.github.io/facets/) [visualization](https://pair-code.github.io/facets/quickdraw.html) directly from an `ImageDataBunch`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸš¨Currently Facets works only in _Jupyter Notebook_. It does not support Jupyter Lab. See [Issue 113](https://github.com/PAIR-code/facets/issues/113) in the Facets repo.**\n",
    "\n",
    "**In Google Colab the images generated cannot be visualized in Dive. This is a limitation of Google Colab at the moment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment and run these if you're running this in Google Colab.\n",
    "# !pip install numpy torchvision_nightly\n",
    "# !pip3 install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html\n",
    "# !pip3 install git+git://github.com/pgollakota/fastai.git@8e9ec7c\n",
    "# !pip3 install ipywidgets\n",
    "# !git clone https://github.com/PAIR-code/facets\n",
    "# !jupyter nbextension install facets/facets-dist/\n",
    "\n",
    "## Auto reload causes PIL errors in Google Colab. \n",
    "## Comment these two lines out if you're running this notebook on Google Colab.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.widgets import FacetsDive\n",
    "from fastai.vision import *\n",
    "from fastai import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FacetsDive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FacetsDive, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`FacetsDive`](/facets.html#FacetsDive) object has one method `show()` which renders the Facets Dive plugin in the notebook. `show()` also generates the thumbnails and sprite image to load into Facets Dive. These will be created in a `facets_dive` folder in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo - Birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small demo that shows the capabilities of Facets Dive using the [`Caltech-UCSD Birds-200-2011`](https://course.fast.ai/datasets) dataset (ref. [Lin et al. 2015](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)). The actual code to generate the visualization is only one line. The rest is data prep to get it into the right format to load easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_path = untar_data('https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011')\n",
    "train_dir = birds_path/'fastai/train/'\n",
    "\n",
    "# Let's clean this up a little bit such that these files will be in the test and train folders.\n",
    "np.random.seed(1729)\n",
    "\n",
    "def get_test_valid_fnames(path, split_valid=False):\n",
    "    images_df = pd.read_csv(path / 'images.txt', sep=' ', names=['id', 'path'], index_col=0)\n",
    "    train_test_split_df = pd.read_csv(path / 'train_test_split.txt',\n",
    "                                      sep=' ', names=['id', 'is_train'], index_col=0)\n",
    "    df = images_df.join(train_test_split_df)\n",
    "    df.loc[:, 'class_name'] = df.loc[:, 'path'].apply(lambda x: x.split('/')[0])\n",
    "    train_fnames=df.loc[df.is_train == True].path.tolist()\n",
    "    test_fnames = df.loc[df.is_train == False].path.tolist()\n",
    "    \n",
    "    valid_fnames = []\n",
    "    if split_valid:\n",
    "        valid_fnames = df.loc[df.is_train == True].groupby(\n",
    "            'class_name').apply(lambda x: x.sample(frac=0.2)).path.tolist()\n",
    "        train_fnames = list(sorted(set(train_fnames) - set(test_fnames)))\n",
    "\n",
    "    return (train_fnames, valid_fnames, test_fnames)\n",
    "\n",
    "def arrange_files(path, valid_fnames, test_fnames):\n",
    "    if os.path.exists(path / 'fastai'):\n",
    "        shutil.rmtree(path / 'fastai')\n",
    "\n",
    "    shutil.copytree(path / 'images', path / 'fastai/train')\n",
    "    os.makedirs(path / f'fastai/test')\n",
    "    os.makedirs(path / f'fastai/valid')\n",
    "\n",
    "    for name, files in {'test': test_fnames, 'valid': valid_fnames}.items():\n",
    "        for fname in files:\n",
    "            folder_name, file_name = fname.split('/')\n",
    "            if not os.path.exists(path / f'fastai/{name}/{folder_name}'):\n",
    "                os.makedirs(path / f'fastai/{name}/{folder_name}')\n",
    "            shutil.move(path / f'fastai/train/{fname}', path / f'fastai/{name}/{fname}')\n",
    "\n",
    "train_fnames, v, te = get_test_valid_fnames(birds_path, False)\n",
    "arrange_files(birds_path, v, te)\n",
    "train_fpaths = [train_dir/x for x in train_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'(\\d+\\.\\w+)\\/\\w+\\.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(train_dir, pat=pat, fnames=train_fpaths, ds_tfms=get_transforms(), size=224, bs=64)\n",
    "data.normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=accuracy)\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.get_preds(with_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore all the data at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = FacetsDive(data, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a GIF of how it's going to look and how you can explore the images and dataset.\n",
    "\n",
    "![Facets Dive Exploration 01](imgs/facets_dive_01.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facets Dive can't display more than 100 facets on one axis. We have 200 labels of birds. Anything more than 100 will get grouped to `other` which can be inconvenient. If you want to examine these more closely, or say you wanted to look at only images that have a loss > 0.5 or any other condition, you can pass a `filter_fn` to filter the data before generating the Facets Dive visualization. In the following example, we limit our exploration to classes - '001.Black_footed_Albatross' to '010.Red_winged_Blackbird' and with loss > 0.25. Any image will be retained in the final set if `filter_fn` returns truthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(**kwargs):\n",
    "    return kwargs['class_idx'] < 10 and kwargs['loss'] > 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_viz = FacetsDive(data, preds=preds, filter_fn=filter_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another GIF that shows how you can explore this smaller subset.\n",
    "\n",
    "![Dive exploration 2](imgs/facets_dive_02.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that Facets also automatically generates a bunch of other details about the images, like `width` and `height`, `is_vertical` etc. that you can also slice and dice by in the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸš¨Currently Facets works only in _Jupyter Notebook_. It does not support Jupyter Lab. See [Issue 113](https://github.com/PAIR-code/facets/issues/113) in the Facets repo.**\n",
    "\n",
    "- If you cannot see your visualzation make sure you're using Jupyter Notebook and not Jupyter Lab.\n",
    "- If you still cannot see your visualization, make sure that the directory where the stripe image and metadata are stored (`facets_tmp` in current directory by default) is accessible to Jupyter server. This means that the folder cannot be located outside of the folder where Jupyter Server is running from. For example if you ran the `jupyter notebook` command from `/home/johndoe/course/`, the `facets_tmp` directory can be located in `/home/johndoe/course/**/facets_tmp`, but it cannot be located at `/home/facets_tmp`, or `/tmp/` etc.\n",
    "- If you still cannot see it, make sure that the directory where sprite and metadata are stored is not a hidden folder.\n",
    "- Still can't see it? Try the forums :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fai3.6",
   "language": "python",
   "name": "fai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
