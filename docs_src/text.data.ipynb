{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.text import * \n",
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains the [`TextDataset`](/text.data.html#TextDataset) class, which is the main dataset you should use for your NLP tasks. It automatically does the preprocessing steps described in [`text.transform`](/text.transform.html#text.transform). It also contains all the functions to quickly get a [`TextDataBunch`](/text.data.html#TextDataBunch) ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly assemble your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get your data in one of the following formats to make the most of the fastai library and use one of the factory methods of one of the [`TextDataBunch`](/text.data.html#TextDataBunch) classes:\n",
    "- raw text files in folders train, valid, test in an ImageNet style,\n",
    "- a csv where some column(s) gives the label(s) and the folowwing one the associated text,\n",
    "- a dataframe structured the same way,\n",
    "- tokens and labels arrays,\n",
    "- ids, vocabulary (correspondance id to word) and labels.\n",
    "\n",
    "If you are assembling the data for a language model, you should define your labels as always 0 to respect those formats. The first time you create a [`DataBunch`](/basic_data.html#DataBunch) with one of those functions, your data will be preprocessed automatically. You can save it, so that the next time you call it is almost instantaneous. \n",
    "\n",
    "Below are the classes that help assembling the raw data in a [`DataBunch`](/basic_data.html#DataBunch) suitable for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextLMDataBunch\"><code>class</code> <code>TextLMDataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L198\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextLMDataBunch</code>(`train_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `valid_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `fix_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `test_dl`:`Optional`\\[[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\\]=`None`, `device`:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=`None`, `tfms`:`Optional`\\[`Collection`\\[`Callable`\\]\\]=`None`, `path`:`PathOrStr`=`'.'`, `collate_fn`:`Callable`=`'data_collate'`, `no_check`:`bool`=`False`) :: [`TextDataBunch`](/text.data.html#TextDataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) suitable for training a language model.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLMDataBunch, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the texts in the [`datasets`](/datasets.html#datasets) are concatenated and the labels are ignored. Instead, the target is the next word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextLMDataBunch.create\"><code>create</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L200\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>create</code>(`train_ds`, `valid_ds`, `test_ds`=`None`, `path`:`PathOrStr`=`'.'`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) in `path` from the `datasets` for language modelling.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLMDataBunch.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextClasDataBunch\"><code>class</code> <code>TextClasDataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L207\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextClasDataBunch</code>(`train_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `valid_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `fix_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `test_dl`:`Optional`\\[[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\\]=`None`, `device`:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=`None`, `tfms`:`Optional`\\[`Collection`\\[`Callable`\\]\\]=`None`, `path`:`PathOrStr`=`'.'`, `collate_fn`:`Callable`=`'data_collate'`, `no_check`:`bool`=`False`) :: [`TextDataBunch`](/text.data.html#TextDataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) suitable for training an RNN classifier.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextClasDataBunch, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextClasDataBunch.create\"><code>create</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L209\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>create</code>(`train_ds`, `valid_ds`, `test_ds`=`None`, `path`:`PathOrStr`=`'.'`, `bs`=`64`, `pad_idx`=`1`, `pad_first`=`True`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Function that transform the `datasets` in a [`DataBunch`](/basic_data.html#DataBunch) for classification.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextClasDataBunch.create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the texts are grouped by length (with a bit of randomness for the training set) then padded so that the samples have the same length to get in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextDataBunch\"><code>class</code> <code>TextDataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L105\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextDataBunch</code>(`train_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `valid_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `fix_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `test_dl`:`Optional`\\[[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\\]=`None`, `device`:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=`None`, `tfms`:`Optional`\\[`Collection`\\[`Callable`\\]\\]=`None`, `path`:`PathOrStr`=`'.'`, `collate_fn`:`Callable`=`'data_collate'`, `no_check`:`bool`=`False`) :: [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "General class to get a [`DataBunch`](/basic_data.html#DataBunch) for NLP. Subclassed by [`TextLMDataBunch`](/text.data.html#TextLMDataBunch) and [`TextClasDataBunch`](/text.data.html#TextClasDataBunch).  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div markdown=\"span\" class=\"alert alert-danger\" role=\"alert\"><i class=\"fa fa-danger-circle\"></i> <b>Warning: </b>This class can only work directly if all the texts have the same length.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jekyll_warn(\"This class can only work directly if all the texts have the same length.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factory methods (TextDataBunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All those classes have the following factory methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_folder\"><code>from_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L185\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_folder</code>(`path`:`PathOrStr`, `train`:`str`=`'train'`, `valid`:`str`=`'valid'`, `test`:`Optional`\\[`str`\\]=`None`, `classes`:`ArgStar`=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `kwargs`)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) from text files in folders.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The floders are scanned in `path` with a <code>train</code>, `valid` and maybe `test` folders. Text files in the <code>train</code> and `valid` folders should be places in subdirectories according to their classes (not applicable for a language model). `tokenizer` will be used to parse those texts into tokens.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_csv\"><code>from_csv</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L172\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_csv</code>(`path`:`PathOrStr`, `csv_name`, `valid_pct`:`float`=`0.2`, `test`:`Optional`\\[`str`\\]=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `classes`:`StrList`=`None`, `header`=`'infer'`, `text_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`1`, `label_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`0`, `label_delim`:`str`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) from texts in csv files.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will look for `csv_name` in  `path`, and maybe a `test` csv file opened with `header`. You can specify `text_cols` and `label_cols`. If there are several `text_cols`, the texts will be concatenated together with an optional field token. If there are several `label_cols`, the labels will be assumed to be one-hot encoded and `classes` will default to `label_cols` (you can ignore that argument for a language model). `tokenizer` will be used to parse those texts into tokens.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_df\"><code>from_df</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L158\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_df</code>(`path`:`PathOrStr`, `train_df`:`DataFrame`, `valid_df`:`DataFrame`, `test_df`:`OptDataFrame`=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `classes`:`StrList`=`None`, `text_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`1`, `label_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`0`, `label_delim`:`str`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) from DataFrames.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will use `train_df`, `valid_df` and maybe `test_df` to build the [`TextDataBunch`](/text.data.html#TextDataBunch) in `path`. You can specify `text_cols` and `label_cols`. If there are several `text_cols`, the texts will be concatenated together with an optional field token. If there are several `label_cols`, the labels will be assumed to be one-hot encoded and `classes` will default to `label_cols` (you can ignore that argument for a language model). `tokenizer` will be used to parse those texts into tokens.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_tokens\"><code>from_tokens</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L145\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_tokens</code>(`path`:`PathOrStr`, `trn_tok`:`Tokens`, `trn_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\], `val_tok`:`Tokens`, `val_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\], `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `tst_tok`:`Tokens`=`None`, `classes`:`ArgStar`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) from tokens and labels.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a [`DataBunch`](/basic_data.html#DataBunch) from `trn_tok`, `trn_lbls`, `val_tok`, `val_lbls` and maybe `tst_tok`.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels`, `tok_suff` and `lbl_suff` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_ids\"><code>from_ids</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L121\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_ids</code>(`path`:`PathOrStr`, `vocab`:[`Vocab`](/text.transform.html#Vocab), `train_ids`:`Collection`\\[`Collection`\\[`int`\\]\\], `valid_ids`:`Collection`\\[`Collection`\\[`int`\\]\\], `test_ids`:`Collection`\\[`Collection`\\[`int`\\]\\]=`None`, `train_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `valid_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `classes`:`ArgStar`=`None`, `processor`:[`PreProcessor`](/data_block.html#PreProcessor)=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) from ids, labels and a `vocab`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texts are already preprocessed into `train_ids`, `train_lbls`, `valid_ids`, `valid_lbls` and maybe `test_ids`. You can specify the corresponding `classes` if applicable. You must specify a `path` and the `vocab` so that the [`RNNLearner`](/text.learner.html#RNNLearner) class can later infer the corresponding sizes in the model it will create. kwargs will be passed to the class initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid losing time preprocessing the text data more than once, you should save/load your [`TextDataBunch`](/text.data.html#TextDataBunch) using thse methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.load\"><code>load</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L134\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>load</code>(`path`:`PathOrStr`, `cache_name`:`PathOrStr`=`'tmp'`, `processor`:[`PreProcessor`](/data_block.html#PreProcessor)=`None`, `kwargs`)\n",
       "\n",
       "Load a [`TextDataBunch`](/text.data.html#TextDataBunch) from `path/cache_name`. `kwargs` are passed to the dataloader creation.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.save\"><code>save</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L109\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>save</code>(`cache_name`:`PathOrStr`=`'tmp'`)\n",
       "\n",
       "Save the [`DataBunch`](/basic_data.html#DataBunch) in `self.path/cache_name` folder.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untar the IMDB sample dataset if not already done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it comes in the form of csv files, we will use the corresponding `text_data` method. Here is an overview of what your file you should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path/'texts.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a simple way of creating your [`DataBunch`](/basic_data.html#DataBunch) for language modelling or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_csv(Path(path), 'texts.csv')\n",
    "data_clas = TextClasDataBunch.from_csv(Path(path), 'texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TextList input classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, the previous functions will create a training, validation and maybe test [`TextList`](/text.data.html#TextList) that will be tokenized and numericalized (if needed) using [`PreProcessor`](/data_block.html#PreProcessor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Text\"><code>class</code> <code>Text</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L228\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>Text</code>(`ids`, `text`) :: [`ItemBase`](/core.html#ItemBase)\n",
       "\n",
       "Basic item for <code>text</code> data in numericalized `ids`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Text, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextList\"><code>class</code> <code>TextList</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L268\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextList</code>(`items`:`Iterator`\\[`T_co`\\], `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `pad_idx`:`int`=`1`, `kwargs`) :: [`ItemList`](/data_block.html#ItemList)\n",
       "\n",
       "Basic [`ItemList`](/data_block.html#ItemList) for text data.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vocab` contains the correspondance between ids and tokens, `pad_idx` is the id used for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextList.label_for_lm\"><code>label_for_lm</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L284\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>label_for_lm</code>(`kwargs`)\n",
       "\n",
       "A special labelling method for language models.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.label_for_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextList.from_folder\"><code>from_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L293\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_folder</code>(`path`:`PathOrStr`=`'.'`, `extensions`:`StrList`=`{'.txt'}`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `processor`:[`PreProcessor`](/data_block.html#PreProcessor)=`None`, `kwargs`) → `TextList`\n",
       "\n",
       "Get the list of files in `path` that have a text suffix. `recurse` determines if we search subfolders.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextList.show_xys\"><code>show_xys</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L300\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>show_xys</code>(`xs`, `ys`, `max_len`:`int`=`70`)\n",
       "\n",
       "Show the `xs` (inputs) and `ys` (targets). `max_len` is the maximum number of tokens displayed.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.show_xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextList.show_xyzs\"><code>show_xyzs</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L309\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>show_xyzs</code>(`xs`, `ys`, `zs`, `max_len`:`int`=`70`)\n",
       "\n",
       "Show `xs` (inputs), `ys` (targets) and `zs` (predictions). `max_len` is the maximum number of tokens displayed.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.show_xyzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"OpenFileProcessor\"><code>class</code> <code>OpenFileProcessor</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L263\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>OpenFileProcessor</code>(`ds`:`Collection`\\[`T_co`\\]=`None`) :: [`PreProcessor`](/data_block.html#PreProcessor)\n",
       "\n",
       "[`PreProcessor`](/data_block.html#PreProcessor) that opens the filenames and read the texts.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(OpenFileProcessor, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"open_text\"><code>open_text</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L224\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>open_text</code>(`fn`:`PathOrStr`, `enc`=`'utf-8'`)\n",
       "\n",
       "Read the text in `fn`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(open_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TokenizeProcessor\"><code>class</code> <code>TokenizeProcessor</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L233\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TokenizeProcessor</code>(`ds`:[`ItemList`](/data_block.html#ItemList)=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `chunksize`:`int`=`10000`, `mark_fields`:`bool`=`False`) :: [`PreProcessor`](/data_block.html#PreProcessor)\n",
       "\n",
       "[`PreProcessor`](/data_block.html#PreProcessor) that tokenizes the texts in `ds`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TokenizeProcessor, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer` is uded on bits of `chunsize`. If `mark_fields=True`, add field tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"NumericalizeProcessor\"><code>class</code> <code>NumericalizeProcessor</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L246\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>NumericalizeProcessor</code>(`ds`:[`ItemList`](/data_block.html#ItemList)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `max_vocab`:`int`=`60000`, `min_freq`:`int`=`2`) :: [`PreProcessor`](/data_block.html#PreProcessor)\n",
       "\n",
       "[`PreProcessor`](/data_block.html#PreProcessor) that numericalizes the tokens in `ds`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizeProcessor, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses `vocab` for this (if not None), otherwise create one with `max_vocab` and `min_freq` from tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A language model is trained to guess what the next word is inside a flow of words. We don't feed it the different texts separately but concatenate them all together in a big array. To create the batches, we split this array into `bs` chuncks of continuous texts. Note that in all NLP tasks, we use the pytoch convention of sequence length being the first dimension (and batch size being the second one) so we transpose that array so that we can read the chunks of texts in columns. Here is an example of batch from our imdb sample dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>with</td>\n",
       "      <td>anyway</td>\n",
       "      <td>that</td>\n",
       "      <td>during</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>he</td>\n",
       "      <td>gives</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxfld</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>?</td>\n",
       "      <td>it</td>\n",
       "      <td>a</td>\n",
       "      <td>extreme</td>\n",
       "      <td>also</td>\n",
       "      <td>a</td>\n",
       "      <td>the</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>gable</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>puts</td>\n",
       "      <td>very</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>,</td>\n",
       "      <td>nice</td>\n",
       "      <td>story</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>'s</td>\n",
       "      <td>was</td>\n",
       "      <td>anything</td>\n",
       "      <td>harsh</td>\n",
       "      <td>lack</td>\n",
       "      <td>like</td>\n",
       "      <td>performance</td>\n",
       "      <td>is</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realize</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>that</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>winter</td>\n",
       "      <td>of</td>\n",
       "      <td>many</td>\n",
       "      <td>,</td>\n",
       "      <td>told</td>\n",
       "      <td>presents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>edward</td>\n",
       "      <td>the</td>\n",
       "      <td>godard</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'s</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>only</td>\n",
       "      <td>has</td>\n",
       "      <td>i</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>a</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>not</td>\n",
       "      <td>hall</td>\n",
       "      <td>mask</td>\n",
       "      <td>created</td>\n",
       "      <td>do</td>\n",
       "      <td>between</td>\n",
       "      <td>i</td>\n",
       "      <td>tony</td>\n",
       "      <td>subtle</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>supposed</td>\n",
       "      <td>(</td>\n",
       "      <td>they</td>\n",
       "      <td>to</td>\n",
       "      <td>n't</td>\n",
       "      <td>leading</td>\n",
       "      <td>have</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>but</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>he</td>\n",
       "      <td>could</td>\n",
       "      <td>shame</td>\n",
       "      <td>know</td>\n",
       "      <td>actors</td>\n",
       "      <td>seen</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>be</td>\n",
       "      <td>of</td>\n",
       "      <td>find</td>\n",
       "      <td>.</td>\n",
       "      <td>why</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>way</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xxup</td>\n",
       "      <td>that</td>\n",
       "      <td>?</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>i</td>\n",
       "      <td>or</td>\n",
       "      <td>did</td>\n",
       "      <td>playing</td>\n",
       "      <td>,</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bsg</td>\n",
       "      <td>cheesy</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>decided</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>not</td>\n",
       "      <td>a</td>\n",
       "      <td>never</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>yet</td>\n",
       "      <td>.</td>\n",
       "      <td>multi</td>\n",
       "      <td>to</td>\n",
       "      <td>very</td>\n",
       "      <td>appear</td>\n",
       "      <td>washed</td>\n",
       "      <td>being</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i</td>\n",
       "      <td>endearing</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>-</td>\n",
       "      <td>continue</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>at</td>\n",
       "      <td>-</td>\n",
       "      <td>self</td>\n",
       "      <td>maybe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>can</td>\n",
       "      <td>crooked</td>\n",
       "      <td>the</td>\n",
       "      <td>talented</td>\n",
       "      <td>watching</td>\n",
       "      <td>bad</td>\n",
       "      <td>all</td>\n",
       "      <td>up</td>\n",
       "      <td>-</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>handle</td>\n",
       "      <td>smile</td>\n",
       "      <td>last</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>it</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>menacing</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>indulgent</td>\n",
       "      <td>next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slow</td>\n",
       "      <td>)</td>\n",
       "      <td>but</td>\n",
       "      <td>jessica</td>\n",
       "      <td>for</td>\n",
       "      <td>casting</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-</td>\n",
       "      <td>,</td>\n",
       "      <td>certainly</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>an</td>\n",
       "      <td>(</td>\n",
       "      <td>something</td>\n",
       "      <td>also</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>paced</td>\n",
       "      <td>her</td>\n",
       "      <td>the</td>\n",
       "      <td>simpson</td>\n",
       "      <td>extra</td>\n",
       "      <td>not</td>\n",
       "      <td>required</td>\n",
       "      <td>does</td>\n",
       "      <td>or</td>\n",
       "      <td>involve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3         4          5          6  \\\n",
       "0      xxbos       with     anyway      that    during      xxmaj         he   \n",
       "1      xxfld      xxmaj          ?        it         a    extreme       also   \n",
       "2          1      gable      xxmaj      puts      very      xxmaj          ,   \n",
       "3          i         's        was  anything     harsh       lack       like   \n",
       "4    realize      xxmaj       that     xxmaj    winter         of       many   \n",
       "5         it     edward        the    godard         .      xxmaj      xxmaj   \n",
       "6         's      xxmaj       only       has         i  chemistry      xxunk   \n",
       "7        not       hall       mask   created        do    between          i   \n",
       "8   supposed          (       they        to       n't    leading       have   \n",
       "9         to         he      could     shame      know     actors       seen   \n",
       "10        be         of       find         .       why          ,          ,   \n",
       "11      xxup       that          ?     xxmaj         i         or        did   \n",
       "12       bsg     cheesy          3       the   decided      xxmaj        not   \n",
       "13       and        yet          .     multi        to       very     appear   \n",
       "14         i  endearing      xxmaj         -  continue      xxmaj         at   \n",
       "15       can    crooked        the  talented  watching        bad        all   \n",
       "16    handle      smile       last     xxmaj        it      xxmaj   menacing   \n",
       "17      slow          )        but   jessica       for    casting          ,   \n",
       "18         -          ,  certainly     xxmaj        an          (  something   \n",
       "19     paced        her        the   simpson     extra        not   required   \n",
       "\n",
       "              7          8         9  \n",
       "0         gives      xxmaj     xxmaj  \n",
       "1             a        the     xxunk  \n",
       "2          nice      story         ,  \n",
       "3   performance         is       and  \n",
       "4             ,       told  presents  \n",
       "5           and         in      this  \n",
       "6         xxmaj          a        as  \n",
       "7          tony     subtle       the  \n",
       "8         xxmaj        but     xxunk  \n",
       "9         xxunk      xxunk        of  \n",
       "10            ,        way     xxmaj  \n",
       "11      playing          ,     xxunk  \n",
       "12            a      never         .  \n",
       "13       washed      being     xxmaj  \n",
       "14            -       self     maybe  \n",
       "15           up          -     their  \n",
       "16        xxunk  indulgent      next  \n",
       "17            ,          ,      film  \n",
       "18         also      xxunk      will  \n",
       "19         does         or   involve  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "data = TextLMDataBunch.from_csv(path, 'texts.csv')\n",
    "x,y = next(iter(data.train_dl))\n",
    "example = x[:20,:10].cpu()\n",
    "texts = pd.DataFrame([data.train_ds.vocab.textify(l).split(' ') for l in example])\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as suggested in [this article](https://arxiv.org/abs/1708.02182) from Stephen Merity et al., we don't use a fixed `bptt` through the different batches but slightly change it from batch to batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 64])\n",
      "torch.Size([76, 64])\n",
      "torch.Size([69, 64])\n",
      "torch.Size([71, 64])\n",
      "torch.Size([71, 64])\n"
     ]
    }
   ],
   "source": [
    "iter_dl = iter(data.train_dl)\n",
    "for _ in range(5):\n",
    "    x,y = next(iter_dl)\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all done internally when we use [`TextLMDataBunch`](/text.data.html#TextLMDataBunch), by creating [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) using the following class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"LanguageModelLoader\"><code>class</code> <code>LanguageModelLoader</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L14\" class=\"source_link\">[source]</a></h2>\n",
       "\n",
       "> <code>LanguageModelLoader</code>(`dataset`:[`LabelList`](/data_block.html#LabelList), `bs`:`int`=`64`, `bptt`:`int`=`70`, `backwards`:`bool`=`False`, `shuffle`:`bool`=`False`, `max_len`:`int`=`25`, `p_bptt`:`int`=`0.95`)\n",
       "\n",
       "Create a dataloader with bptt slightly changing.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the texts from `dataset` and concatenate them all, then create a big array with `bs` columns (transposed from the data source so that we read the texts in the columns). Spits batches with a size approximately equal to `bptt` but changing at every batch. If `backwards=True`, reverses the original text. If `shuffle=True`, we shuffle the texts before concatenating them together at the start of each epoch. `max_len` is the maximum amount we add to `bptt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageModelLoader.batchify\"><code>batchify</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L49\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>batchify</code>(`data`:`ndarray`) → `LongTensor`\n",
       "\n",
       "Split the corpus `data` in batches.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelLoader.batchify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageModelLoader.get_batch\"><code>get_batch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L56\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>get_batch</code>(`i`:`int`, `seq_len`:`int`) → `Tuple`\\[`LongTensor`, `LongTensor`\\]\n",
       "\n",
       "Create a batch at `i` of a given `seq_len`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelLoader.get_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When preparing the data for a classifier, we keep the different texts separate, which poses another challenge for the creation of batches: since they don't all have the same length, we can't easily collate them together in batches. To help with this we use two different techniques:\n",
    "- padding: each text is padded with the `PAD` token to get all the ones we picked to the same size\n",
    "- sorting the texts (ish): to avoid having together a very long text with a very short one (which would then have a lot of `PAD` tokens), we regroup the texts by order of length. For the training set, we still add some randomness to avoid showing the same batches at every step of the training.\n",
    "\n",
    "Here is an example of batch with padding (the padding index is 1, and the padding is applied before the sentences start)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   2,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   3,    2,    2,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [  44,    3,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   4,   44,   44,    2,    2,    2,    1,    1,    1,    1],\n",
       "        [  20,    4,   18,    3,    3,    3,    2,    1,    1,    1],\n",
       "        [  31,   20,  521,   44,   44,   44,    3,    2,    1,    1],\n",
       "        [  63,  625,    8,    4,    4,    4,   44,    3,    1,    1],\n",
       "        [   9,  825,  111,  281,   20,   69,    4,   44,    2,    2],\n",
       "        [ 141,   13,   21,   38,   15,  898,   29,    4,    3,    3],\n",
       "        [   8,   12,    4,  135,    9,   49,   12, 2194,   44,   44],\n",
       "        [ 425,   27, 2243,    8,   17,    4, 1558,  368,    4,    4],\n",
       "        [ 683,   25,   21, 1254,   80, 4856,  803,   14,   20,  323],\n",
       "        [ 179,  608,   27,  113,  552,    4,   23,  558,   31,  193]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "data = TextClasDataBunch.from_csv(path, 'texts.csv')\n",
    "iter_dl = iter(data.train_dl)\n",
    "_ = next(iter_dl)\n",
    "x,y = next(iter_dl)\n",
    "x[:20,-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all done internally when we use [`TextClasDataBunch`](/text.data.html#TextClasDataBunch), by using the following classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SortSampler\"><code>class</code> <code>SortSampler</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L61\" class=\"source_link\">[source]</a></h2>\n",
       "\n",
       "> <code>SortSampler</code>(`data_source`:`NPArrayList`, `key`:`KeyFunc`) :: [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler)\n",
       "\n",
       "Go through the text data by order of length.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SortSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pytorch [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) is used for the validation and (if applicable) the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SortishSampler\"><code>class</code> <code>SortishSampler</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L69\" class=\"source_link\">[source]</a></h2>\n",
       "\n",
       "> <code>SortishSampler</code>(`data_source`:`NPArrayList`, `key`:`KeyFunc`, `bs`:`int`) :: [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler)\n",
       "\n",
       "Go through the text data by order of length with a bit of randomness.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SortishSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pytorch [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) is generally used for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"pad_collate\"><code>pad_collate</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L90\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>pad_collate</code>(`samples`:`BatchSamples`, `pad_idx`:`int`=`1`, `pad_first`:`bool`=`True`) → `Tuple`\\[`LongTensor`, `LongTensor`\\]\n",
       "\n",
       "Function that collect samples and adds padding.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pad_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will collate the `samples` in batches while adding padding with `pad_idx`. If `pad_first=True`, padding is applied at the beginning (before the sentence starts) otherwise it's applied at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undocumented Methods - Methods moved below this line will intentionally be hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ItemList.new\"><code>new</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/data_block.py#L86\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>new</code>(`items`:`Iterator`\\[`T_co`\\], `processor`:[`PreProcessor`](/data_block.html#PreProcessor)=`None`, `kwargs`) → `ItemList`\n",
       "\n",
       "Create a new [`ItemList`](/data_block.html#ItemList) from `items`, keeping the same attributes.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextList.get\"><code>get</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L280\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>get</code>(`i`)\n",
       "\n",
       "Subclass if you want to customize how to create item `i` from `self.items`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TokenizeProcessor.process_one\"><code>process_one</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L238\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>process_one</code>(`item`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TokenizeProcessor.process_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TokenizeProcessor.process\"><code>process</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L239\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>process</code>(`ds`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TokenizeProcessor.process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"OpenFileProcessor.process_one\"><code>process_one</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L265\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>process_one</code>(`item`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(OpenFileProcessor.process_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"NumericalizeProcessor.process\"><code>process</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L253\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>process</code>(`ds`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizeProcessor.process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"NumericalizeProcessor.process_one\"><code>process_one</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L252\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>process_one</code>(`item`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizeProcessor.process_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextList.reconstruct\"><code>reconstruct</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L289\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>reconstruct</code>(`t`:`Tensor`)\n",
       "\n",
       "Reconstuct one of the underlying item for its data `t`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextList.reconstruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Methods - Please document or move to the undocumented section"
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "keywords": "fastai",
   "summary": "Basic dataset for NLP tasks and helper functions to create a DataBunch",
   "title": "text.data"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
