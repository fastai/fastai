{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.text import * \n",
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains the [`TextDataset`](/text.data.html#TextDataset) class, which is the main dataset you should use for your NLP tasks. It automatically does the preprocessing steps described in [`text.transform`](/text.transform.html#text.transform). It also contains all the functions to quickly get a [`TextDataBunch`](/text.data.html#TextDataBunch) ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly assemble your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get your data in one of the following formats to make the most of the fastai library and use one of the factory methods of one of the [`TextDataBunch`](/text.data.html#TextDataBunch) classes:\n",
    "- raw text files in folders train, valid, test in an ImageNet style,\n",
    "- a csv where some column(s) gives the label(s) and the folowwing one the associated text,\n",
    "- a dataframe structured the same way,\n",
    "- tokens and labels arrays,\n",
    "- ids, vocabulary (correspondance id to word) and labels.\n",
    "\n",
    "If you are assembling the data for a language model, you should define your labels as always 0 to respect those formats. The first time you create a [`DataBunch`](/basic_data.html#DataBunch) with one of those functions, your data will be preprocessed automatically. You can save it, so that the next time you call it is almost instantaneous. \n",
    "\n",
    "Below are the classes that help assembling the raw data in a [`DataBunch`](/basic_data.html#DataBunch) suitable for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextLMDataBunch\"><code>class</code> <code>TextLMDataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L380\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextLMDataBunch</code>(`train_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `valid_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `test_dl`:`Optional`\\[[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\\]=`None`, `device`:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=`None`, `tfms`:`Optional`\\[`Collection`\\[`Callable`\\]\\]=`None`, `path`:`PathOrStr`=`'.'`, `collate_fn`:`Callable`=`'data_collate'`) :: [`TextDataBunch`](/text.data.html#TextDataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLMDataBunch, title_level=3, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`DataBunch`](/basic_data.html#DataBunch) suitable for language modeling: all the texts in the [`datasets`](/datasets.html#datasets) are concatenated and the labels are ignored. Instead, the target is the next word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextLMDataBunch.show_batch\"><code>show_batch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L390\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>show_batch</code>(`sep`=`' '`, `ds_type`:[`DatasetType`](/basic_data.html#DatasetType)=`<DatasetType.Train: 1>`, `rows`:`int`=`10`, `max_len`:`int`=`100`)\n",
       "\n",
       "Show `rows` texts from a batch of `ds_type`, tokens are joined with `sep`, truncated at `max_len`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLMDataBunch.show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextClasDataBunch\"><code>class</code> <code>TextClasDataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L401\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextClasDataBunch</code>(`train_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `valid_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `test_dl`:`Optional`\\[[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\\]=`None`, `device`:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=`None`, `tfms`:`Optional`\\[`Collection`\\[`Callable`\\]\\]=`None`, `path`:`PathOrStr`=`'.'`, `collate_fn`:`Callable`=`'data_collate'`) :: [`TextDataBunch`](/text.data.html#TextDataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextClasDataBunch, title_level=3, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`DataBunch`](/basic_data.html#DataBunch) suitable for a text classifier: all the texts are grouped by length (with a bit of randomness for the training set) then padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextClasDataBunch.show_batch\"><code>show_batch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L418\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>show_batch</code>(`sep`=`' '`, `ds_type`:[`DatasetType`](/basic_data.html#DatasetType)=`<DatasetType.Train: 1>`, `rows`:`int`=`10`, `max_len`:`int`=`100`)\n",
       "\n",
       "Show `rows` texts from a batch of `ds_type`, tokens are joined with `sep`, truncated at `max_len`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextClasDataBunch.show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextDataBunch\"><code>class</code> <code>TextDataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L282\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextDataBunch</code>(`train_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `valid_dl`:[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), `test_dl`:`Optional`\\[[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\\]=`None`, `device`:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)=`None`, `tfms`:`Optional`\\[`Collection`\\[`Callable`\\]\\]=`None`, `path`:`PathOrStr`=`'.'`, `collate_fn`:`Callable`=`'data_collate'`) :: [`DataBunch`](/basic_data.html#DataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch, title_level=3, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`DataBunch`](/basic_data.html#DataBunch) with the raw texts. This is only going to work if they all ahve the same lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factory methods (TextDataBunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All those classes have the following factory methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_folder\"><code>from_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L359\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_folder</code>(`path`:`PathOrStr`, `train`:`str`=`'train'`, `valid`:`str`=`'valid'`, `test`:`Optional`\\[`str`\\]=`None`, `classes`:`ArgStar`=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `kwargs`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_folder, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a [`DataBunch`](/basic_data.html#DataBunch) from texts placed in `path` in a [`train`](/train.html#train), `valid` and maybe `test` folders. Text files in the [`train`](/train.html#train) and `valid` folders should be places in subdirectories according to their classes (always the same for a language model) and the ones for the `test` folder should all be placed there directly. `tokenizer` will be used to parse those texts into tokens. The `shuffle` flag will optionally shuffle the texts found.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_csv\"><code>from_csv</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L346\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_csv</code>(`path`:`PathOrStr`, `csv_name`, `valid_pct`:`float`=`0.2`, `test`:`Optional`\\[`str`\\]=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `classes`:`StrList`=`None`, `header`=`'infer'`, `text_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`1`, `label_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`0`, `label_delim`:`str`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_csv, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a [`DataBunch`](/basic_data.html#DataBunch) from texts placed in `path` in a csv file and maybe `test` csv file opened with `header`. You can specify `txt_cols` and `lbl_cols` or just an integer `n_labels` in which case the label(s) should be the first column(s). `tokenizer` will be used to parse those texts into tokens.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_df\"><code>from_df</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L337\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_df</code>(`path`:`PathOrStr`, `train_df`:`DataFrame`, `valid_df`:`DataFrame`, `test_df`:`OptDataFrame`=`None`, `tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `classes`:`StrList`=`None`, `text_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`1`, `label_cols`:`Union`\\[`int`, `Collection`\\[`int`\\], `str`, `StrList`\\]=`0`, `label_delim`:`str`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_df, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a [`DataBunch`](/basic_data.html#DataBunch) in `path` from texts in `train_df`, `valid_df` and maybe `test_df`. By default, those are opened with `header=infer` but you can specify another value in the kwargs. You can specify `txt_cols` and `lbl_cols` or just an integer `n_labels` in which case the label(s) should be the first column(s). `tokenizer` will be used to parse those texts into tokens.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_tokens\"><code>from_tokens</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L326\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_tokens</code>(`path`:`PathOrStr`, `trn_tok`:`Tokens`, `trn_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\], `val_tok`:`Tokens`, `val_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\], `vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `tst_tok`:`Tokens`=`None`, `classes`:`ArgStar`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_tokens, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a [`DataBunch`](/basic_data.html#DataBunch) from `trn_tok`, `trn_lbls`, `val_tok`, `val_lbls` and maybe `tst_tok`.\n",
    "\n",
    "You can pass a specific `vocab` for the numericalization step (if you are building a classifier from a language model you fine-tuned for instance). kwargs will be split between the [`TextDataset`](/text.data.html#TextDataset) function and to the class initialization, you can precise there parameters such as `max_vocab`, `chunksize`, `min_freq`, `n_labels`, `tok_suff` and `lbl_suff` (see the [`TextDataset`](/text.data.html#TextDataset) documentation) or `bs`, `bptt` and `pad_idx` (see the sections LM data and classifier data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.from_ids\"><code>from_ids</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L305\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_ids</code>(`path`:`PathOrStr`, `vocab`:[`Vocab`](/text.transform.html#Vocab), `trn_ids`:`Collection`\\[`Collection`\\[`int`\\]\\], `val_ids`:`Collection`\\[`Collection`\\[`int`\\]\\], `tst_ids`:`Collection`\\[`Collection`\\[`int`\\]\\]=`None`, `trn_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `val_lbls`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `classes`:`ArgStar`=`None`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.from_ids, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a [`DataBunch`](/basic_data.html#DataBunch) in `path` from texts already processed into `trn_ids`, `trn_lbls`, `val_ids`, `val_lbls` and maybe `tst_ids`. You can specify the corresponding `classes` if applciable. You must specify the `vocab` so that the [`RNNLearner`](/text.learner.html#RNNLearner) class can later infer the corresponding sizes in the model it will create. kwargs will be passed to the class initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid losing time preprocessing the text data more than once, you should save/load your [`TextDataBunch`](/text.data.html#TextDataBunch) using thse methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.load\"><code>load</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L315\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>load</code>(`path`:`PathOrStr`, `cache_name`:`PathOrStr`=`'tmp'`, `kwargs`)\n",
       "\n",
       "Load a [`TextDataBunch`](/text.data.html#TextDataBunch) from `path/cache_name`. `kwargs` are passed to the dataloader creation.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataBunch.save\"><code>save</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L293\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>save</code>(`cache_name`:`PathOrStr`=`'tmp'`)\n",
       "\n",
       "Save the [`DataBunch`](/basic_data.html#DataBunch) in `self.path/cache_name` folder.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataBunch.save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untar the IMDB sample dataset if not already done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it comes in the form of csv files, we will use the corresponding `text_data` method. Here is an overview of what your file you should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path/'texts.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a simple way of creating your [`DataBunch`](/basic_data.html#DataBunch) for language modelling or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_csv(Path(path), 'texts.csv')\n",
    "data_clas = TextClasDataBunch.from_csv(Path(path), 'texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TextBase dataset classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, the previous functions will create a training, validation and maybe test [`TextDataset`](/text.data.html#TextDataset) which will then be transformed in a [`TokenizedDataset`](/text.data.html#TokenizedDataset) then a [`NumericalizedDataset`](/text.data.html#NumericalizedDataset). Those are all subclasses of [`TextBase`](/text.data.html#TextBase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextBase\"><code>class</code> <code>TextBase</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L61\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextBase</code>(`x`:`ArgStar`, `labels`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `classes`:`ArgStar`=`None`, `encode_classes`:`bool`=`True`) :: [`DatasetBase`](/basic_data.html#DatasetBase)\n",
       "\n",
       "Basic dataset for NLP tasks.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextBase, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x` is an array representing the inputs (filenames, texts, tokens or ids) with certain `labels` (default to all zeros if not specified). `classes` can be passed and if `encode_classes`, the `labels` are changed from their class to the corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextDataset\"><code>class</code> <code>TextDataset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L127\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextDataset</code>(`texts`:`StrList`, `labels`:`ArgStar`=`None`, `classes`:`ArgStar`=`None`, `mark_fields`:`bool`=`True`, `encode_classes`:`bool`=`True`) :: [`TextBase`](/text.data.html#TextBase)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataset, doc_string=False, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`TextBase`](/text.data.html#TextBase) dataset of `texts` with `labels` belonging to `classes`. The `texts` are joined in the column dimension and if `mark_fields`, field markers are added in-between. If `encode_classes` the `labels` are changed from their class to the corresponding index. If `is_fnames`, the filenames in `texts` are read to pull the texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataset.from_folder\"><code>from_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L158\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_folder</code>(`path`:`PathOrStr`, `classes`:`ArgStar`=`None`, `valid_pct`:`float`=`0.0`, `extensions`:`StrList`=`['.txt']`, `mark_fields`:`bool`=`True`) → `TextDataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataset.from_folder, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`TextDataset`](/text.data.html#TextDataset) by scanning the subfolders in `path` for files with `extensions`. Only keep the ones with labels in `classes` if it's specified. If `valid_pct` is not 0., returns two datasets randomly split. `mark_fields` is passed to the initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataset.from_one_folder\"><code>from_one_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L176\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_one_folder</code>(`path`:`PathOrStr`, `classes`:`ArgStar`, `extensions`:`StrList`=`['.txt']`, `mark_fields`:`bool`=`True`) → `TextDataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataset.from_one_folder, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primarly used for the test set. Create a [`TextDataset`](/text.data.html#TextDataset) by scanning the subfolders in `path` for files with `extensions`. Labels all of them for `classes[0]`.  `mark_fields` is passed to the initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataset.from_df\"><code>from_df</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L134\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_df</code>(`df`:`DataFrame`, `classes`:`ArgStar`=`None`, `n_labels`:`int`=`1`, `txt_cols`:`Collection`\\[`Union`\\[`int`, `str`\\]\\]=`None`, `label_cols`:`Collection`\\[`Union`\\[`int`, `str`\\]\\]=`None`, `mark_fields`:`bool`=`True`) → `TextDataset`\n",
       "\n",
       "Create a [`TextDataset`](/text.data.html#TextDataset) from the texts in a dataframe  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataset.from_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextDataset.tokenize\"><code>tokenize</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L186\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>tokenize</code>(`tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `chunksize`:`int`=`10000`) → `TokenizedDataset`\n",
       "\n",
       "Tokenize the texts with `tokenizer` by bits of `chunksize`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextDataset.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"FilesTextDataset\"><code>class</code> <code>FilesTextDataset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L194\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>FilesTextDataset</code>(`fns`:`StrList`, `labels`:`ArgStar`=`None`, `classes`:`ArgStar`=`None`, `mark_fields`:`bool`=`True`, `encode_classes`:`bool`=`True`) :: [`TextDataset`](/text.data.html#TextDataset)\n",
       "\n",
       "Reads the content of `fns` then pass them to a `TextDataSet`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FilesTextDataset, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TokenizedDataset\"><code>class</code> <code>TokenizedDataset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L100\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TokenizedDataset</code>(`tokens`:`Tokens`, `labels`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `classes`:`ArgStar`=`None`, `encode_classes`:`bool`=`True`) :: [`TextBase`](/text.data.html#TextBase)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TokenizedDataset, doc_string=False, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`TextBase`](/text.data.html#TextBase) dataset of `tokens` with `labels` belonging to `classes`. If `encode_classes` the `labels` are changed from their class to the corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TokenizedDataset.save\"><code>save</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L106\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>save</code>(`path`:`Path`, `name`:`str`)\n",
       "\n",
       "Save the dataset in `path` with `name`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TokenizedDataset.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TokenizedDataset.numericalize\"><code>numericalize</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L113\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>numericalize</code>(`vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `max_vocab`:`int`=`60000`, `min_freq`:`int`=`2`) → `NumericalizedDataset`\n",
       "\n",
       "Numericalize the tokens with `vocab` (if not None) otherwise create one with `max_vocab` and `min_freq` from tokens.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TokenizedDataset.numericalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"NumericalizedDataset\"><code>class</code> <code>NumericalizedDataset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L70\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>NumericalizedDataset</code>(`vocab`:[`Vocab`](/text.transform.html#Vocab), `ids`:`Collection`\\[`Collection`\\[`int`\\]\\], `labels`:`Collection`\\[`Union`\\[`int`, `float`\\]\\]=`None`, `classes`:`ArgStar`=`None`, `encode_classes`:`bool`=`True`) :: [`TextBase`](/text.data.html#TextBase)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizedDataset, doc_string=False, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [`TextBase`](/text.data.html#TextBase) dataset of `ids` with `labels` belonging to `classes`. `vocab` contains the correspondance between ids an tokens. If `encode_classes` the `labels` are changed from their class to the corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"NumericalizedDataset.get_text_item\"><code>get_text_item</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L77\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>get_text_item</code>(`idx`, `sep`=`' '`, `max_len`:`int`=`None`)\n",
       "\n",
       "Return the text in `idx`, tokens separated by `sep` and cutting at `max_len`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizedDataset.get_text_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"NumericalizedDataset.save\"><code>save</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L84\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>save</code>(`path`:`Path`, `name`:`str`)\n",
       "\n",
       "Save the dataset in `path` with `name`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizedDataset.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"NumericalizedDataset.load\"><code>load</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L92\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>load</code>(`path`:`Path`, `name`:`str`)\n",
       "\n",
       "Load a [`NumericalizedDataset`](/text.data.html#NumericalizedDataset) from `path` in `name`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NumericalizedDataset.load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A language model is trained to guess what the next word is inside a flow of words. We don't feed it the different texts separately but concatenate them all together in a big array. To create the batches, we split this array into `bs` chuncks of continuous texts. Note that in all NLP tasks, we use the pytoch convention of sequence length being the first dimension (and batch size being the second one) so we transpose that array so that we can read the chunks of texts in columns. Here is an example of batch from our imdb sample dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxfld</td>\n",
       "      <td>can</td>\n",
       "      <td>the</td>\n",
       "      <td>!</td>\n",
       "      <td>-</td>\n",
       "      <td>young</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>him</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>firstly</td>\n",
       "      <td>watch</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>this</td>\n",
       "      <td>and</td>\n",
       "      <td>?</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>one</td>\n",
       "      <td>corpse</td>\n",
       "      <td>,</td>\n",
       "      <td>the</td>\n",
       "      <td>is</td>\n",
       "      <td>stinks</td>\n",
       "      <td>have</td>\n",
       "      <td>no</td>\n",
       "      <td>debut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>definite</td>\n",
       "      <td>'s</td>\n",
       "      <td>of</td>\n",
       "      <td>there</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>sent</td>\n",
       "      <td>!</td>\n",
       "      <td>considered</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>perception</td>\n",
       "      <td>the</td>\n",
       "      <td>are</td>\n",
       "      <td>stealing</td>\n",
       "      <td>by</td>\n",
       "      <td>as</td>\n",
       "      <td>myself</td>\n",
       "      <td>for</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.</td>\n",
       "      <td>of</td>\n",
       "      <td>dead</td>\n",
       "      <td>a</td>\n",
       "      <td>scene</td>\n",
       "      <td>his</td>\n",
       "      <td>everyone</td>\n",
       "      <td>as</td>\n",
       "      <td>taste</td>\n",
       "      <td>chilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>reality</td>\n",
       "      <td>hitchhiker</td>\n",
       "      <td>number</td>\n",
       "      <td>to</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>knows</td>\n",
       "      <td>an</td>\n",
       "      <td>)</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxunk</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>of</td>\n",
       "      <td>see</td>\n",
       "      <td>to</td>\n",
       "      <td>it</td>\n",
       "      <td>atheist</td>\n",
       "      <td>.</td>\n",
       "      <td>dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>in</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>reviews</td>\n",
       "      <td>what</td>\n",
       "      <td>conclude</td>\n",
       "      <td>'s</td>\n",
       "      <td>throughout</td>\n",
       "      <td>the</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>this</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>available</td>\n",
       "      <td>i</td>\n",
       "      <td>the</td>\n",
       "      <td>based</td>\n",
       "      <td>my</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>this</td>\n",
       "      <td>case</td>\n",
       "      <td>awful</td>\n",
       "      <td>from</td>\n",
       "      <td>mean</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>upon</td>\n",
       "      <td>adult</td>\n",
       "      <td>of</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>movie</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>the</td>\n",
       "      <td>.</td>\n",
       "      <td>of</td>\n",
       "      <td>some</td>\n",
       "      <td>life</td>\n",
       "      <td>madness</td>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is</td>\n",
       "      <td>we</td>\n",
       "      <td>but</td>\n",
       "      <td>film</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>a</td>\n",
       "      <td>geico</td>\n",
       "      <td>.</td>\n",
       "      <td>(</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>an</td>\n",
       "      <td>have</td>\n",
       "      <td>i</td>\n",
       "      <td>'s</td>\n",
       "      <td>the</td>\n",
       "      <td>recently</td>\n",
       "      <td>insurance</td>\n",
       "      <td>in</td>\n",
       "      <td>simply</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>absolute</td>\n",
       "      <td>a</td>\n",
       "      <td>really</td>\n",
       "      <td>german</td>\n",
       "      <td>fight</td>\n",
       "      <td>deceased</td>\n",
       "      <td>commercials</td>\n",
       "      <td>fact</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dud</td>\n",
       "      <td>well</td>\n",
       "      <td>did</td>\n",
       "      <td>xxup</td>\n",
       "      <td>scenes</td>\n",
       "      <td>widow</td>\n",
       "      <td>;</td>\n",
       "      <td>when</td>\n",
       "      <td>being</td>\n",
       "      <td>widowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>n't</td>\n",
       "      <td>theatrical</td>\n",
       "      <td>were</td>\n",
       "      <td>,</td>\n",
       "      <td>what</td>\n",
       "      <td>it</td>\n",
       "      <td>enough</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>known</td>\n",
       "      <td>get</td>\n",
       "      <td>release</td>\n",
       "      <td>at</td>\n",
       "      <td>who</td>\n",
       "      <td>no</td>\n",
       "      <td>comes</td>\n",
       "      <td>to</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>having</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>into</td>\n",
       "      <td>-</td>\n",
       "      <td>once</td>\n",
       "      <td>died</td>\n",
       "      <td>one</td>\n",
       "      <td>to</td>\n",
       "      <td>be</td>\n",
       "      <td>paxton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>been</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>this</td>\n",
       "      <td>i</td>\n",
       "      <td>quite</td>\n",
       "      <td>on</td>\n",
       "      <td>knows</td>\n",
       "      <td>religion</td>\n",
       "      <td>a</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3         4         5  \\\n",
       "0      xxfld         can         the           !         -     young   \n",
       "1          1       xxunk       xxunk     firstly     watch     xxunk   \n",
       "2          a         one      corpse           ,       the        is   \n",
       "3   definite          's          of       there     xxunk      sent   \n",
       "4         no  perception         the         are  stealing        by   \n",
       "5          .          of        dead           a     scene       his   \n",
       "6          a     reality  hitchhiker      number        to     xxunk   \n",
       "7      xxunk           .           .          of       see        to   \n",
       "8         no          in        \\n\\n     reviews      what  conclude   \n",
       "9          .        this       xxunk   available         i       the   \n",
       "10      this        case       awful        from      mean     xxunk   \n",
       "11     movie           ,           ,         the         .        of   \n",
       "12        is          we         but        film      \\n\\n         a   \n",
       "13        an        have           i          's       the  recently   \n",
       "14  absolute           a      really      german     fight  deceased   \n",
       "15       dud        well         did        xxup    scenes     widow   \n",
       "16         .           -         n't  theatrical      were         ,   \n",
       "17      \\n\\n       known         get     release        at       who   \n",
       "18    having       xxunk        into           -      once      died   \n",
       "19      been       xxunk        this           i     quite        on   \n",
       "\n",
       "              6           7        8         9  \n",
       "0         xxunk       xxunk      him       his  \n",
       "1          this         and        ?     xxunk  \n",
       "2        stinks        have       no     debut  \n",
       "3             !  considered    xxunk      with  \n",
       "4            as      myself      for      this  \n",
       "5      everyone          as    taste  chilling  \n",
       "6         knows          an        )         ,  \n",
       "7            it     atheist        .      dark  \n",
       "8            's  throughout      the         ,  \n",
       "9         based          my    xxunk       and  \n",
       "10         upon       adult       of     xxunk  \n",
       "11         some        life  madness      made  \n",
       "12        geico           .        (  thriller  \n",
       "13    insurance          in   simply     about  \n",
       "14  commercials        fact    xxunk         a  \n",
       "15            ;        when    being   widowed  \n",
       "16         what          it   enough     xxunk  \n",
       "17           no       comes       to         (  \n",
       "18          one          to       be    paxton  \n",
       "19        knows    religion        a   himself  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "data = TextLMDataBunch.from_csv(path, 'texts.csv')\n",
    "x,y = next(iter(data.train_dl))\n",
    "example = x[:20,:10].cpu()\n",
    "texts = pd.DataFrame([data.train_ds.vocab.textify(l).split(' ') for l in example])\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as suggested in [this article](https://arxiv.org/abs/1708.02182) from Stephen Merity et al., we don't use a fixed `bptt` through the different batches but slightly change it from batch to batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n",
      "torch.Size([69, 64])\n",
      "torch.Size([71, 64])\n",
      "torch.Size([71, 64])\n",
      "torch.Size([76, 64])\n"
     ]
    }
   ],
   "source": [
    "iter_dl = iter(data.train_dl)\n",
    "for _ in range(5):\n",
    "    x,y = next(iter_dl)\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all done internally when we use [`TextLMDataBunch`](/text.data.html#TextLMDataBunch), by creating [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) using the following class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"LanguageModelLoader\"><code>class</code> <code>LanguageModelLoader</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L203\" class=\"source_link\">[source]</a></h2>\n",
       "\n",
       "> <code>LanguageModelLoader</code>(`dataset`:[`TextDataset`](/text.data.html#TextDataset), `bs`:`int`=`64`, `bptt`:`int`=`70`, `backwards`:`bool`=`False`, `shuffle`:`bool`=`False`, `max_len`:`int`=`25`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelLoader, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the texts from `dataset` and concatenate them all, then create a big array with `bs` columns (transposed from the data source so that we read the texts in the columns). Spits batches with a size approximately equal to `bptt` but changing at every batch. If `backwards` is True, reverses the original text. If `shuffle` is True, we shuffle the texts before concatenating them together at the start of each epoch. `max_len` is the maximum amount we add to `bptt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageModelLoader.batchify\"><code>batchify</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L232\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>batchify</code>(`data`:`ndarray`) → `LongTensor`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelLoader.batchify, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Called at the inialization to create the big array of text ids from the [`data`](/text.data.html#text.data) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LanguageModelLoader.get_batch\"><code>get_batch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L239\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>get_batch</code>(`i`:`int`, `seq_len`:`int`) → `Tuple`\\[`LongTensor`, `LongTensor`\\]\n",
       "\n",
       "Create a batch at `i` of a given `seq_len`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LanguageModelLoader.get_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When preparing the data for a classifier, we keep the different texts separate, which poses another challenge for the creation of batches: since they don't all have the same length, we can't easily collate them together in batches. To help with this we use two different techniques:\n",
    "- padding: each text is padded with the `PAD` token to get all the ones we picked to the same size\n",
    "- sorting the texts (ish): to avoid having together a very long text with a very short one (which would then have a lot of `PAD` tokens), we regroup the texts by order of length. For the training set, we still add some randomness to avoid showing the same batches at every step of the training.\n",
    "\n",
    "Here is an example of batch with padding (the padding index is 1, and the padding is applied before the sentences start)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "data = TextClasDataBunch.from_csv(path, 'texts.csv')\n",
    "iter_dl = iter(data.train_dl)\n",
    "_ = next(iter_dl)\n",
    "x,y = next(iter_dl)\n",
    "x[:20,-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all done internally when we use [`TextClasDataBunch`](/text.data.html#TextClasDataBunch), by using the following classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SortSampler\"><code>class</code> <code>SortSampler</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L244\" class=\"source_link\">[source]</a></h2>\n",
       "\n",
       "> <code>SortSampler</code>(`data_source`:`NPArrayList`, `key`:`KeyFunc`) :: [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SortSampler, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) to batchify the `data_source` by order of length of the texts. Used for the validation and (if applicable) the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SortishSampler\"><code>class</code> <code>SortishSampler</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L252\" class=\"source_link\">[source]</a></h2>\n",
       "\n",
       "> <code>SortishSampler</code>(`data_source`:`NPArrayList`, `key`:`KeyFunc`, `bs`:`int`) :: [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SortishSampler, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch [`Sampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) to batchify with size `bs` the `data_source` by order of length of the texts with a bit of randomness. Used for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"pad_collate\"><code>pad_collate</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L273\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>pad_collate</code>(`samples`:`BatchSamples`, `pad_idx`:`int`=`1`, `pad_first`:`bool`=`True`) → `Tuple`\\[`LongTensor`, `LongTensor`\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pad_collate, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used by the pytorch [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) to collate the `samples` in batches while adding padding with `pad_idx`. If `pad_first` is True, padding is applied at the beginning (before the sentence starts) otherwise it's applied at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data block API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data block API works for the text application too. Here are a few subclasses of the usual objects to implement the parts speficic to the text application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextFileList\"><code>class</code> <code>TextFileList</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L14\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextFileList</code>(`items`:`Iterator`, `path`:`PathOrStr`=`'.'`) :: [`InputList`](/data_block.html#InputList)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextFileList, doc_string=False, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subclasses [`InputList`](/data_block.html#InputList) just to change the defulat extentions in `from_folder` to text extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextFileList.from_folder\"><code>from_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L20\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>from_folder</code>(`path`:`PathOrStr`=`'.'`, `extensions`:`StrList`=`['.txt']`, `recurse`=`True`) → `ImageFileList`\n",
       "\n",
       "Get the list of files in `path` that have a suffix in `extensions`. `recurse` determines if we search subfolders.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextFileList.from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextSplitData\"><code>class</code> <code>TextSplitData</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L30\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextSplitData</code>(`path`:`PathOrStr`, `train`:[`LabelList`](/data_block.html#LabelList), `valid`:[`LabelList`](/data_block.html#LabelList), `test`:[`LabelList`](/data_block.html#LabelList)=`None`) :: [`SplitData`](/data_block.html#SplitData)\n",
       "\n",
       "A [`LabelList`](/data_block.html#LabelList) for each of `train` and `valid` (optional `test`), and method to get `datasets`  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitData, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextSplitData.add_test_folder\"><code>add_test_folder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L38\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>add_test_folder</code>(`test_folder`:`str`=`'test'`, `label`:`Any`=`None`)\n",
       "\n",
       "Add test set containing items from folder `test_folder` and an arbitrary `label`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitData.add_test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TextSplitDatasets\"><code>class</code> <code>TextSplitDatasets</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L43\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>TextSplitDatasets</code>(`path`:`PathOrStr`, `train_ds`:[`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset), `valid_ds`:[`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset), `test_ds`:`Optional`\\[[`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\\]=`None`) :: [`SplitDatasets`](/data_block.html#SplitDatasets)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitDatasets, doc_string=False, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subclass of [`SplitDatasets`](/data_block.html#SplitDatasets) that implements methods specific to texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextSplitDatasets.tokenize\"><code>tokenize</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L44\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>tokenize</code>(`tokenizer`:[`Tokenizer`](/text.transform.html#Tokenizer)=`None`, `chunksize`:`int`=`10000`)\n",
       "\n",
       "Tokenize `self.datasets` with `tokenizer` by bits of `chunksize`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitDatasets.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextSplitDatasets.numericalize\"><code>numericalize</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L49\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>numericalize</code>(`vocab`:[`Vocab`](/text.transform.html#Vocab)=`None`, `max_vocab`:`int`=`60000`, `min_freq`:`int`=`2`)\n",
       "\n",
       "Numericalize `self.datasets` with `vocab` or by creating one on the training set with `max_vocab` and `min_freq`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitDatasets.numericalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextSplitDatasets.databunch\"><code>databunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L56\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>databunch</code>(`cls_func`, `path`:`PathOrStr`=`None`, `kwargs`)\n",
       "\n",
       "Create an `cls_func` from self, `path` will override `self.path`, `kwargs` are passed to `cls_func.create`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitDatasets.databunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TextMtd\">`TextMtd`</h2>\n",
       "\n",
       "> <code>Enum</code> = [DF, TOK, IDS]\n",
       "\n",
       "[`TextDataset`](/text.data.html#TextDataset) enum to keep track of what data needs to be processed (dataframe, csv, tokens, ids) "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextMtd, alt_doc_string='`TextDataset` enum to keep track of what data needs to be processed (dataframe, csv, tokens, ids)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undocumented Methods - Methods moved below this line will intentionally be hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextLMDataBunch.create\"><code>create</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L382\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>create</code>(`train_ds`, `valid_ds`, `test_ds`=`None`, `path`:`PathOrStr`=`'.'`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Create a [`TextDataBunch`](/text.data.html#TextDataBunch) in `path` from the `datasets` for language modelling.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLMDataBunch.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextClasDataBunch.create\"><code>create</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L403\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>create</code>(`train_ds`, `valid_ds`, `test_ds`=`None`, `path`:`PathOrStr`=`'.'`, `bs`=`64`, `pad_idx`=`1`, `pad_first`=`True`, `kwargs`) → [`DataBunch`](/basic_data.html#DataBunch)\n",
       "\n",
       "Function that transform the `datasets` in a [`DataBunch`](/basic_data.html#DataBunch) for classification.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextClasDataBunch.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextSplitData.dataset_cls\"><code>dataset_cls</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L35\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>dataset_cls</code>()"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextSplitData.dataset_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Methods - Please document or move to the undocumented section"
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "keywords": "fastai",
   "summary": "Basic dataset for NLP tasks and helper functions to create a DataBunch",
   "title": "text.data"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
