{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains all the basic functions we need in other modules of the fastai library (split with [`core`](/core.html#core) that contains the ones not requiring pytorch). Its documentation can easily be skipped at a first read, unless you want to know what a given fuction does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.layers import *\n",
    "from fastai.torch_core import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AdamW = partial(optim.Adam, betas=(0.9,0.99))` <div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L43\">[source]</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)` <div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L41\">[source]</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`defaults.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')` <div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L62\">[source]</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are trying to make fastai run on the CPU, simply change the default device: `defaults.device = 'cpu'`. \n",
    "\n",
    "Alternatively, if not using wildcard imports: `fastai.torch_core.defaults.device = 'cpu'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that operate conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"batch_to_half\"><code>batch_to_half</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L198\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>batch_to_half</code>(<b>`b`</b>:`Collection`\\[`Tensor`\\]) → `Collection`\\[`Tensor`\\]\n",
       "\n",
       "Set the input of batch `b` to half precision.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(batch_to_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"flatten_model\"><code>flatten_model</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L152\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>flatten_model</code>(<b>`m`</b>)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(flatten_model, full_name='flatten_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattens all the layers of `m` into an array. This allows for easy access to the layers of the model and allows you to manipulate the model as if it was an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = simple_cnn([3,6,12])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " ReLU(inplace),\n",
       " Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " ReLU(inplace),\n",
       " AdaptiveAvgPool2d(output_size=1),\n",
       " Flatten()]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"model2half\"><code>model2half</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L208\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>model2half</code>(<b>`model`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "Convert `model` to half precision except the batchnorm layers.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(model2half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting model parameters to half precision allows us to leverage fast `FP16` arithmatic which can speed up the computations by 2-8 times. It also reduces memory consumption allowing us to train deeper models. \n",
    "\n",
    "**Note**: Batchnorm layers are not converted to half precision as that may lead to instability in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtypes of model parameters before model2half: \n",
      "0.0.weight                    : torch.float32\n",
      "0.2.weight                    : torch.float32\n",
      "0.2.bias                      : torch.float32\n",
      "0.2.running_mean              : torch.float32\n",
      "0.2.running_var               : torch.float32\n",
      "0.2.num_batches_tracked       : torch.int64\n",
      "1.0.weight                    : torch.float32\n",
      "1.0.bias                      : torch.float32\n",
      "\n",
      "dtypes of model parameters after model2half: \n",
      "0.0.weight                    : torch.float16\n",
      "0.2.weight                    : torch.float32\n",
      "0.2.bias                      : torch.float32\n",
      "0.2.running_mean              : torch.float32\n",
      "0.2.running_var               : torch.float32\n",
      "0.2.num_batches_tracked       : torch.int64\n",
      "1.0.weight                    : torch.float16\n",
      "1.0.bias                      : torch.float16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = simple_cnn([3,6,12], bn=True)\n",
    "\n",
    "def show_params_dtype(state_dict):\n",
    "    \"\"\"Simple function to pretty print the dtype of the model params\"\"\"\n",
    "    for wt_name, param in state_dict.items():\n",
    "        print(\"{:<30}: {}\".format(wt_name, str(param.dtype)))\n",
    "    print()    \n",
    "\n",
    "print(\"dtypes of model parameters before model2half: \")\n",
    "show_params_dtype(m.state_dict())\n",
    "\n",
    "# Converting model to half precision\n",
    "m_half = model2half(m)\n",
    "\n",
    "print(\"dtypes of model parameters after model2half: \")\n",
    "show_params_dtype(m_half.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"np2model_tensor\"><code>np2model_tensor</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L255\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>np2model_tensor</code>(<b>`a`</b>)\n",
       "\n",
       "Tranform numpy array `a` to a tensor of the same type.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(np2model_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a wrapper on top of Pytorch's `torch.as_tensor` which converts numpy array to torch tensor, and additionally attempts to map all floats to `torch.float32` and all integers to `torch.int64` for consistencies in model data. Below is an example demonstrating it's functionality for floating number, similar functionality applies to integer as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of as': float16, float32, float64\n",
      "Datatype of bs': torch.float32, torch.float32, torch.float32\n"
     ]
    }
   ],
   "source": [
    "a1 = np.ones((2, 3)).astype(np.float16)\n",
    "a2 = np.ones((2, 3)).astype(np.float32)\n",
    "a3 = np.ones((2, 3)).astype(np.float64)\n",
    "\n",
    "b1 = np2model_tensor(a1) # Maps to torch.float32\n",
    "b2 = np2model_tensor(a2) # Maps to torch.float32\n",
    "b3 = np2model_tensor(a3) # Maps to torch.float32\n",
    "\n",
    "print(f\"Datatype of as': {a1.dtype}, {a2.dtype}, {a3.dtype}\")\n",
    "print(f\"Datatype of bs': {b1.dtype}, {b2.dtype}, {b3.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"requires_grad\"><code>requires_grad</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L112\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>requires_grad</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), <b>`b`</b>:`Optional`\\[`bool`\\]=<b><i>`None`</i></b>) → `Optional`\\[`bool`\\]\n",
       "\n",
       "If `b` is not set return [`requires_grad`](/torch_core.html#requires_grad) of first param, else set [`requires_grad`](/torch_core.html#requires_grad) on all params as `b`  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs both getting and setting of [`requires_grad`](/torch_core.html#requires_grad) parameter of the tensors, which decided whether to accumulate gradients or not. \n",
    "\n",
    "* If `b` is `None`: The function **gets** the [`requires_grad`](/torch_core.html#requires_grad) for the model parameter, to be more specific it returns the [`requires_grad`](/torch_core.html#requires_grad) of the first element in the model.\n",
    "\n",
    "* Else if `b` is passed (a boolean value), [`requires_grad`](/torch_core.html#requires_grad) of all parameters of the model is **set** to `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad of model: True\n",
      "requires_grad of model: False\n"
     ]
    }
   ],
   "source": [
    "# Any Pytorch model\n",
    "m = simple_cnn([3, 6, 12], bn=True)\n",
    "\n",
    "# Get the requires_grad of model\n",
    "print(\"requires_grad of model: {}\".format(requires_grad(m)))\n",
    "\n",
    "# Set requires_grad of all params in model to false\n",
    "requires_grad(m, False)\n",
    "\n",
    "# Get the requires_grad of model\n",
    "print(\"requires_grad of model: {}\".format(requires_grad(m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tensor\"><code>tensor</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L65\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>tensor</code>(<b>`x`</b>:`Any`, <b>`rest`</b>) → `Tensor`\n",
       "\n",
       "Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handy function when you want to convert any list type object to tensor, initialize your weights manually, and other similar cases.\n",
    "\n",
    "**NB**: When passing multiple vectors, all vectors must be of same dimensions. (Obvious but can be forgotten sometimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) <class 'torch.Tensor'>\n",
      "tensor([1, 2, 3]) <class 'torch.Tensor'>\n",
      "tensor([1, 2, 3]) <class 'torch.Tensor'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Conversion from any numpy array\n",
    "b = tensor(np.array([1, 2, 3]))\n",
    "print(b, type(b))\n",
    "\n",
    "# Passing as multiple parameters\n",
    "b = tensor(1, 2, 3)\n",
    "print(b, type(b))\n",
    "\n",
    "# Passing a single list\n",
    "b = tensor([1, 2, 3])\n",
    "print(b, type(b))\n",
    "\n",
    "# Can work with multiple vectors / lists\n",
    "b = tensor([1, 2], [3, 4])\n",
    "print(b, type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"to_cpu\"><code>to_cpu</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L92\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>to_cpu</code>(<b>`b`</b>:`ItemsList`)\n",
       "\n",
       "Recursively map lists of tensors in `b ` to the cpu.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(to_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wrapper on top of Pytorch's `torch.Tensor.cpu()` function, which creates and returns a copy of a tensor or even a **list** of tensors in the CPU. As described in Pytorch's docs, if the tensor or list of tensor is already on the CPU, the exact data is returned and no copy is made.\n",
    "\n",
    "Usefult to convert all the list of parameters of the model to CPU in a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.5932]], device='cuda:0'), tensor([[-0.2867]], device='cuda:0'), tensor([[-1.0616]], device='cuda:0')]\n",
      "Id of tensors in a: \n",
      "139974954993416\n",
      "139977016149120\n",
      "139974955521008\n",
      "[tensor([[-0.5932]]), tensor([[-0.2867]]), tensor([[-1.0616]])]\n",
      "Id of tensors in b:\n",
      "139974954963016\n",
      "139974955458280\n",
      "139974955521152\n",
      "[tensor([[-0.5932]]), tensor([[-0.2867]]), tensor([[-1.0616]])]\n",
      "Id of tensors in c:\n",
      "139974954963016\n",
      "139974955458280\n",
      "139974955521152\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    a = [torch.randn((1, 1)).cuda() for i in range(3)]\n",
    "    print(a)\n",
    "    print(\"Id of tensors in a: \")\n",
    "    for i in a: print(id(i))\n",
    "    \n",
    "    # Getting a CPU version of the tensors in GPU\n",
    "    b = to_cpu(a)\n",
    "    print(b)\n",
    "    print(\"Id of tensors in b:\")\n",
    "    for i in b: print(id(i))\n",
    "    \n",
    "    # Trying to perform to_cpu on a list of tensor already in CPU\n",
    "    c = to_cpu(b)\n",
    "    print(c)\n",
    "    # The tensors in c has exact id as that of b. No copy performed.\n",
    "    print(\"Id of tensors in c:\")\n",
    "    for i in c: print(id(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"to_data\"><code>to_data</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L87\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>to_data</code>(<b>`b`</b>:`ItemsList`)\n",
       "\n",
       "Recursively map lists of items in `b ` to their wrapped data.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the data attribute from the object or collection of objects that inherits from [`ItemBase`](/core.html#ItemBase) class. Useful to examine the exact values of the data, could be used to work with the data outside of `fastai` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category display names:  [Category 3, Category 7]\n",
      "Unique classes internally represented as:  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Default example examined\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path)\n",
    "\n",
    "# Examin the labels\n",
    "ys = list(data.y)\n",
    "print(\"Category display names: \", [ys[0], ys[-1]])\n",
    "\n",
    "print(\"Unique classes internally represented as: \", to_data([ys[0], ys[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"to_detach\"><code>to_detach</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L80\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>to_detach</code>(<b>`b`</b>:`Tensors`, <b>`cpu`</b>:`bool`=<b><i>`True`</i></b>)\n",
       "\n",
       "Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(to_detach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"to_device\"><code>to_device</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L102\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>to_device</code>(<b>`b`</b>:`Tensors`, <b>`device`</b>:[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device))\n",
       "\n",
       "Recursively put `b` on `device`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"to_half\"><code>to_half</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L97\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>to_half</code>(<b>`b`</b>:`Collection`\\[`Tensor`\\]) → `Collection`\\[`Tensor`\\]\n",
       "\n",
       "Recursively map lists of tensors in `b ` to FP16.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(to_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts the tensor or list of `FP16`, resulting in less memory consumption and faster computations with the tensor. It does not convert `torch.int` types to half precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of as: \ttorch.int64\ttorch.int32\ttorch.int16\ttorch.float64\ttorch.float32\ttorch.float16\n",
      "dtype of bs: \ttorch.int64\ttorch.int32\ttorch.int16\ttorch.float16\ttorch.float16\ttorch.float16\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor([1, 2], dtype=torch.int64)\n",
    "a2 = torch.tensor([1, 2], dtype=torch.int32)\n",
    "a3 = torch.tensor([1, 2], dtype=torch.int16)\n",
    "a4 = torch.tensor([1, 2], dtype=torch.float64)\n",
    "a5 = torch.tensor([1, 2], dtype=torch.float32)\n",
    "a6 = torch.tensor([1, 2], dtype=torch.float16)\n",
    "\n",
    "print(\"dtype of as: \", a1.dtype, a2.dtype, a3.dtype, a4.dtype, a5.dtype, a6.dtype, sep=\"\\t\")\n",
    "\n",
    "b1, b2, b3, b4, b5, b6 = to_half([a1, a2, a3, a4, a5, a6])\n",
    "\n",
    "print(\"dtype of bs: \", b1.dtype, b2.dtype, b3.dtype, b4.dtype, b5.dtype, b6.dtype, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"to_np\"><code>to_np</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L273\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>to_np</code>(<b>`x`</b>)\n",
       "\n",
       "Convert a tensor to a numpy array.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(to_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally puts the data to CPU, and converts to `numpy.ndarray` equivalent of `torch.tensor` by calling `torch.Tensor.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], dtype=torch.float64) <class 'torch.Tensor'> cpu\n",
      "[1. 2.] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2], dtype=torch.float64)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "\n",
    "print(a, type(a), a.device)\n",
    "\n",
    "b = to_np(a)\n",
    "\n",
    "print(b, type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"try_int\"><code>try_int</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L322\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>try_int</code>(<b>`o`</b>:`Any`) → `Any`\n",
       "\n",
       "Try to convert `o` to int, default to `o` if not possible.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(try_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 <class 'int'>\n",
      "[1.5] float64\n",
      "1 <class 'int'>\n",
      "2 <class 'int'>\n",
      "12.5 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Converts floating point numbers to integer\n",
    "print(try_int(12.5), type(try_int(12.5)))\n",
    "\n",
    "# This is a Rank-1 ndarray, which ideally should not be converted to int \n",
    "print(try_int(np.array([1.5])), try_int(np.array([1.5])).dtype)\n",
    "\n",
    "# Numpy array with a single elements are converted to int\n",
    "print(try_int(np.array(1.5)), type(try_int(np.array(1.5))))\n",
    "\n",
    "print(try_int(torch.tensor(2.5)), type(try_int(torch.tensor(2.5))))\n",
    "\n",
    "# Strings are not converted to int (of course)\n",
    "print(try_int(\"12.5\"), type(try_int(\"12.5\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to deal with model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"apply_init\"><code>apply_init</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L229\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>apply_init</code>(<b>`m`</b>, <b>`init_func`</b>:`LayerFunc`)\n",
       "\n",
       "Initialize all non-batchnorm layers of `m` with `init_func`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(apply_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"apply_leaf\"><code>apply_leaf</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L223\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>apply_leaf</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), <b>`f`</b>:`LayerFunc`)\n",
       "\n",
       "Apply `f` to children of `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(apply_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"cond_init\"><code>cond_init</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L219\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>cond_init</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), <b>`init_func`</b>:`LayerFunc`)\n",
       "\n",
       "Initialize the non-batchnorm layers of `m` with `init_func`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(cond_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"in_channels\"><code>in_channels</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L233\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>in_channels</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → `List`\\[`int`\\]\n",
       "\n",
       "Return the shape of the first weight layer in `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"init_default\"><code>init_default</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L212\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>init_default</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), <b>`func`</b>:`LayerFunc`=<b><i>`'kaiming_normal_'`</i></b>)\n",
       "\n",
       "Initialize `m` weights with `func` and set `bias` to 0.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(init_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get information of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"children\"><code>children</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L124\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>children</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → `ModuleList`\n",
       "\n",
       "Get children of `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"children_and_parameters\"><code>children_and_parameters</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L144\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>children_and_parameters</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module))\n",
       "\n",
       "Return the children of `m` and its direct parameters not registered in modules.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(children_and_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"first_layer\"><code>first_layer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L154\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>first_layer</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "Retrieve first layer in a module `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(first_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"last_layer\"><code>last_layer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L158\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>last_layer</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "Retrieve last layer in a module `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"num_children\"><code>num_children</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L128\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>num_children</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → `int`\n",
       "\n",
       "Get number of children modules in `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(num_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"one_param\"><code>one_param</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L318\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>one_param</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → `Tensor`\n",
       "\n",
       "Return the first parameter of `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(one_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"range_children\"><code>range_children</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L132\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>range_children</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → `Iterator`\\[`int`\\]\n",
       "\n",
       "Return iterator of len of children of `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(range_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"trainable_params\"><code>trainable_params</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L119\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>trainable_params</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → `ParamList`\n",
       "\n",
       "Return list of trainable params in `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to deal with BatchNorm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bn2float\"><code>bn2float</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L202\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>bn2float</code>(<b>`module`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)) → [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "If `module` is batchnorm don't use half precision.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bn2float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"set_bn_eval\"><code>set_bn_eval</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L191\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>set_bn_eval</code>(<b>`m`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module))\n",
       "\n",
       "Set bn layers in eval mode for all recursive children of `m`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(set_bn_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"split_bn_bias\"><code>split_bn_bias</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L180\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>split_bn_bias</code>(<b>`layer_groups`</b>:`ModuleList`) → `ModuleList`\n",
       "\n",
       "Split the layers in `layer_groups` into batchnorm (`bn_types`) and non-batchnorm groups.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(split_bn_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"log_uniform\"><code>log_uniform</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L305\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>log_uniform</code>(<b>`low`</b>, <b>`high`</b>, <b>`size`</b>:`Optional`\\[`List`\\[`int`\\]\\]=<b><i>`None`</i></b>) → `FloatOrTensor`\n",
       "\n",
       "Draw 1 or shape=`size` random floats from uniform dist: min=log(`low`), max=log(`high`).  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(log_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5775, 0.7902, 0.6087, 0.5730, 0.8057, 0.8845, 0.8975, 0.5585])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_uniform(0.5,2,(8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"rand_bool\"><code>rand_bool</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L310\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>rand_bool</code>(<b>`p`</b>:`float`, <b>`size`</b>:`Optional`\\[`List`\\[`int`\\]\\]=<b><i>`None`</i></b>) → `BoolOrTensor`\n",
       "\n",
       "Draw 1 or shape=`size` random booleans (`True` occuring with probability `p`).  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(rand_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_bool(0.5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"uniform\"><code>uniform</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L300\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>uniform</code>(<b>`low`</b>:`Number`, <b>`high`</b>:`Number`=<b><i>`None`</i></b>, <b>`size`</b>:`Optional`\\[`List`\\[`int`\\]\\]=<b><i>`None`</i></b>) → `FloatOrTensor`\n",
       "\n",
       "Draw 1 or shape=`size` random floats from uniform dist: min=`low`, max=`high`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6432, 0.3110, 0.7588, 0.7058, 0.7121, 0.8552, 0.3352, 0.2620])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform(0,1,(8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"uniform_int\"><code>uniform_int</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L314\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>uniform_int</code>(<b>`low`</b>:`int`, <b>`high`</b>:`int`, <b>`size`</b>:`Optional`\\[`List`\\[`int`\\]\\]=<b><i>`None`</i></b>) → `IntOrTensor`\n",
       "\n",
       "Generate int or tensor `size` of ints between `low` and `high` (included).  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(uniform_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_int(0,2,(8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"ParameterModule\"><code>class</code> <code>ParameterModule</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L136\" class=\"source_link\">[source]</a></h3>\n",
       "\n",
       "> <code>ParameterModule</code>(<b>`p`</b>:[`Parameter`](https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter)) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "Register a lone parameter `p` in a module.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ParameterModule, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"calc_loss\"><code>calc_loss</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L239\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>calc_loss</code>(<b>`y_pred`</b>:`Tensor`, <b>`y_true`</b>:`Tensor`, <b>`loss_func`</b>:`LossFunction`)\n",
       "\n",
       "Calculate loss between `y_pred` and `y_true` using `loss_func`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(calc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"data_collate\"><code>data_collate</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L108\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>data_collate</code>(<b>`batch`</b>:`ItemsList`) → `Tensor`\n",
       "\n",
       "Convert `batch` items to tensor data.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"get_model\"><code>get_model</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L330\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>get_model</code>(<b>`model`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module))\n",
       "\n",
       "Return the model maybe wrapped inside `model`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"grab_idx\"><code>grab_idx</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L285\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>grab_idx</code>(<b>`x`</b>, <b>`i`</b>, <b>`batch_first`</b>:`bool`=<b><i>`True`</i></b>)\n",
       "\n",
       "Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(grab_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"logit\"><code>logit</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L290\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>logit</code>(<b>`x`</b>:`Tensor`) → `Tensor`\n",
       "\n",
       "Logit of `x`, clamped to avoid inf.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"logit_\"><code>logit_</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L295\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>logit_</code>(<b>`x`</b>:`Tensor`) → `Tensor`\n",
       "\n",
       "Inplace logit of `x`, clamped to avoid inf  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(logit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"model_type\"><code>model_type</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L249\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>model_type</code>(<b>`dtype`</b>)\n",
       "\n",
       "Return the torch type corresponding to `dtype`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"np_address\"><code>np_address</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L76\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>np_address</code>(<b>`x`</b>:`ndarray`) → `int`\n",
       "\n",
       "Address of `x` in memory.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(np_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"split_model\"><code>split_model</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L169\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>split_model</code>(<b>`model`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), <b>`splits`</b>:`Collection`\\[`Union`\\[[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), `ModuleList`\\]\\], <b>`want_idxs`</b>:`bool`=<b><i>`False`</i></b>)\n",
       "\n",
       "Split `model` according to the layers in `splits`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(split_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `splits` are layers, the model is split at those (not included) sequentially. If `want_idxs` is True, the corresponding indexes are returned. If `splits` are lists of layers, the model is split according to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"split_model_idx\"><code>split_model_idx</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L162\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>split_model_idx</code>(<b>`model`</b>:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), <b>`idxs`</b>:`Collection`\\[`int`\\]) → `ModuleList`\n",
       "\n",
       "Split `model` according to the indexes in `idxs`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(split_model_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"trange_of\"><code>trange_of</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L269\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>trange_of</code>(<b>`x`</b>)\n",
       "\n",
       "Create a tensor from `range_of(x)`.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(trange_of)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undocumented Methods - Methods moved below this line will intentionally be hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tensor__array__\"><code>tensor__array__</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L278\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>tensor__array__</code>(<b>`dtype`</b>=<b><i>`None`</i></b>)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tensor__array__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ParameterModule.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L142\" class=\"source_link\">[source]</a></h4>\n",
       "\n",
       "> <code>forward</code>(<b>`x`</b>)\n",
       "\n",
       "Defines the computation performed at every call. Should be overridden by all subclasses.\n",
       "\n",
       ".. note::\n",
       "    Although the recipe for forward pass needs to be defined within\n",
       "    this function, one should call the :class:`Module` instance afterwards\n",
       "    instead of this since the former takes care of running the\n",
       "    registered hooks while the latter silently ignores them. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ParameterModule.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Methods - Please document or move to the undocumented section"
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "keywords": "fastai",
   "summary": "Basic functions using pytorch",
   "title": "torch_core"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
