{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast.ai has introduced a new module called fastai.text which replaces the torchtext library. Torchtext was used in our dl1 2018 course. The fastai.text module also supersedes the fastai.nlp library but retains many of the functions.\n",
    "\n",
    "We also import HTML so that we can unescape HTML tags in data during tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BOS and FLD are custom tokens to be inserted into the text data during tokenization.\n",
    "BOS is beginning of stream, which means one stream(block of text like a movie review) has ended and another begun\n",
    "FLD is used if the text data has many fields. In the case of IMDB, we have only one text field, the review itself. So this new token might not have a lot of value, but we still insert it anyway.\n",
    "\n",
    "There are more tokens introduced like t_up which is inserted into the text data in front of fully UP-CASE words (could mean shouting or emphasis). This saves us the information loss with lower() or also not having to learn 2 tokens for the same word - i.e. the lower and upper case versions. t_up tells the model that the following word was originally UP-CASED but i've downcased it for you. * more details below in the tokenizer section *\n",
    "\n",
    "You also need to download IMDB large movie reviews from this site: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "Direct link : [Link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) and untar it into the PATH location. Path is pathlib which makes directory traveral a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH=Path('data/aclImdb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create 2 paths:\n",
    "\n",
    "**CLAS** is for the classifier model and data & \n",
    "**LM** is for the language model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH=Path('data/imdb_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imdb dataset has 3 classes. positive, negative and unsupervised(sentiment is unknown). The README file in the imdb corpus directory explains how the data is laid out. \n",
    "\n",
    "The get_texts fn is used to read the step into the directory for each class(p,n,u) and read all the files and store them as entries in an array called texts. We also create another array called labels and fill it up with 0 for pos, 1 for neg and 2 for unsup reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            texts.append(fname.open('r').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts),np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use get_texts fn to read all the training reviews and test reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,trn_labels = get_texts(PATH/'train')\n",
    "val_texts,val_labels = get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 75k training reviews(12.5k pos, 12.5k neg, 50k unsup)\n",
    "\n",
    "There are 25k training reviews(12.5k pos, 12.5k neg & no unsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 25000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts),len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels','text'] # setup column names because pandas dataframe will ask for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a random permutation np array to shuffle the text reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # the random seed ensures that the next 2 random permutations result in the same order.\n",
    "trn_idx = np.random.permutation(len(trn_texts)) # Create an array of numbers for randomly shuffling training review texts\n",
    "val_idx = np.random.permutation(len(val_texts)) # Create an array of numbers for randomly shuffling test review texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26837  2592 18359 73292 60127 71737 26473  1040 32622 44679 17262 65288  9908 70558  5897 46462  2679 30356\n",
      " 36732 48199] \n",
      " [23481 13606 13639  1170  6803 18371 12360 13547 13215 21187  6251 23086  4688 15580 11756  2906 20742  2455\n",
      "  1454 17650]\n"
     ]
    }
   ],
   "source": [
    "print (trn_idx[:20],'\\n', val_idx[:20]) # see first 20 indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass the whole random array as an index to the texts and store the shuffled text in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts = trn_texts[trn_idx] #use trn index\n",
    "val_texts = val_texts[val_idx] # ditto for val texts\n",
    "\n",
    "trn_labels = trn_labels[trn_idx] # use same trn idx to get labels shuffled in same order\n",
    "val_labels = val_labels[val_idx] # ditto for val labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the training and text files/labels should be shuffled now and ready to get loaded into a pandas DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 75000, 25000, 25000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts),len(trn_labels),len(val_texts),len(val_labels) #75k 75k 25k 25k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas dataframe is used to store text data in a newly evolving standard format of label followed by text columns. This was influenced by a paper by Yann LeCun. Fastai adopts this new format. In the case of IMDB, there is only one text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dr Steven Segal saves the world from a deadly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cleopatra 2525 is a very funny, entertaining s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I was recently at a sleepover birthday party w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Why? Why? Why on earth no one tells the truth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Unlike most reviewers here, I hated this movie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       0  Dr Steven Segal saves the world from a deadly ...\n",
       "1       1  Cleopatra 2525 is a very funny, entertaining s...\n",
       "2       1  I was recently at a sleepover birthday party w...\n",
       "3       0  Why? Why? Why on earth no one tells the truth ...\n",
       "4       0  Unlike most reviewers here, I hated this movie..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe as CSV files in the CLAS path. Since CLAS is for the classifier data, we discard the unsup training reviews. So in CLAS_PATH/'train.csv' you will see only 1(pos) and 0(neg) reviews. The CSV mirrors the DF structure.\n",
    "\n",
    "All 3 classes are stored in a classes.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn[df_trn['labels']!=2].to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH/'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Classifier data is stored, we will not need it for a while. We need to get a good language model for IMDB first.\n",
    "\n",
    "Let's start by creating the data for the Language Model(LM). The LM's goal is to learn the structure of the english language. It learns language by trying to predict the next word given a set of previous words(ngrams). We really don't need to classify reviews as pos, neg etc. and labels can be ignored because we are not classifying anything in the LM.\n",
    "(*The labels are only used in the classifier model we will see later in this notebook.*)\n",
    "\n",
    "The LM can benefit from all the textual data and there is no need to exclude the unsup/unclassified movie reviews.\n",
    "\n",
    "We first concat all the train(pos/neg/unsup = **75k**) and test(pos/neg=**25k**) reviews into a big chunk of **100k** reviews. And then we use sklearn splitter to divide up the 100k texts into 90% training and 10% validation sets. *Again, the goal of the LM is to learn english by trying to predict words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([trn_texts,val_texts]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts) # 90k to train and 10k to predict prose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I really like the show and the virile \"manliness\" and cool humor exhibited by Darren Gavin. I\\'m sorry he has passed on. Some feminists might find the humor demeaning, but we have to remember it was mid-60s. My only criticism is that it was mainly filmed in Hollywood except for a very few exterior shots of New York. It is very Californiaish, particularly in some outdoors shots which are definitely not New York countryside. That\\'s a failing if you really want authenticity about a New York detective, particularly when you compare it to \"Naked City\" which was filmed on the streets of the city. Luckily some of the episodes are now on DVD. (I wish there would be more of these classic series on TV.)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_texts[0] # print first moview review from the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have a standard format of textual data, we need to store the reviews again in train.csv(90k) and test.csv(10k) in the LM path. This is just like the CLAS path files we stored earlier. We put labels first and then the text columns. Since we don't have labels in the LM case, we just put 0s in the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I really like the show and the virile \"manline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Michael Pitt can't act PLEASE make him stop tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Misty Ayers had a smoking body, and that's all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Which do you think the average person would kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>This ground breaking movie, much like the grou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       0  I really like the show and the virile \"manline...\n",
       "1       0  Michael Pitt can't act PLEASE make him stop tr...\n",
       "2       0  Misty Ayers had a smoking body, and that's all...\n",
       "3       0  Which do you think the average person would kn...\n",
       "4       0  This ground breaking movie, much like the grou..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False) #save LM train.csv\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False) #save LM test.csv\n",
    "\n",
    "df_trn.head() # print few rows from the pandas dataframe - labels are just 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous section was all about storing the textual data into LM and CLAS paths in a standard format we have adopted at fastai. In this section, we will start cleaning up the messy text. There are 2 main activities we need to perform:\n",
    "\n",
    "1. Clean up extra spaces, tab chars, new ln chars and other characters and replace them with standard ones\n",
    "2. Use the awesome [spacy](http://spacy.io) library to tokenize the data. Since spacy does not provide a parallel/multicore version of the tokenizer, the fastai library adds this functionality. This parallel version uses all the cores of your CPUs and runs much faster than the serial version of the spacy tokenizer.\n",
    "\n",
    "Tokenization is the process of splitting the text into separate tokens so that each token can be assigned a unique index. This means we can convert the text into pure numbers our models can use. *the indexes are integers but our models like to use real numbers - we will see how to convert these indexes to real numbers later.*\n",
    "\n",
    "A big issue with the tokenization process is that it is memory intensive - we use a chunksize of 24k to process the data in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fixup fn standardizes text and unescapes HTML tags. The get_texts fn uses the parallel tokenizer and creates the tokens in tok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i) # print out the loop number for each chunk of DF processed. chunksize is set above.\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Since we have 24k chunks you should see the loop run for each 24k chunk.\n",
    "#chunksize=100000 # Do this if you have enough RAM.\n",
    "tok_trn, trn_labels = get_all(df_trn, 1) # 4 loops (0,1,2,3) for 90k of training data\n",
    "tok_val, val_labels = get_all(df_val, 1) # 1 loop (0) for 10k of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a temporary directory and store all the tokenized data as numpy arrays that can be loaded up in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/imdb_lm/test.csv  data/imdb_lm/train.csv\r\n",
      "\r\n",
      "data/imdb_lm/tmp:\r\n",
      "itos.pkl  tok_trn.npy  tok_val.npy  trn_ids.npy  val_ids.npy\r\n"
     ]
    }
   ],
   "source": [
    "#Check saved files\n",
    "!ls $LM_PATH/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok_trn) # 90k training data text properly tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'xbos',\n",
       " 'xfld',\n",
       " '1',\n",
       " 'costner',\n",
       " \"'s\",\n",
       " 'films',\n",
       " 'continue',\n",
       " 'without',\n",
       " 'heart']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_trn[100][:10] #101th review shown as tokens - only first 10 tokens are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n xbos xfld 1 costner 's films continue without heart or soul . each is an appendage to the only film he ever made . this episode is more properly judged in the genre of videos , as this film substitutes any plot or character development , and certainly any acting for bland cinematography and overdone music . discard comments regarding sexism and ignore comparisons to tombstone , i feel sorry for him and his costars , some of whom actually deliver strong , believable performances . doc holliday is always entertaining . i was particularly saddened that the writers chose to trivialize the friendship between doc and wyatt by basing it upon a few meaningful looks and friendly handshakes . showing doc save wyatt 's life would have made for better watching and historical accuracy . and may i say , i love this legend ...\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tok_trn[100]) #101th review in training set - shown as tokenized text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, you can avoid the tokenization and cleaning process if you have stored the data in numpy files. You can simply load them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use python's Counter class to get the counts for each token in our data set. This can be useful to see which tokens/words are most used. Usually in normal text like english movie reviews, you'll find the words *a,the,and,of* etc. as the most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1209774),\n",
       " ('.', 992434),\n",
       " (',', 985208),\n",
       " ('and', 587218),\n",
       " ('a', 583337),\n",
       " ('of', 524995),\n",
       " ('to', 485571),\n",
       " ('is', 393545),\n",
       " ('it', 341509),\n",
       " ('in', 337883),\n",
       " ('i', 307894),\n",
       " ('this', 270449),\n",
       " ('that', 261016),\n",
       " ('\"', 237586),\n",
       " (\"'s\", 221225),\n",
       " ('-', 187707),\n",
       " ('was', 180504),\n",
       " ('\\n\\n', 179085),\n",
       " ('as', 166306),\n",
       " ('with', 159178),\n",
       " ('for', 158681),\n",
       " ('movie', 157557),\n",
       " ('but', 150450),\n",
       " ('film', 144288),\n",
       " ('you', 124032)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o) # for each object in tok_trn, take out the pieces. And foe each piece, run a count.\n",
    "freq.most_common(25) # display in descending order of count the top 25 tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *vocab* is the **unique set of all tokens** in our dataset. The vocab provides us a way for us to simply replace each word in our datasets with a unique integer called an index. This way we can convert textual data into numbers that our models can use. You might recall that an embedding layer is sometimes used to convert these indexes to real numbers which neural nets prefer.\n",
    "\n",
    "In a large corpus of data one might find some rare words which are only used a few times in the whole dataset. In such cases, there is no point wasting time, trying to learn meaningful patterns out of them and we can choose to discard them. Here we have set a minimum frequency of occurence to 2 times. If any token does not appear atleast twice in our full dataset, we will set it to a token called \\_unk\\_\n",
    "\n",
    "It has been observed by NLP practicioners that a maximum vocab of 60k usually yields good results for classification tasks. So we set maz_vocab to 60000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a mapping of the vocab indexes so that we can represent all of our corpus data as a big set of integers. We call this mapping itos. itos is created descending order of frequency of our corpus tokens. Since we set max_vocab to 60k, we have itos length as 60000. In addition we add a couple more tokens for unknown and pad characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:10] #here are the top 10 tokens from the itos mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60k most frequent words of the corpus in descending order + \\_unk\\_ & \\_pad\\_ tokens make up our vocab of size 60002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an itos, we can quickly create a reverse mapping called stoi which is useful to lookup the index of a given token. stoi also has the same number of elements as itos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a high performance container called [collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) to store our stoi mapping. It looks and feels like a typical dictionary in python, but is immune to missing values. \n",
    "\n",
    "Here are 10 elements in stoi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stoi)[:10] # displaying 10 elements after casting as a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert our 90k training and 10k test tokens into integer indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['_pad_'] #get the index of the _pad_ token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90000,), (10000,))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_lm.shape,val_lm.shape #np arrays after tokenization and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[40, 41, 42, 39, 12, 82, 52, 2, 140, 5, 2, 20552, 15, 36157, 15, 5, 602, 469, 13103, 46, 7364, 13699, 3, 12, 166, 771, 34, 59, 2186, 28, 3, 64, 17309, 252, 185, 2, 469, 15219, 4, 24, 89, 36, 8, 418, 10, 18, 39743, 3, 76, 80, 2840, 9, 14, 10, 18, 1430, 760, 11, 361, 565, 22, 6, 69, 189, 6246, 688, 7, 179, 786, 3, 10, 9, 69, 0, 4, 612, 11, 64, 12880, 688, 79, 33, 423, 32, 179, 786, 4424, 3, 14, 16, 6, 4198, 62, 26, 82, 203, 5754, 58, 6, 179, 786, 1210, 4, 612, 67, 26, 1723, 10, 8, 15, 1278, 515, 15, 79, 18, 760, 28, 2, 1817, 7, 2, 515, 3, 3808, 64, 7, 2, 770, 33, 165, 28, 31, 288, 3, 30, 12, 662, 53, 72, 37, 68, 7, 150, 389, 226, 28, 264, 3, 27]'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(trn_lm[0]) #The first training movie review expressed purely as integer indexes - numericalized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', 'xbos', 'xfld', '1', 'i', 'really', 'like', 'the', 'show', 'and', 'the', 'virile', '\"',\n",
       "       'manliness', '\"', 'and', 'cool', 'humor', 'exhibited', 'by', 'darren', 'gavin', '.', 'i', \"'m\",\n",
       "       'sorry', 'he', 'has', 'passed', 'on', '.', 'some', 'feminists', 'might', 'find', 'the', 'humor',\n",
       "       'demeaning', ',', 'but', 'we', 'have', 'to', 'remember', 'it', 'was', 'mid-60s', '.', 'my', 'only',\n",
       "       'criticism', 'is', 'that', 'it', 'was', 'mainly', 'filmed', 'in', 'hollywood', 'except', 'for', 'a',\n",
       "       'very', 'few', 'exterior', 'shots', 'of', 'new', 'york', '.', 'it', 'is', 'very', '_unk_', ',',\n",
       "       'particularly', 'in', 'some', 'outdoors', 'shots', 'which', 'are', 'definitely', 'not', 'new', 'york',\n",
       "       'countryside', '.', 'that', \"'s\", 'a', 'failing', 'if', 'you', 'really', 'want', 'authenticity',\n",
       "       'about', 'a', 'new', 'york', 'detective', ',', 'particularly', 'when', 'you', 'compare', 'it', 'to',\n",
       "       '\"', 'naked', 'city', '\"', 'which', 'was', 'filmed', 'on', 'the', 'streets', 'of', 'the', 'city', '.',\n",
       "       'luckily', 'some', 'of', 'the', 'episodes', 'are', 'now', 'on', 't_up', 'dvd', '.', '(', 'i', 'wish',\n",
       "       'there', 'would', 'be', 'more', 'of', 'these', 'classic', 'series', 'on', 'tv', '.', ')'],\n",
       "      dtype='<U34')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos_arr = np.array(itos)\n",
    "itos_arr[trn_lm[0]] # showing the first movie review as a reverse lookup of trn_lm[0] from itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now save our indexed data as numpy arrays. Saving the array can save us time in the future and we can load the datasets.\n",
    " We also save our itos mapping because we will be using it in the future for lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/imdb_lm/test.csv  data/imdb_lm/train.csv\r\n",
      "\r\n",
      "data/imdb_lm/tmp:\r\n",
      "itos.pkl  tok_trn.npy  tok_val.npy  trn_ids.npy  val_ids.npy\r\n"
     ]
    }
   ],
   "source": [
    "#Check the saved files\n",
    "!ls $LM_PATH/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: For the time being, I'm sacrificing accuracy to check the LM - So, only 100 rows are used to in the lm dataset - and sent to the dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "#val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "\n",
    "#For quick notebook validation - load back only 100 training and 100 validation reviews from our LM npys.\n",
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')[:100]\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')[:100]\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 100)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos) #vocab size\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikitext103 conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to build a language model for the IMDB corpus. We could start from scratch and try to learn the structure of the english language. But we use a technique called transfer learning to make this process easier. In transfer learning (a fairly recent idea for NLP) a pre-trained LM that has been trained on a large generic corpus(_like wikipedia articles_) can be used to transfer it's knowledge to a target LM and the weights can be fine-tuned. The source and target LMs should have data in the same  natural language(_english in our case_).\n",
    "\n",
    "Our source LM is the wikitext103 LM created by Stephen Merity @ Salesforce research. [Link to dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
    "The language model for wikitext103 has already been created for us using the AWD LSTM model and the weights can be downloaded here: [Link](http://files.fast.ai/models/wt103/)\n",
    "\n",
    "Our target LM is the IMDB LM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wget to download the files from the fast.ai link\n",
    "# ! wget -nH -r -np http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained LM weights have been created with an embedding size of 400, 1150 hidden units and just 3 layers. _The model is based on AWD LSTM seen in lesson 4 and contains lot of droput values placed strategically throughout the model._\n",
    "\n",
    "We need to match these values (emedding size, number of hidden and total layers) with the target IMDB LM so that the weights can be loaded up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded pre-trained model weights are placed in a separate directory called PRE_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/aclImdb/models/wt103')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the weights using torch.load that returns an ordered dictionary. The odict contains the number of elements matching the number of layers we have in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.encoder.weight', '0.encoder_with_dropout.embed.weight', '0.rnns.0.module.weight_ih_l0', '0.rnns.0.module.bias_ih_l0', '0.rnns.0.module.bias_hh_l0', '0.rnns.0.module.weight_hh_l0_raw', '0.rnns.1.module.weight_ih_l0', '0.rnns.1.module.bias_ih_l0', '0.rnns.1.module.bias_hh_l0', '0.rnns.1.module.weight_hh_l0_raw', '0.rnns.2.module.weight_ih_l0', '0.rnns.2.module.bias_ih_l0', '0.rnns.2.module.bias_hh_l0', '0.rnns.2.module.weight_hh_l0_raw', '1.decoder.weight'])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are weights and biases for many encoder, rnn layers. We can also see weights for a decoder (_last key_). But as you'll see, we are mainly interested in the encoders - the encoders are the layers which contain the knowledge of \"english language structure\" that we want to eventually use in our classifier(_last section of this notebook_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0) # calculate mean of encoder layer 0 weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the mean of the layer0 encoder weights. This can be used to assign weights to unknown tokens when we transfer to target IMDB LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400,),\n",
       " array([-0.0183 , -0.13826,  0.01438, -0.01285,  0.00407,  0.01944,  0.01149, -0.13282, -0.02295, -0.01722],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_m.shape, row_m[:10] #the mean has same size as the embedding. Shown are first 10 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try to transfer the knowledge from wikitext to IMDB model, we need to match up the vocab words and their indexes. We load the wikitext103 tokens into a list called itos2 and use it to create the stoi2 reverse mapping. \n",
    "\n",
    "We use the defaultdict container once again, that gives us the option of creating missing key values on lookup. We choose to initialize missing token lookups to -1. There shouldn't be any -1 when we start, but when we try to find IMDB words in wikitext103 stoi2, we could find some missing words. At that point, stoi2 will automatically set the values for those missing tokens to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238462,\n",
       " ['create',\n",
       "  '1998',\n",
       "  'upper',\n",
       "  'longer',\n",
       "  'soldiers',\n",
       "  'your',\n",
       "  'jackson',\n",
       "  'done',\n",
       "  'trade',\n",
       "  'fort'])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the wikitext103 contains 238462 tokens. \n",
    "#Here are 10 of them. 'create' seems to be the 1000th most common word in wikitext103\n",
    "len(itos2),itos2[999:1009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we start creating an embedding matrix for the target IMDB LM. The embedding matrix is of size (vocab size, embedding size) which is common between both LMs.\n",
    "\n",
    "We initialize the embedding matrix with a zeros np array and start filling it up by a cross-lookup between IMDB and wikitext103 tokens. We take a token from itos(IMDB), and do a reverse lookup in stoi2(Wikitext103). If it is found, we take the weights of that token and plug them into our embedding matrix. If we hit a missing token (that's in IMDB and not wikitext) stoi2 will automatically set it to -1. So we check for those numbers less than 0(missing tokens) and initialize them with mean weights(*row_m calculated earlier*).\n",
    "\n",
    "*The missing token embedding weights can be initialized randomly as well but the model might find it easier to tune weights from the mean point.*\n",
    "\n",
    "While the embedding layer tokens are initialized with well trained weights from wikitext, the missing token weights need to be tuned well before use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 400)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w.shape # our new IMDB embedding matrix is of IMDB vocab size X emb_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now overwrite the weights into the wgts odict, by first converting np arrays to tensors. If we don't make copies of NP arrays before assignment the torch tensors will share memory space and won't train well.\n",
    "\n",
    "*The decoder module, which we will explore in detail is also loaded with the same weights due to an idea called weight tying. Weight tying is a concept of using the same set of weights for multiple parameters by having the model point to the same memoray locations where the weights are stored. This usually results is a lot less parameters to train and speeds up the process. Sometimes, it is beneficial to tie weights across layers to have more control over the activations from those layers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60002, 400])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tensor size of named element weights\n",
    "wgts['1.decoder.weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the weights prepared, we are ready to create and start training our new IMDB language pytorch model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is fairly straightforward to create a new language model using the fastai library. Like every other lesson, our model will have a backbone and a custom head. The backbone in our case is the IMDB LM pre-trained with wikitext and the custom head is a linear classifier. In this section we will focus on the backbone LM and the next section will talk about the classifier custom head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initializing the following core settings for our model: \n",
    "Weight decay, back prop through time (*the approximate number of tokens we read in each batch to predict the target token*), batch size (*the number of inputs processed in each mini-batch*) and the optimizer we want to use.\n",
    "\n",
    "bptt (*also known traditionally in NLP LM as ngrams*) in fastai LMs is approximated to a std. deviation around 70, by perturbing the sequence length on a per-batch basis. This is akin to shuffling our data in computer vision, only that in NLP we cannot shuffle inputs and we have to maintain statefulness. \n",
    "\n",
    "Since we are predicting words using ngrams, we want our next batch to line up with the end-points of the previous mini-batch's items. batch-size is constant and but the fastai library expands and contracts bptt each mini-batch using a clever stochastic implementation of a batch, whose original credits are attributed to [Smerity](https://twitter.com/jeremyphoward/status/980227258395770882)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7 #weight decay\n",
    "bptt=70 # we mention 70 but fastai uses some approximate value around 70\n",
    "bs=100 #batch size\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99)) # use adam optimizer with low betas - RNNs tend to work better with this setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the LM is to learn to predict a word/token given a preceeding set of words(tokens). We take all the movie reviews in both the 90k training set and 10k validation set and concatenate them to form long strings of tokens. In fastai, we use the `LanguageModelLoader` to create a data loader which makes it easy to create and use bptt sized mini batches. The  `LanguageModelLoader` takes a concatenated string of tokens and returns a loader.\n",
    "\n",
    "Then we chuck both those training and validation loaders into a model data object. We have a special class for LMs called `LanguageModelData`. Using this class, we can conveniently ask the fastai library to automatically give us the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of the `LanguageModelLoader` class**: Return an iterator of bs X bptt by batchifying a train/validation or test set \n",
    "\n",
    "```python\n",
    "Init signature: LanguageModelLoader(nums, bs, bptt, backwards=False)\n",
    "Docstring:      <no docstring>\n",
    "Source:        \n",
    "class LanguageModelLoader():\n",
    "    def __init__(self, nums, bs, bptt, backwards=False):\n",
    "        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n",
    "        self.data = self.batchify(nums)\n",
    "        self.i,self.iter = 0,0\n",
    "        self.n = len(self.data)\n",
    "\n",
    "    def __iter__(self):                #Iteratively returns approximately mini batch of size bs X (approx bptt)\n",
    "        self.i,self.iter = 0,0\n",
    "        while self.i < self.n-1 and self.iter<len(self):\n",
    "            bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n",
    "            seq_len = max(5, int(np.random.normal(bptt, 5)))\n",
    "            res = self.get_batch(self.i, seq_len)\n",
    "            self.i += seq_len\n",
    "            self.iter += 1\n",
    "            yield res \n",
    "\n",
    "    def __len__(self): return self.n // self.bptt - 1\n",
    "\n",
    "    def batchify(self, data):         #breaks up the whole dataset into bs number of chunks\n",
    "        nb = data.shape[0] // self.bs\n",
    "        data = np.array(data[:nb*self.bs])\n",
    "        data = data.reshape(self.bs, -1).T\n",
    "        if self.backwards: data=data[::-1]\n",
    "        return T(data)\n",
    "\n",
    "    def get_batch(self, i, seq_len):\n",
    "        source = self.data\n",
    "        seq_len = min(seq_len, len(source) - 1 - i)\n",
    "        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n",
    "File:           ~/fastai2/fastai/courses/dl2/fastai/text.py\n",
    "Type:           type\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of the `LanguageModelData` class** : Initialize core settings and retrieve model from `get_language_model` and return it as using `RNN_Learner`.\n",
    "\n",
    "The magic happens the `get_model` fn where the `get_language_model` fn is used to return a `SequentialRNN` model.\n",
    "In the SequentialRNN model, an RNN_Encoder layer is instantiated using the parameters provided. This is followed by the creation of a LinearDecoder layer. Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder is used to  instantiate the weights for the LinearDecoder layer. As a final step, the learner which gets returned is a special type called `RNN_Learner` where the loss fn is set to cross-entropy. We need this loss to make sure the LM effectively learns to predict subsequent words.\n",
    "\n",
    "    The SequentialRNN layer is the native torch's Sequential wrapper that puts the RNN_Encoder and\n",
    "    LinearDecoder layers sequentially in the model.\n",
    "```python\n",
    "Init signature: LanguageModelData(path, pad_idx, nt, trn_dl, val_dl, test_dl=None, bptt=70, backwards=False, **kwargs)\n",
    "Docstring:      <no docstring>\n",
    "Source:        \n",
    "class LanguageModelData():\n",
    "    def __init__(self, path, pad_idx, nt, trn_dl, val_dl, test_dl=None, bptt=70, backwards=False, **kwargs):\n",
    "        self.path,self.pad_idx,self.nt = path,pad_idx,nt\n",
    "        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n",
    "\n",
    "    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n",
    "        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n",
    "        model = LanguageModel(to_gpu(m))\n",
    "        #return RNN_Learner(self, nn.DataParallel(model), opt_fn=opt_fn)\n",
    "        return RNN_Learner(self, model, opt_fn=opt_fn)\n",
    "File:           ~/fastai2/fastai/courses/dl2/fastai/text.py\n",
    "Type:           type\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "??RNN_Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the dropouts for the model - these values have been chosen after experimentation. If you need to update them for custom LMs, you can change the weighting factor (0.7 here) based on the amount of data you have. For more data, you can reduce dropout factor and for small datasets, you can reduce overfitting by choosing a higher dropout factor. *No other dropout value requires tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7 #setup dropout values and control them using a weighting factor: 0.7 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model data object for our IMDB LM, it is a straightforward process to get the model from it and name it `learner`. One of the first things to tune in the encoder(and the decoder because of default weight tying) is the last embedding layer. This is mainly done so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1) # Freeze until the last embedding layer\n",
    "#learner.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the learner is a typical pytorch module with an (0)encoder and a (1)decoder.\n",
    "\n",
    "The encoder contains the embedding layer and 3 hidden LSTM layers. The decoder is a linear layer with *vocab_size* number of tokens for predicting output probabilities of each of the tokens in the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(60002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150, dropout=0.105)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150, dropout=0.105)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400, dropout=0.105)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60002, bias=False)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner #Show the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.encoder.weight', \n",
       "               0.0676 -0.0510  0.0617  ...  -0.0848  0.0321  0.0716\n",
       "               0.0672  0.0265  0.0298  ...   0.0638  0.0968 -0.0329\n",
       "              -0.0119  0.0022 -0.0030  ...   0.0645 -0.0806  0.0679\n",
       "                        ...             ⋱             ...          \n",
       "               0.0074 -0.0083  0.0296  ...   0.0371  0.0334 -0.0621\n",
       "              -0.0100  0.0115  0.0054  ...  -0.0695  0.0668 -0.0989\n",
       "               0.0970  0.0534 -0.0448  ...   0.0264 -0.0076 -0.0402\n",
       "              [torch.FloatTensor of size 60002x400]),\n",
       "             ('0.encoder_with_dropout.embed.weight', \n",
       "               0.0676 -0.0510  0.0617  ...  -0.0848  0.0321  0.0716\n",
       "               0.0672  0.0265  0.0298  ...   0.0638  0.0968 -0.0329\n",
       "              -0.0119  0.0022 -0.0030  ...   0.0645 -0.0806  0.0679\n",
       "                        ...             ⋱             ...          \n",
       "               0.0074 -0.0083  0.0296  ...   0.0371  0.0334 -0.0621\n",
       "              -0.0100  0.0115  0.0054  ...  -0.0695  0.0668 -0.0989\n",
       "               0.0970  0.0534 -0.0448  ...   0.0264 -0.0076 -0.0402\n",
       "              [torch.FloatTensor of size 60002x400]),\n",
       "             ('0.rnns.0.module.weight_ih_l0', \n",
       "               2.6760e-02  1.8656e-02 -2.8584e-02  ...   6.4010e-03 -2.3807e-03  6.5946e-03\n",
       "              -1.9742e-02 -1.8077e-02  1.0809e-02  ...   6.5002e-04 -1.2346e-02 -1.1271e-02\n",
       "              -1.4300e-02  9.7758e-03 -1.8166e-04  ...  -1.7179e-02  2.9470e-02  1.6653e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "               8.8191e-03 -1.4824e-02 -1.3223e-02  ...   8.0783e-03 -2.2985e-02 -2.6820e-02\n",
       "              -1.4690e-02  5.0693e-03  1.4939e-02  ...  -2.4526e-02 -2.3279e-02 -1.1754e-02\n",
       "              -2.0119e-02  1.9096e-02 -2.7934e-02  ...   8.3901e-03 -6.3521e-03  2.1374e-02\n",
       "              [torch.FloatTensor of size 4600x400]),\n",
       "             ('0.rnns.0.module.bias_ih_l0', \n",
       "              1.00000e-02 *\n",
       "               -1.0154\n",
       "                0.0500\n",
       "               -1.2052\n",
       "                  ⋮   \n",
       "               -0.6798\n",
       "                1.7756\n",
       "                1.8385\n",
       "              [torch.FloatTensor of size 4600]),\n",
       "             ('0.rnns.0.module.bias_hh_l0', \n",
       "              1.00000e-02 *\n",
       "               -1.8510\n",
       "                1.8437\n",
       "               -2.8223\n",
       "                  ⋮   \n",
       "                0.8863\n",
       "               -0.6205\n",
       "               -0.6875\n",
       "              [torch.FloatTensor of size 4600]),\n",
       "             ('0.rnns.0.module.weight_hh_l0_raw', \n",
       "              -8.4351e-03 -2.7104e-02 -5.1294e-03  ...   2.4843e-02  4.5757e-04  1.5326e-02\n",
       "               2.5324e-02  2.5369e-02  1.6262e-02  ...  -2.8916e-02 -2.4430e-02 -2.1458e-02\n",
       "              -2.9231e-02 -9.3349e-04 -4.1260e-03  ...  -2.2222e-03 -2.3458e-02 -1.1135e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "              -2.5735e-02  2.9360e-02 -1.7863e-02  ...   9.9484e-03 -5.1910e-03 -2.4852e-02\n",
       "              -9.0387e-03 -3.8634e-04 -2.8675e-02  ...  -1.5823e-02  2.2701e-02  6.0549e-03\n",
       "               1.9179e-02  1.2636e-02  9.2736e-04  ...  -2.3832e-02 -4.1920e-03 -9.4183e-03\n",
       "              [torch.FloatTensor of size 4600x1150]),\n",
       "             ('0.rnns.1.module.weight_ih_l0', \n",
       "               2.9340e-02  1.6505e-03 -2.7523e-02  ...   6.4218e-03 -2.8036e-02 -8.6387e-03\n",
       "               2.1036e-02  1.6515e-02 -1.0027e-02  ...   2.6036e-02 -1.4801e-02 -2.1610e-02\n",
       "              -1.1338e-02  1.7890e-02  1.5818e-02  ...  -2.6958e-02 -2.5186e-02 -1.9274e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "               4.1021e-03  5.1510e-05 -2.6759e-02  ...  -2.1294e-02 -2.8819e-02 -1.1077e-02\n",
       "              -2.3736e-02 -6.3544e-03 -5.5161e-03  ...   1.9659e-02 -1.7197e-02 -1.4988e-02\n",
       "               1.0893e-02  2.3476e-02 -1.0757e-02  ...  -1.3809e-02  2.1239e-02  1.7999e-02\n",
       "              [torch.FloatTensor of size 4600x1150]),\n",
       "             ('0.rnns.1.module.bias_ih_l0', \n",
       "              1.00000e-02 *\n",
       "                0.0224\n",
       "               -0.6739\n",
       "                2.1840\n",
       "                  ⋮   \n",
       "                2.2955\n",
       "               -0.8660\n",
       "                0.9616\n",
       "              [torch.FloatTensor of size 4600]),\n",
       "             ('0.rnns.1.module.bias_hh_l0', \n",
       "              1.00000e-02 *\n",
       "                1.5333\n",
       "                0.1944\n",
       "                1.1917\n",
       "                  ⋮   \n",
       "               -1.7989\n",
       "                1.5608\n",
       "               -1.2016\n",
       "              [torch.FloatTensor of size 4600]),\n",
       "             ('0.rnns.1.module.weight_hh_l0_raw', \n",
       "              1.00000e-02 *\n",
       "               0.8967  0.2968  0.5144  ...  -1.2057 -2.1270  0.0524\n",
       "              -0.1912  0.6382  2.4874  ...   0.6097 -2.4468 -1.5746\n",
       "               0.6660 -1.7908 -1.0793  ...  -2.0224 -0.5250  1.7669\n",
       "                        ...             ⋱             ...          \n",
       "              -1.8246  2.2317  0.6559  ...   2.0754 -1.7072  0.9403\n",
       "               2.8802  2.2444 -2.9051  ...  -2.3975 -0.8228  1.2990\n",
       "              -1.5868 -1.2555  0.5250  ...  -1.4278  2.6850  1.1723\n",
       "              [torch.FloatTensor of size 4600x1150]),\n",
       "             ('0.rnns.2.module.weight_ih_l0', \n",
       "               1.4302e-03  3.5697e-02 -2.8231e-02  ...  -7.7525e-03 -2.9733e-03 -4.0140e-02\n",
       "               2.6500e-02 -2.7245e-02 -4.4374e-02  ...  -3.7141e-02  3.9958e-02 -4.2265e-02\n",
       "               5.3277e-03 -2.0050e-02 -1.6155e-02  ...  -8.2470e-03 -2.2769e-02 -1.7780e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "               2.9349e-02  2.1426e-03  4.7387e-02  ...  -2.1501e-03  1.3338e-02 -2.4982e-02\n",
       "              -2.5082e-02  3.2728e-02 -3.4479e-02  ...  -3.1603e-02 -3.0674e-02 -8.6129e-03\n",
       "              -4.0703e-02  3.2792e-02  9.8799e-03  ...  -8.5211e-03  4.2555e-02 -4.7734e-02\n",
       "              [torch.FloatTensor of size 1600x1150]),\n",
       "             ('0.rnns.2.module.bias_ih_l0', \n",
       "              1.00000e-02 *\n",
       "               -3.5141\n",
       "               -3.0325\n",
       "                1.9370\n",
       "                  ⋮   \n",
       "               -2.9902\n",
       "                3.0151\n",
       "                4.8949\n",
       "              [torch.FloatTensor of size 1600]),\n",
       "             ('0.rnns.2.module.bias_hh_l0', \n",
       "              1.00000e-02 *\n",
       "               -3.6511\n",
       "               -3.7604\n",
       "                4.0547\n",
       "                  ⋮   \n",
       "               -2.9855\n",
       "               -2.7076\n",
       "               -2.8216\n",
       "              [torch.FloatTensor of size 1600]),\n",
       "             ('0.rnns.2.module.weight_hh_l0_raw', \n",
       "              -4.8149e-02  4.2305e-02 -1.4591e-02  ...   3.0080e-02 -2.3588e-02  2.1497e-02\n",
       "              -2.6269e-02  2.3875e-03 -2.3776e-02  ...   3.6061e-03 -9.6844e-03 -2.4127e-02\n",
       "               4.1638e-02 -2.0504e-02  2.6105e-02  ...  -2.3031e-02 -4.7880e-02  1.8952e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "               3.0830e-02 -1.5607e-02  3.7896e-02  ...   2.0714e-02 -4.4020e-02  9.6817e-03\n",
       "              -1.8264e-02 -3.7490e-02 -1.9460e-02  ...  -3.5068e-02 -1.6359e-02  6.9477e-03\n",
       "               1.0879e-02  2.8403e-02  2.7099e-02  ...   4.8319e-02  4.3994e-02 -3.0772e-02\n",
       "              [torch.FloatTensor of size 1600x400]),\n",
       "             ('1.decoder.weight', \n",
       "               0.0676 -0.0510  0.0617  ...  -0.0848  0.0321  0.0716\n",
       "               0.0672  0.0265  0.0298  ...   0.0638  0.0968 -0.0329\n",
       "              -0.0119  0.0022 -0.0030  ...   0.0645 -0.0806  0.0679\n",
       "                        ...             ⋱             ...          \n",
       "               0.0074 -0.0083  0.0296  ...   0.0371  0.0334 -0.0621\n",
       "              -0.0100  0.0115  0.0054  ...  -0.0695  0.0668 -0.0989\n",
       "               0.0970  0.0534 -0.0448  ...   0.0264 -0.0076 -0.0402\n",
       "              [torch.FloatTensor of size 60002x400])])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model.state_dict() # Let's check our model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "??learner.model.load_state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now copy our weights from the `wgts` state dictionary using the fastai `load_state_dict` function. It copied the parameters and buffers from `wgts` into our model's module and its descendants. The attribute`strict` is ``True`` by default and it forces the the keys of `wgts` to exactly match the keys returned by our module's `state_dict()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(wgts) # Load the weights into our learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set learning rates and fit our IMDB LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the wikitext103 learn better weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f737acee03bf4f6688706a248bb4a13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy               \n",
      "    0      5.602066   5.413144   0.218776  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.413143873214722, 0.21877604166666667]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we print out accuracy and keep track of how often we end up predicting the target word correctly. While this is a good metric to check, it is not part of our loss function as it can get quite bumpy. We only minimize cross-entropy loss in the LM.\n",
    "\n",
    "The exponent of the cross-entropy loss is called the perplexity of the LM. A low perplexity is a potential indicator of a good LM. If an LM is perplexed, it cannot speak good english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft') # save last layer fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft') # load last layer fit model in future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now unfreeze the model layers and get ready to fine tune some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75e696864e345fbb9cc95184c0f0eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy               \n",
      "    0      5.583637   6.30935    0.194163  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4caec17fc94f289b3921e0ec6ecf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy               \n",
      "    0      5.536444   5.312485   0.223434  \n",
      "    1      5.459926   5.120803   0.230434               \n",
      "    2      5.323185   5.0591     0.229125               \n",
      "    3      5.192071   5.010774   0.23125                \n",
      "    4      5.074899   4.98609    0.231264               \n",
      "    5      4.982038   4.949386   0.238163               \n",
      "    6      4.884302   4.977661   0.23335                \n",
      "    7      4.792179   4.95419    0.239158               \n",
      "    8      4.704118   5.017949   0.231487               \n",
      "    9      4.623066   5.017501   0.229992               \n",
      "    10     4.549517   5.029907   0.231253               \n",
      "    11     4.478839   5.049689   0.229848               \n",
      "    12     4.422343   5.052155   0.229095               \n",
      "    13     4.362847   5.062611   0.230302               \n",
      "    14     4.315576   5.065027   0.229792               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.065026760101318, 0.22979234616220917]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the trained model weights and separately save the encoder part of the LM model as well. This will serve as our backbone in the classification task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier model is basically a linear layer custom head on top of the LM backbone. Before we create the classifier model and train it, we need to setup the data. \n",
    "\n",
    "Setting up the classifier data is similar to the LM data setup except that we cannot use the unsup movie reviews this time. In the LM, our goal was to learn english and the unsup reviews were used. Now, with actual pos/neg labels coming into play we discard the unsup reviews and use only the pos/neg ones.\n",
    "\n",
    "We read the original train and test CSV files we had in the `CLAS_PATH` saved and perform the same sequence of steps to get the tokens, numericalized arrays and the `itos` and `stoi` mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numericalized data as npy arrays for future quick loads\n",
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the itos mapping and stoi reverse mapping for tokens in the IMDB vocab.\n",
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final data for classifier model\n",
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have training data for the classifier model in `trn_clas` and validation data in `val_clas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our final model, a classifier which is really a custom linear head over our trained IMDB backbone. The steps to create the classifier model are similar to the ones for the LM.\n",
    "\n",
    "We first pickup the data and labels for creating the new modeldata object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick a batch size that you can comfortably fit into memory while training the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classifier, unlike LM, we need to read a movie review at a time and ;earn to predict the it's sentiment as pos/neg. We do not deal with equal bptt size batches, so we have to pad the sequences to the same length in each batch. Now, some movie reviews (like my documentation) can be quite lengthy and will result in the rest of the batch getting padded like crazy. To avoid this, a cool trick called the sortish sampler was invented by, wait for it, [@Smerity](https://twitter.com/Smerity) and [@jekbradbury](https://twitter.com/jekbradbury)\n",
    "\n",
    "The sortishSampler approximately sorts in ascending order of sequence length the movie reviews so that we create batches where similar sized reviews get bundled into mini-batches. This cuts down the overall number of padding tokens the classifier ends up seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RNN_Learner` is the learner class with the same encoder as our LM but a pooling linear classifier as the decoder(which gets trained more, while the LM encoder is slightly trained in the end after unfreezing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e989e4c7e94c5c941716d889fce581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 822/1042 [1:03:47<17:04,  4.66s/it, loss=1.99] "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9b5290d74c407799efe07bbceec217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                        \n",
      "    0      0.369499   0.29496    0.875496  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29495994311948653, 0.8754958413307742]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de1f26cced4420e8bbe8c2cadc35f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                         \n",
      "    0      0.346185   0.244749   0.901056  \n",
      "    1      0.263001   0.214615   0.916787                         \n",
      "    2      0.244726   0.195925   0.923664                         \n",
      "    3      0.182181   0.189529   0.928399                         \n",
      " 63%|██████▎   | 661/1042 [2:11:29<1:15:47, 11.93s/it, loss=0.142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c17f00c1e04d5bbb13f75497cf661e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1it [00:11, 11.62s/it, loss=0.091] epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.091031   0.208004   0.927303  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20800437038539124, 0.9273032629558541]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 0, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6038399748d341788c48c682262dce90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 450/1042 [1:22:06<1:48:00, 10.95s/it, loss=0.0897]"
     ]
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From original Jeremy's notebook: *The previous state of the art result was 94.1% accuracy (5.9% error). With bidir we get 95.4% accuracy (4.6% error).*\n",
    "\n",
    "Note: Since we have trained a weaker LM model(only 100 rows) and run fewer epochs on the classifier, we get lesser accuracy than Jeremy - But will more LM finetuning & more classifier training it should be possible to achieve the 94.7% accuracy.\n",
    "\n",
    "***This notebook will be continuously updated with more information - If you spotted any errors in the descriptions, please notify @narvind2003 in the fast.ai forums. Thanks!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tbd: reverse the data tokens and train a backwards model - just like a bidirectional RNN and use the avg(forward preds, backward preds) should yield much better accuracy **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
